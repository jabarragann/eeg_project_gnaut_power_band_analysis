{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with Jing math data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainModel import createImageDataset, showImages\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Possible set of labels\n",
    "# \"\"\"\n",
    "# [\"pegNormal\",\"pegInversion\"]\n",
    "# [\"EasyAdd\",\"HardMult\"]\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file information: Chiho 1 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 60/300Interpolating 89/300Interpolating 144/300Interpolating 173/300Interpolating 204/300Interpolating 291/300\n",
      "file information: Chiho 1 1 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 63/300Interpolating 91/300Interpolating 121/300Interpolating 150/300Interpolating 179/300Interpolating 208/300Interpolating 237/300\n",
      "file information: Chiho 2 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 89/300Interpolating 119/300Interpolating 148/300Interpolating 177/300Interpolating 205/300Interpolating 234/300Interpolating 264/300\n",
      "file information: Chiho 2 2 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 63/300Interpolating 93/300Interpolating 184/300Interpolating 211/300Interpolating 241/300Interpolating 264/300Interpolating 293/300\n",
      "file information: Chiho 4 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 63/300Interpolating 92/300Interpolating 122/300Interpolating 152/300Interpolating 182/300Interpolating 212/300Interpolating 242/300Interpolating 270/300Interpolating 300/300\n",
      "file information: Chiho 4 1 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 60/300Interpolating 89/300Interpolating 119/300Interpolating 147/300Interpolating 175/300Interpolating 204/300Interpolating 232/300Interpolating 260/300Interpolating 289/300\n",
      "file information: Juan 1 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 62/300Interpolating 86/300Interpolating 114/300Interpolating 144/300Interpolating 173/300Interpolating 204/300Interpolating 233/300Interpolating 262/300Interpolating 292/300\n",
      "file information: Juan 1 1 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 61/300Interpolating 91/300Interpolating 120/300Interpolating 149/300Interpolating 173/300Interpolating 201/300Interpolating 231/300Interpolating 260/300Interpolating 289/300\n",
      "file information: Juan 2 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 60/300Interpolating 89/300Interpolating 119/300Interpolating 196/300Interpolating 222/300Interpolating 251/300Interpolating 278/300\n",
      "file information: Juan 2 1 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 60/300Interpolating 88/300Interpolating 116/300Interpolating 146/300Interpolating 175/300Interpolating 204/300Interpolating 291/300\n",
      "file information: Juan 3 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 59/300Interpolating 85/300Interpolating 112/300Interpolating 140/300Interpolating 169/300Interpolating 197/300Interpolating 226/300Interpolating 255/300Interpolating 284/300\n",
      "file information: Juan 3 1 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 60/300Interpolating 88/300Interpolating 117/300Interpolating 145/300Interpolating 174/300Interpolating 202/300Interpolating 231/300Interpolating 261/300Interpolating 290/300\n",
      "file information: Juan 4 1 EyesClosed\n",
      "300 frames generated with label  0.0/300Interpolating 60/300Interpolating 89/300Interpolating 116/300Interpolating 144/300Interpolating 171/300Interpolating 198/300Interpolating 225/300Interpolating 254/300Interpolating 281/300\n",
      "file information: Juan 4 1 EyesOpen\n",
      "300 frames generated with label  1.0/300Interpolating 59/300Interpolating 87/300Interpolating 116/300Interpolating 144/300Interpolating 170/300Interpolating 198/300Interpolating 226/300Interpolating 254/300Interpolating 282/300\n"
     ]
    }
   ],
   "source": [
    "dataPath = Path(r\"C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiment1-Pilot\\UI02\\pyprep_edf\")\n",
    "X, y = createImageDataset(dataPath,imageSize=32,frameDuration=1,overlap=0.2,\n",
    "                          augment_data=False, labels = [\"pegNormal\",\"pegInversion\"],\n",
    "                          lstm_format=False, lstm_sequence_length=None,\n",
    "                         fileNameFormat=1)\n",
    "\n",
    "\n",
    "# Eyes open-close dataset\n",
    "# dataPath = Path(r'C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiments3-Data\\EyesOpen_closeDataset\\edf')\n",
    "# X, y = createImageDataset(dataPath,imageSize=32,frameDuration=1,overlap=0.2,\n",
    "#                           augment_data=False, labels = [\"EyesClosed\",\"EyesOpen\"],\n",
    "#                           lstm_format=False, lstm_sequence_length=None,\n",
    "#                          fileNameFormat=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file information: UJing 1 1 EasyAdd\n",
      "file information: UJing 1 2 HardMult\n",
      "file information: UJing 1 3 EasyAdd\n",
      "file information: UJing 1 4 HardMult\n",
      "file information: UJing 1 5 EasyAdd\n",
      "file information: UJing 1 6 HardMult\n",
      "file information: UJing 1 7 EasyAdd\n",
      "file information: UJing 1 8 HardMult\n",
      "file information: UJing 1 9 EasyAdd\n",
      "file information: UJing 1 10 HardMult\n",
      "file information: UJing 1 11 EasyAdd\n",
      "file information: UJing 1 12 HardMult\n",
      "file information: UJing 2 1 EasyAdd\n",
      "file information: UJing 2 2 HardMult\n",
      "file information: UJing 2 3 EasyAdd\n",
      "file information: UJing 2 4 HardMult\n",
      "file information: UJing 2 5 EasyAdd\n",
      "file information: UJing 2 6 HardMult\n",
      "file information: UJing 2 7 EasyAdd\n",
      "file information: UJing 2 8 HardMult\n",
      "file information: UJing 2 9 EasyAdd\n",
      "file information: UJing 2 10 HardMult\n",
      "file information: UJing 2 11 EasyAdd\n",
      "file information: UJing 2 12 HardMult\n",
      "file information: UJing 3 1 EasyAdd\n",
      "file information: UJing 3 2 HardMult\n",
      "file information: UJing 3 3 EasyAdd\n",
      "file information: UJing 3 4 HardMult\n",
      "file information: UJing 3 5 EasyAdd\n",
      "file information: UJing 3 6 HardMult\n",
      "file information: UJing 3 7 EasyAdd\n",
      "file information: UJing 3 8 HardMult\n",
      "file information: UJing 3 9 EasyAdd\n",
      "file information: UJing 3 10 HardMult\n",
      "file information: UJing 3 11 EasyAdd\n",
      "file information: UJing 3 12 HardMult\n",
      "file information: UJuan 1 1 EasyAdd\n",
      "file information: UJuan 1 2 HardMult\n",
      "file information: UJuan 1 3 EasyAdd\n",
      "file information: UJuan 1 4 HardMult\n",
      "file information: UJuan 1 5 EasyAdd\n",
      "file information: UJuan 1 6 HardMult\n",
      "file information: UJuan 1 7 EasyAdd\n",
      "file information: UJuan 1 8 HardMult\n",
      "file information: UJuan 1 9 EasyAdd\n",
      "file information: UJuan 1 10 HardMult\n",
      "file information: UJuan 1 11 EasyAdd\n",
      "file information: UJuan 1 12 HardMult\n",
      "file information: UJuan 2 1 EasyAdd\n",
      "file information: UJuan 2 2 HardMult\n",
      "file information: UJuan 2 3 EasyAdd\n",
      "file information: UJuan 2 4 HardMult\n",
      "file information: UJuan 2 5 EasyAdd\n",
      "file information: UJuan 2 6 HardMult\n",
      "file information: UJuan 2 7 EasyAdd\n",
      "file information: UJuan 2 8 HardMult\n",
      "file information: UJuan 2 9 EasyAdd\n",
      "file information: UJuan 2 10 HardMult\n",
      "file information: UJuan 2 11 EasyAdd\n",
      "file information: UJuan 2 12 HardMult\n"
     ]
    }
   ],
   "source": [
    "dataPath = Path(r\"C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiments3-Data\\ArithmeticCalibrationProcedure\\edf\")\n",
    "X_arith, y_arith = createImageDataset(dataPath,imageSize=64,frameDuration=1,overlap=0.2,\n",
    "                          image_format=False, augment_data=False, labels = [\"EasyAdd\",\"HardMult\"],\n",
    "                          lstm_format=False, lstm_sequence_length=None,\n",
    "                         fileNameFormat=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arithmetic dataset size\n",
      "(2352, 90) (2352,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Arithmetic dataset size\", )\n",
    "print(X_arith.shape, y_arith.shape)\n",
    "\n",
    "# print(\"Inversion dataset size\", )\n",
    "# print(X.shape, y.shape)\n",
    "# showImages(X,y)\n",
    "\n",
    "# X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, TimeDistributed, Input, BatchNormalization, Softmax\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def createConvModel(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def createLstmModel(input_shape,num_classes, lstmLayers=2, lstmOutputSize=4.0,\n",
    "                  isBidirectional=1.0, inputLayerNeurons=64, inputLayerDropout=0.25):\n",
    "\n",
    "    dropoutRate = 0.45\n",
    "    \n",
    "    lstmLayers = int(lstmLayers)\n",
    "    lstmOutputSize =int(lstmOutputSize)\n",
    "    isBidirectional =int(isBidirectional)\n",
    "\n",
    "    # Input layer\n",
    "    networkInput = Input(shape=input_shape)\n",
    "    dropout1 = Dropout(rate=inputLayerDropout)(networkInput)\n",
    "\n",
    "    # First Hidden layer\n",
    "    hidden1 = Dense(inputLayerNeurons, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(rate=dropoutRate)(hidden1)\n",
    "    batchNorm1 = BatchNormalization()(dropout2)\n",
    "\n",
    "    out = batchNorm1\n",
    "    for i in range(1, lstmLayers+1):\n",
    "        retSeq = False if i == lstmLayers else True\n",
    "        lstmLayer = LSTM(lstmOutputSize, stateful=False, return_sequences=retSeq,\n",
    "                         dropout=dropoutRate, kernel_regularizer=regularizers.l2(0.05))\n",
    "        if isBidirectional:\n",
    "            out = Bidirectional(lstmLayer, merge_mode='concat')(out)\n",
    "        else:\n",
    "            out = lstmLayer(out)\n",
    "\n",
    "    hidden3 = Dense(num_classes, activation='linear')(out)\n",
    "    networkOutput = Softmax()(hidden3)\n",
    "\n",
    "    model1 = Model(inputs=networkInput, outputs=networkOutput)\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model1\n",
    "\n",
    "def createConvLstmModel(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape)))\n",
    "#     model.add(TimeDistributed(Conv2D(8, (3, 3), padding='same')))\n",
    "# #     model.add(Dropout(rate=0.3))\n",
    "#     model.add(TimeDistributed(Activation('relu')))\n",
    "#     model.add(Dropout(rate=0.3))\n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3))))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(45)))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    #LSTM layer\n",
    "    model.add(Bidirectional(LSTM(20, stateful=False, dropout=0.35)))\n",
    "    \n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                72010     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 82,176\n",
      "Trainable params: 82,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3, 90)]           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 90)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3, 64)             5824      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3, 64)             256       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 3, 8)              2208      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 8,722\n",
      "Trainable params: 8,594\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model summary\n",
    "testModel = createConvModel((32,32,3),2)\n",
    "testModel.summary()\n",
    "\n",
    "testModel = createLstmModel((3, 90),2)\n",
    "testModel.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train convolutional network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360,)\n",
      "x_train shape: (3360, 32, 32, 3)\n",
      "x_test shape: (840, 32, 32, 3)\n",
      "3360 train samples\n",
      "840 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=True)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 32, 32, 3)\n",
      "Global statistics\n",
      "0.20303775\n",
      "0.19670053\n",
      "Statistics per color\n",
      "[0.18281205 0.17406805 0.25223285]\n",
      "[0.17917745 0.17015097 0.22660296]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999998"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get dataset statistics\n",
    "print(x_train.shape)\n",
    "print(\"Global statistics\")\n",
    "print(x_train.mean())\n",
    "print(x_train.std())\n",
    "print(\"Statistics per color\")\n",
    "print(x_train.mean(axis=(0, 1,2)))\n",
    "print(x_train.std(axis=(0,1,2)))\n",
    "\n",
    "##Normalize the dataset\n",
    "\n",
    "##No normalization -- Seems to yield the best results \n",
    "# x_train_2 = x_train\n",
    "# x_test_2 = x_test\n",
    "\n",
    "##Method 1: Normalize with global mean and std\n",
    "global_mean = x_train.mean(); global_std = x_train.std();\n",
    "x_train_2 = (x_train - global_mean)/global_std;\n",
    "x_test_2 = (x_test - global_mean)/global_std;\n",
    "\n",
    "##Method 2: Normalize each color channel independently (e.g normalize the red channel with red mean accross all samples)\n",
    "# color_mean = x_train.mean(axis=(0, 1,2)); color_std = x_train.std(axis=(0, 1,2));\n",
    "# color_mean = np.expand_dims(color_mean,axis=(0,1,2))\n",
    "# x_train_2 = (x_train - color_mean)/color_std;\n",
    "# x_test_2 = (x_test - color_mean)/color_std;\n",
    "\n",
    "\n",
    "##Debug\n",
    "x_train_2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360,)\n",
      "(3360, 32, 32, 3)\n",
      "Train on 3360 samples, validate on 840 samples\n",
      "Epoch 1/400\n",
      "3360/3360 [==============================] - 3s 818us/sample - loss: 0.5991 - accuracy: 0.6625 - val_loss: 0.5982 - val_accuracy: 0.7012\n",
      "Epoch 2/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.5584 - accuracy: 0.6914 - val_loss: 0.5723 - val_accuracy: 0.6917\n",
      "Epoch 3/400\n",
      "3360/3360 [==============================] - 0s 95us/sample - loss: 0.5421 - accuracy: 0.7030 - val_loss: 0.5700 - val_accuracy: 0.7048\n",
      "Epoch 4/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.5290 - accuracy: 0.7164 - val_loss: 0.5388 - val_accuracy: 0.7143\n",
      "Epoch 5/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.5173 - accuracy: 0.7202 - val_loss: 0.5648 - val_accuracy: 0.7536\n",
      "Epoch 6/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.5126 - accuracy: 0.7262 - val_loss: 0.5368 - val_accuracy: 0.7440\n",
      "Epoch 7/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.4975 - accuracy: 0.7348 - val_loss: 0.5126 - val_accuracy: 0.7262\n",
      "Epoch 8/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4945 - accuracy: 0.7467 - val_loss: 0.5211 - val_accuracy: 0.7702\n",
      "Epoch 9/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4885 - accuracy: 0.7616 - val_loss: 0.5078 - val_accuracy: 0.7476\n",
      "Epoch 10/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4791 - accuracy: 0.7649 - val_loss: 0.5064 - val_accuracy: 0.7726\n",
      "Epoch 11/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.4733 - accuracy: 0.7625 - val_loss: 0.4930 - val_accuracy: 0.7679\n",
      "Epoch 12/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4715 - accuracy: 0.7714 - val_loss: 0.5078 - val_accuracy: 0.7690\n",
      "Epoch 13/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4700 - accuracy: 0.7765 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
      "Epoch 14/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4659 - accuracy: 0.7774 - val_loss: 0.4846 - val_accuracy: 0.7964\n",
      "Epoch 15/400\n",
      "3360/3360 [==============================] - 0s 96us/sample - loss: 0.4550 - accuracy: 0.7845 - val_loss: 0.4687 - val_accuracy: 0.7976\n",
      "Epoch 16/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.4450 - accuracy: 0.7955 - val_loss: 0.4694 - val_accuracy: 0.8060\n",
      "Epoch 17/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.4491 - accuracy: 0.7881 - val_loss: 0.4645 - val_accuracy: 0.7833\n",
      "Epoch 18/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4357 - accuracy: 0.7988 - val_loss: 0.4614 - val_accuracy: 0.8155\n",
      "Epoch 19/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4359 - accuracy: 0.7967 - val_loss: 0.4921 - val_accuracy: 0.8060\n",
      "Epoch 20/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7798\n",
      "Epoch 21/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4309 - accuracy: 0.8068 - val_loss: 0.4466 - val_accuracy: 0.8131\n",
      "Epoch 22/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.4238 - accuracy: 0.8083 - val_loss: 0.4615 - val_accuracy: 0.7893\n",
      "Epoch 23/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.4199 - accuracy: 0.8030 - val_loss: 0.4349 - val_accuracy: 0.8393\n",
      "Epoch 24/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4222 - accuracy: 0.8042 - val_loss: 0.4395 - val_accuracy: 0.8262\n",
      "Epoch 25/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4110 - accuracy: 0.8146 - val_loss: 0.4302 - val_accuracy: 0.8155\n",
      "Epoch 26/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.4104 - accuracy: 0.8057 - val_loss: 0.4231 - val_accuracy: 0.8238\n",
      "Epoch 27/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.4056 - accuracy: 0.8214 - val_loss: 0.4309 - val_accuracy: 0.8345\n",
      "Epoch 28/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4067 - accuracy: 0.8196 - val_loss: 0.4284 - val_accuracy: 0.8333\n",
      "Epoch 29/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.4020 - accuracy: 0.8211 - val_loss: 0.4405 - val_accuracy: 0.8179\n",
      "Epoch 30/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3982 - accuracy: 0.8250 - val_loss: 0.4300 - val_accuracy: 0.8310\n",
      "Epoch 31/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3934 - accuracy: 0.8226 - val_loss: 0.4263 - val_accuracy: 0.8107\n",
      "Epoch 32/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3955 - accuracy: 0.8202 - val_loss: 0.4127 - val_accuracy: 0.8369\n",
      "Epoch 33/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3882 - accuracy: 0.8244 - val_loss: 0.4103 - val_accuracy: 0.8381\n",
      "Epoch 34/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.3858 - accuracy: 0.8256 - val_loss: 0.3989 - val_accuracy: 0.8393\n",
      "Epoch 35/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3855 - accuracy: 0.8348 - val_loss: 0.4075 - val_accuracy: 0.8393\n",
      "Epoch 36/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3862 - accuracy: 0.8283 - val_loss: 0.4056 - val_accuracy: 0.8393\n",
      "Epoch 37/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3848 - accuracy: 0.8360 - val_loss: 0.3958 - val_accuracy: 0.8452\n",
      "Epoch 38/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3750 - accuracy: 0.8446 - val_loss: 0.4088 - val_accuracy: 0.8286\n",
      "Epoch 39/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3737 - accuracy: 0.8393 - val_loss: 0.3915 - val_accuracy: 0.8429\n",
      "Epoch 40/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3751 - accuracy: 0.8426 - val_loss: 0.3939 - val_accuracy: 0.8262\n",
      "Epoch 41/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3715 - accuracy: 0.8396 - val_loss: 0.4129 - val_accuracy: 0.8286\n",
      "Epoch 42/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3609 - accuracy: 0.8429 - val_loss: 0.3930 - val_accuracy: 0.8429\n",
      "Epoch 43/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3724 - accuracy: 0.8384 - val_loss: 0.4096 - val_accuracy: 0.8333\n",
      "Epoch 44/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3661 - accuracy: 0.8423 - val_loss: 0.3926 - val_accuracy: 0.8464\n",
      "Epoch 45/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3718 - accuracy: 0.8435 - val_loss: 0.4229 - val_accuracy: 0.8190\n",
      "Epoch 46/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3659 - accuracy: 0.8399 - val_loss: 0.3974 - val_accuracy: 0.8440\n",
      "Epoch 47/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3720 - accuracy: 0.8443 - val_loss: 0.3916 - val_accuracy: 0.8512\n",
      "Epoch 48/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3634 - accuracy: 0.8408 - val_loss: 0.3909 - val_accuracy: 0.8536\n",
      "Epoch 49/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3575 - accuracy: 0.8568 - val_loss: 0.4010 - val_accuracy: 0.8440\n",
      "Epoch 50/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3587 - accuracy: 0.8467 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 51/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3636 - accuracy: 0.8488 - val_loss: 0.3775 - val_accuracy: 0.8500\n",
      "Epoch 52/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3541 - accuracy: 0.8438 - val_loss: 0.3846 - val_accuracy: 0.8405\n",
      "Epoch 53/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3593 - accuracy: 0.8470 - val_loss: 0.4080 - val_accuracy: 0.8274\n",
      "Epoch 54/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3538 - accuracy: 0.8497 - val_loss: 0.3911 - val_accuracy: 0.8476\n",
      "Epoch 55/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3539 - accuracy: 0.8551 - val_loss: 0.3826 - val_accuracy: 0.8524\n",
      "Epoch 56/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3534 - accuracy: 0.8518 - val_loss: 0.3710 - val_accuracy: 0.8571\n",
      "Epoch 57/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3477 - accuracy: 0.8542 - val_loss: 0.3677 - val_accuracy: 0.8536\n",
      "Epoch 58/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3482 - accuracy: 0.8545 - val_loss: 0.3692 - val_accuracy: 0.8595\n",
      "Epoch 59/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3453 - accuracy: 0.8545 - val_loss: 0.3667 - val_accuracy: 0.8524\n",
      "Epoch 60/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3472 - accuracy: 0.8515 - val_loss: 0.3939 - val_accuracy: 0.8452\n",
      "Epoch 61/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3428 - accuracy: 0.8518 - val_loss: 0.3679 - val_accuracy: 0.8619\n",
      "Epoch 62/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3456 - accuracy: 0.8571 - val_loss: 0.3697 - val_accuracy: 0.8595\n",
      "Epoch 63/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3357 - accuracy: 0.8619 - val_loss: 0.3536 - val_accuracy: 0.8702\n",
      "Epoch 64/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3347 - accuracy: 0.8595 - val_loss: 0.3601 - val_accuracy: 0.8536\n",
      "Epoch 65/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3466 - accuracy: 0.8598 - val_loss: 0.3575 - val_accuracy: 0.8500\n",
      "Epoch 66/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3407 - accuracy: 0.8613 - val_loss: 0.3584 - val_accuracy: 0.8631\n",
      "Epoch 67/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3332 - accuracy: 0.8634 - val_loss: 0.3669 - val_accuracy: 0.8464\n",
      "Epoch 68/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3357 - accuracy: 0.8628 - val_loss: 0.3524 - val_accuracy: 0.8631\n",
      "Epoch 69/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3353 - accuracy: 0.8607 - val_loss: 0.3546 - val_accuracy: 0.8667\n",
      "Epoch 70/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3412 - accuracy: 0.8583 - val_loss: 0.3544 - val_accuracy: 0.8536\n",
      "Epoch 71/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3261 - accuracy: 0.8622 - val_loss: 0.3495 - val_accuracy: 0.8643\n",
      "Epoch 72/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3275 - accuracy: 0.8643 - val_loss: 0.3438 - val_accuracy: 0.8679\n",
      "Epoch 73/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.3323 - accuracy: 0.8622 - val_loss: 0.3499 - val_accuracy: 0.8726\n",
      "Epoch 74/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.3311 - accuracy: 0.8655 - val_loss: 0.3604 - val_accuracy: 0.8571\n",
      "Epoch 75/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3309 - accuracy: 0.8643 - val_loss: 0.3672 - val_accuracy: 0.8512\n",
      "Epoch 76/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.3277 - accuracy: 0.8696 - val_loss: 0.3414 - val_accuracy: 0.8667\n",
      "Epoch 77/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.3160 - accuracy: 0.8723 - val_loss: 0.3876 - val_accuracy: 0.8202\n",
      "Epoch 78/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.3227 - accuracy: 0.8637 - val_loss: 0.3618 - val_accuracy: 0.8679\n",
      "Epoch 79/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3215 - accuracy: 0.8664 - val_loss: 0.3407 - val_accuracy: 0.8619\n",
      "Epoch 80/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3227 - accuracy: 0.8655 - val_loss: 0.3478 - val_accuracy: 0.8631\n",
      "Epoch 81/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3218 - accuracy: 0.8726 - val_loss: 0.3380 - val_accuracy: 0.8655\n",
      "Epoch 82/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3192 - accuracy: 0.8732 - val_loss: 0.3451 - val_accuracy: 0.8631\n",
      "Epoch 83/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3305 - accuracy: 0.8670 - val_loss: 0.3490 - val_accuracy: 0.8690\n",
      "Epoch 84/400\n",
      "3360/3360 [==============================] - 0s 96us/sample - loss: 0.3166 - accuracy: 0.8652 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 85/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3187 - accuracy: 0.8696 - val_loss: 0.3498 - val_accuracy: 0.8631\n",
      "Epoch 86/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3138 - accuracy: 0.8729 - val_loss: 0.3536 - val_accuracy: 0.8500\n",
      "Epoch 87/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.3134 - accuracy: 0.8726 - val_loss: 0.3795 - val_accuracy: 0.8452\n",
      "Epoch 88/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3180 - accuracy: 0.8732 - val_loss: 0.3375 - val_accuracy: 0.8702\n",
      "Epoch 89/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3166 - accuracy: 0.8682 - val_loss: 0.3512 - val_accuracy: 0.8500\n",
      "Epoch 90/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3121 - accuracy: 0.8732 - val_loss: 0.3559 - val_accuracy: 0.8571\n",
      "Epoch 91/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2986 - accuracy: 0.8756 - val_loss: 0.3445 - val_accuracy: 0.8500\n",
      "Epoch 92/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3173 - accuracy: 0.8723 - val_loss: 0.3389 - val_accuracy: 0.8714\n",
      "Epoch 93/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3163 - accuracy: 0.8741 - val_loss: 0.3339 - val_accuracy: 0.8702\n",
      "Epoch 94/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3034 - accuracy: 0.8801 - val_loss: 0.3504 - val_accuracy: 0.8619\n",
      "Epoch 95/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3083 - accuracy: 0.8789 - val_loss: 0.3482 - val_accuracy: 0.8631\n",
      "Epoch 96/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3063 - accuracy: 0.8807 - val_loss: 0.3504 - val_accuracy: 0.8643\n",
      "Epoch 97/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3042 - accuracy: 0.8765 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
      "Epoch 98/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.3102 - accuracy: 0.8753 - val_loss: 0.3483 - val_accuracy: 0.8631\n",
      "Epoch 99/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3089 - accuracy: 0.8765 - val_loss: 0.3334 - val_accuracy: 0.8726\n",
      "Epoch 100/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3006 - accuracy: 0.8765 - val_loss: 0.3427 - val_accuracy: 0.8738\n",
      "Epoch 101/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.3062 - accuracy: 0.8810 - val_loss: 0.3260 - val_accuracy: 0.8750\n",
      "Epoch 102/400\n",
      "3360/3360 [==============================] - 0s 95us/sample - loss: 0.3033 - accuracy: 0.8815 - val_loss: 0.3512 - val_accuracy: 0.8440\n",
      "Epoch 103/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2984 - accuracy: 0.8824 - val_loss: 0.3557 - val_accuracy: 0.8500\n",
      "Epoch 104/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3036 - accuracy: 0.8756 - val_loss: 0.3316 - val_accuracy: 0.8750\n",
      "Epoch 105/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2974 - accuracy: 0.8813 - val_loss: 0.3516 - val_accuracy: 0.8667\n",
      "Epoch 106/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2924 - accuracy: 0.8839 - val_loss: 0.3631 - val_accuracy: 0.8429\n",
      "Epoch 107/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.3117 - accuracy: 0.8735 - val_loss: 0.3422 - val_accuracy: 0.8679\n",
      "Epoch 108/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2844 - accuracy: 0.8869 - val_loss: 0.3488 - val_accuracy: 0.8679\n",
      "Epoch 109/400\n",
      "3360/3360 [==============================] - 0s 96us/sample - loss: 0.2947 - accuracy: 0.8845 - val_loss: 0.3257 - val_accuracy: 0.8774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.3045 - accuracy: 0.8792 - val_loss: 0.3404 - val_accuracy: 0.8738\n",
      "Epoch 111/400\n",
      "3360/3360 [==============================] - 0s 96us/sample - loss: 0.2916 - accuracy: 0.8830 - val_loss: 0.3225 - val_accuracy: 0.8786\n",
      "Epoch 112/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2970 - accuracy: 0.8836 - val_loss: 0.3428 - val_accuracy: 0.8690\n",
      "Epoch 113/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2984 - accuracy: 0.8821 - val_loss: 0.3815 - val_accuracy: 0.8179\n",
      "Epoch 114/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2916 - accuracy: 0.8866 - val_loss: 0.3628 - val_accuracy: 0.8476\n",
      "Epoch 115/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2963 - accuracy: 0.8869 - val_loss: 0.3691 - val_accuracy: 0.8262\n",
      "Epoch 116/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2961 - accuracy: 0.8830 - val_loss: 0.3386 - val_accuracy: 0.8690\n",
      "Epoch 117/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2969 - accuracy: 0.8866 - val_loss: 0.3247 - val_accuracy: 0.8726\n",
      "Epoch 118/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2956 - accuracy: 0.8789 - val_loss: 0.3330 - val_accuracy: 0.8738\n",
      "Epoch 119/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2899 - accuracy: 0.8923 - val_loss: 0.3622 - val_accuracy: 0.8345\n",
      "Epoch 120/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2887 - accuracy: 0.8824 - val_loss: 0.3107 - val_accuracy: 0.8810\n",
      "Epoch 121/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2828 - accuracy: 0.8848 - val_loss: 0.3070 - val_accuracy: 0.8786\n",
      "Epoch 122/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2913 - accuracy: 0.8854 - val_loss: 0.3070 - val_accuracy: 0.8821\n",
      "Epoch 123/400\n",
      "3360/3360 [==============================] - 0s 96us/sample - loss: 0.2974 - accuracy: 0.8795 - val_loss: 0.3194 - val_accuracy: 0.8833\n",
      "Epoch 124/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2896 - accuracy: 0.8854 - val_loss: 0.3101 - val_accuracy: 0.8750\n",
      "Epoch 125/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2875 - accuracy: 0.8866 - val_loss: 0.3462 - val_accuracy: 0.8560\n",
      "Epoch 126/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2832 - accuracy: 0.8881 - val_loss: 0.3026 - val_accuracy: 0.8845\n",
      "Epoch 127/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2840 - accuracy: 0.8860 - val_loss: 0.3104 - val_accuracy: 0.8738\n",
      "Epoch 128/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2850 - accuracy: 0.8914 - val_loss: 0.3104 - val_accuracy: 0.8786\n",
      "Epoch 129/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2859 - accuracy: 0.8917 - val_loss: 0.3185 - val_accuracy: 0.8750\n",
      "Epoch 130/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2790 - accuracy: 0.8902 - val_loss: 0.3207 - val_accuracy: 0.8738\n",
      "Epoch 131/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2858 - accuracy: 0.8857 - val_loss: 0.3142 - val_accuracy: 0.8762\n",
      "Epoch 132/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2843 - accuracy: 0.8935 - val_loss: 0.3084 - val_accuracy: 0.8786\n",
      "Epoch 133/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2866 - accuracy: 0.8839 - val_loss: 0.3561 - val_accuracy: 0.8452\n",
      "Epoch 134/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2806 - accuracy: 0.8905 - val_loss: 0.3475 - val_accuracy: 0.8536\n",
      "Epoch 135/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2785 - accuracy: 0.8917 - val_loss: 0.3075 - val_accuracy: 0.8798\n",
      "Epoch 136/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2791 - accuracy: 0.8842 - val_loss: 0.3515 - val_accuracy: 0.8381\n",
      "Epoch 137/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2750 - accuracy: 0.8857 - val_loss: 0.3771 - val_accuracy: 0.8238\n",
      "Epoch 138/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2760 - accuracy: 0.8932 - val_loss: 0.3422 - val_accuracy: 0.8690\n",
      "Epoch 139/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2744 - accuracy: 0.8955 - val_loss: 0.3248 - val_accuracy: 0.8750\n",
      "Epoch 140/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2707 - accuracy: 0.8967 - val_loss: 0.3327 - val_accuracy: 0.8643\n",
      "Epoch 141/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2851 - accuracy: 0.8893 - val_loss: 0.3201 - val_accuracy: 0.8738\n",
      "Epoch 142/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2687 - accuracy: 0.8970 - val_loss: 0.3122 - val_accuracy: 0.8821\n",
      "Epoch 143/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2714 - accuracy: 0.8908 - val_loss: 0.3319 - val_accuracy: 0.8726\n",
      "Epoch 144/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2726 - accuracy: 0.8964 - val_loss: 0.3124 - val_accuracy: 0.8798\n",
      "Epoch 145/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2753 - accuracy: 0.8881 - val_loss: 0.3398 - val_accuracy: 0.8679\n",
      "Epoch 146/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2682 - accuracy: 0.8938 - val_loss: 0.3733 - val_accuracy: 0.8274\n",
      "Epoch 147/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2710 - accuracy: 0.8958 - val_loss: 0.3570 - val_accuracy: 0.8333\n",
      "Epoch 148/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2791 - accuracy: 0.8961 - val_loss: 0.2955 - val_accuracy: 0.8845\n",
      "Epoch 149/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2614 - accuracy: 0.8979 - val_loss: 0.3207 - val_accuracy: 0.8798\n",
      "Epoch 150/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2659 - accuracy: 0.8985 - val_loss: 0.3192 - val_accuracy: 0.8690\n",
      "Epoch 151/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2777 - accuracy: 0.8893 - val_loss: 0.3215 - val_accuracy: 0.8893\n",
      "Epoch 152/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2653 - accuracy: 0.8929 - val_loss: 0.3154 - val_accuracy: 0.8845\n",
      "Epoch 153/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2738 - accuracy: 0.8881 - val_loss: 0.3112 - val_accuracy: 0.8821\n",
      "Epoch 154/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2633 - accuracy: 0.8982 - val_loss: 0.3167 - val_accuracy: 0.8726\n",
      "Epoch 155/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2667 - accuracy: 0.8961 - val_loss: 0.3200 - val_accuracy: 0.8821\n",
      "Epoch 156/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2676 - accuracy: 0.8923 - val_loss: 0.3274 - val_accuracy: 0.8810\n",
      "Epoch 157/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2714 - accuracy: 0.8920 - val_loss: 0.3159 - val_accuracy: 0.8774\n",
      "Epoch 158/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2598 - accuracy: 0.9045 - val_loss: 0.2989 - val_accuracy: 0.8929\n",
      "Epoch 159/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2651 - accuracy: 0.8958 - val_loss: 0.3026 - val_accuracy: 0.8869\n",
      "Epoch 160/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2641 - accuracy: 0.8955 - val_loss: 0.2953 - val_accuracy: 0.8833\n",
      "Epoch 161/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2577 - accuracy: 0.8976 - val_loss: 0.3090 - val_accuracy: 0.8833\n",
      "Epoch 162/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2602 - accuracy: 0.8985 - val_loss: 0.3677 - val_accuracy: 0.8262\n",
      "Epoch 163/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2644 - accuracy: 0.8949 - val_loss: 0.3201 - val_accuracy: 0.8702\n",
      "Epoch 164/400\n",
      "3360/3360 [==============================] - 0s 103us/sample - loss: 0.2641 - accuracy: 0.8985 - val_loss: 0.2996 - val_accuracy: 0.8833\n",
      "Epoch 165/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2600 - accuracy: 0.8932 - val_loss: 0.2944 - val_accuracy: 0.8833\n",
      "Epoch 166/400\n",
      "3360/3360 [==============================] - 0s 102us/sample - loss: 0.2636 - accuracy: 0.8991 - val_loss: 0.3320 - val_accuracy: 0.8571\n",
      "Epoch 167/400\n",
      "3360/3360 [==============================] - 0s 103us/sample - loss: 0.2520 - accuracy: 0.8952 - val_loss: 0.3511 - val_accuracy: 0.8464\n",
      "Epoch 168/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2620 - accuracy: 0.8970 - val_loss: 0.3002 - val_accuracy: 0.8881\n",
      "Epoch 169/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2575 - accuracy: 0.8949 - val_loss: 0.3149 - val_accuracy: 0.8786\n",
      "Epoch 170/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2567 - accuracy: 0.8967 - val_loss: 0.3158 - val_accuracy: 0.8833\n",
      "Epoch 171/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2549 - accuracy: 0.8973 - val_loss: 0.3520 - val_accuracy: 0.8333\n",
      "Epoch 172/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2580 - accuracy: 0.8985 - val_loss: 0.3266 - val_accuracy: 0.8738\n",
      "Epoch 173/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2525 - accuracy: 0.8973 - val_loss: 0.3376 - val_accuracy: 0.8595\n",
      "Epoch 174/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2493 - accuracy: 0.9086 - val_loss: 0.2998 - val_accuracy: 0.8810\n",
      "Epoch 175/400\n",
      "3360/3360 [==============================] - 0s 96us/sample - loss: 0.2520 - accuracy: 0.8988 - val_loss: 0.3029 - val_accuracy: 0.8845\n",
      "Epoch 176/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2547 - accuracy: 0.8970 - val_loss: 0.3386 - val_accuracy: 0.8583\n",
      "Epoch 177/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2491 - accuracy: 0.9027 - val_loss: 0.2925 - val_accuracy: 0.8869\n",
      "Epoch 178/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2440 - accuracy: 0.9060 - val_loss: 0.3348 - val_accuracy: 0.8583\n",
      "Epoch 179/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2498 - accuracy: 0.9080 - val_loss: 0.3652 - val_accuracy: 0.8202\n",
      "Epoch 180/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2462 - accuracy: 0.9018 - val_loss: 0.3027 - val_accuracy: 0.8905\n",
      "Epoch 181/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2521 - accuracy: 0.9039 - val_loss: 0.3114 - val_accuracy: 0.8714\n",
      "Epoch 182/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2490 - accuracy: 0.9051 - val_loss: 0.3004 - val_accuracy: 0.8798\n",
      "Epoch 183/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2482 - accuracy: 0.9027 - val_loss: 0.3680 - val_accuracy: 0.8226\n",
      "Epoch 184/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2501 - accuracy: 0.9030 - val_loss: 0.3164 - val_accuracy: 0.8655\n",
      "Epoch 185/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2440 - accuracy: 0.9042 - val_loss: 0.2915 - val_accuracy: 0.8869\n",
      "Epoch 186/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2457 - accuracy: 0.8997 - val_loss: 0.3342 - val_accuracy: 0.8571\n",
      "Epoch 187/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2501 - accuracy: 0.9036 - val_loss: 0.2811 - val_accuracy: 0.8964\n",
      "Epoch 188/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2434 - accuracy: 0.9048 - val_loss: 0.3121 - val_accuracy: 0.8845\n",
      "Epoch 189/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2483 - accuracy: 0.9080 - val_loss: 0.2938 - val_accuracy: 0.8821\n",
      "Epoch 190/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2461 - accuracy: 0.8991 - val_loss: 0.3558 - val_accuracy: 0.8393\n",
      "Epoch 191/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2451 - accuracy: 0.9062 - val_loss: 0.2888 - val_accuracy: 0.8821\n",
      "Epoch 192/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2429 - accuracy: 0.9080 - val_loss: 0.3343 - val_accuracy: 0.8607\n",
      "Epoch 193/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2379 - accuracy: 0.9107 - val_loss: 0.2952 - val_accuracy: 0.8893\n",
      "Epoch 194/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2447 - accuracy: 0.9068 - val_loss: 0.3061 - val_accuracy: 0.8845\n",
      "Epoch 195/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2493 - accuracy: 0.9068 - val_loss: 0.2819 - val_accuracy: 0.8893\n",
      "Epoch 196/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2400 - accuracy: 0.9062 - val_loss: 0.3372 - val_accuracy: 0.8476\n",
      "Epoch 197/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2420 - accuracy: 0.9042 - val_loss: 0.3642 - val_accuracy: 0.8298\n",
      "Epoch 198/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2409 - accuracy: 0.9060 - val_loss: 0.2901 - val_accuracy: 0.8857\n",
      "Epoch 199/400\n",
      "3360/3360 [==============================] - 0s 102us/sample - loss: 0.2377 - accuracy: 0.9042 - val_loss: 0.2915 - val_accuracy: 0.8845\n",
      "Epoch 200/400\n",
      "3360/3360 [==============================] - 0s 104us/sample - loss: 0.2458 - accuracy: 0.9045 - val_loss: 0.3242 - val_accuracy: 0.8643\n",
      "Epoch 201/400\n",
      "3360/3360 [==============================] - 0s 103us/sample - loss: 0.2366 - accuracy: 0.9077 - val_loss: 0.2793 - val_accuracy: 0.8940\n",
      "Epoch 202/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2432 - accuracy: 0.9062 - val_loss: 0.3188 - val_accuracy: 0.8655\n",
      "Epoch 203/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2383 - accuracy: 0.9045 - val_loss: 0.2993 - val_accuracy: 0.8798\n",
      "Epoch 204/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2399 - accuracy: 0.9051 - val_loss: 0.2946 - val_accuracy: 0.8833\n",
      "Epoch 205/400\n",
      "3360/3360 [==============================] - 0s 102us/sample - loss: 0.2463 - accuracy: 0.9125 - val_loss: 0.3258 - val_accuracy: 0.8702\n",
      "Epoch 206/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2353 - accuracy: 0.9119 - val_loss: 0.3097 - val_accuracy: 0.8726\n",
      "Epoch 207/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2356 - accuracy: 0.9054 - val_loss: 0.2911 - val_accuracy: 0.8869\n",
      "Epoch 208/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2305 - accuracy: 0.9119 - val_loss: 0.2969 - val_accuracy: 0.8786\n",
      "Epoch 209/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2411 - accuracy: 0.9018 - val_loss: 0.3473 - val_accuracy: 0.8393\n",
      "Epoch 210/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2371 - accuracy: 0.9101 - val_loss: 0.2827 - val_accuracy: 0.8952\n",
      "Epoch 211/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2318 - accuracy: 0.9167 - val_loss: 0.2768 - val_accuracy: 0.8976\n",
      "Epoch 212/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2324 - accuracy: 0.9101 - val_loss: 0.3245 - val_accuracy: 0.8655\n",
      "Epoch 213/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2426 - accuracy: 0.9071 - val_loss: 0.3186 - val_accuracy: 0.8726\n",
      "Epoch 214/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2318 - accuracy: 0.9065 - val_loss: 0.2940 - val_accuracy: 0.8726\n",
      "Epoch 215/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2302 - accuracy: 0.9146 - val_loss: 0.2780 - val_accuracy: 0.9000\n",
      "Epoch 216/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2266 - accuracy: 0.9128 - val_loss: 0.3064 - val_accuracy: 0.8679\n",
      "Epoch 217/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2387 - accuracy: 0.9068 - val_loss: 0.3072 - val_accuracy: 0.8762\n",
      "Epoch 218/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2248 - accuracy: 0.9086 - val_loss: 0.2944 - val_accuracy: 0.8786\n",
      "Epoch 219/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2314 - accuracy: 0.9107 - val_loss: 0.3238 - val_accuracy: 0.8524\n",
      "Epoch 220/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2408 - accuracy: 0.9080 - val_loss: 0.2945 - val_accuracy: 0.8869\n",
      "Epoch 221/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2189 - accuracy: 0.9143 - val_loss: 0.3000 - val_accuracy: 0.8750\n",
      "Epoch 222/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2373 - accuracy: 0.9071 - val_loss: 0.2884 - val_accuracy: 0.8881\n",
      "Epoch 223/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2219 - accuracy: 0.9155 - val_loss: 0.2908 - val_accuracy: 0.8881\n",
      "Epoch 224/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2292 - accuracy: 0.9089 - val_loss: 0.2918 - val_accuracy: 0.8869\n",
      "Epoch 225/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2310 - accuracy: 0.9048 - val_loss: 0.3042 - val_accuracy: 0.8774\n",
      "Epoch 226/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2267 - accuracy: 0.9119 - val_loss: 0.3283 - val_accuracy: 0.8464\n",
      "Epoch 227/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2274 - accuracy: 0.9110 - val_loss: 0.3118 - val_accuracy: 0.8702\n",
      "Epoch 228/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2322 - accuracy: 0.9033 - val_loss: 0.3196 - val_accuracy: 0.8571\n",
      "Epoch 229/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2276 - accuracy: 0.9080 - val_loss: 0.2889 - val_accuracy: 0.8917\n",
      "Epoch 230/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2277 - accuracy: 0.9161 - val_loss: 0.3349 - val_accuracy: 0.8500\n",
      "Epoch 231/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2246 - accuracy: 0.9167 - val_loss: 0.2896 - val_accuracy: 0.8845\n",
      "Epoch 232/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2318 - accuracy: 0.9107 - val_loss: 0.3098 - val_accuracy: 0.8833\n",
      "Epoch 233/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2309 - accuracy: 0.9092 - val_loss: 0.2985 - val_accuracy: 0.8786\n",
      "Epoch 234/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2271 - accuracy: 0.9128 - val_loss: 0.2840 - val_accuracy: 0.8905\n",
      "Epoch 235/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2179 - accuracy: 0.9116 - val_loss: 0.3008 - val_accuracy: 0.8786\n",
      "Epoch 236/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2222 - accuracy: 0.9131 - val_loss: 0.3292 - val_accuracy: 0.8476\n",
      "Epoch 237/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2227 - accuracy: 0.9137 - val_loss: 0.3388 - val_accuracy: 0.8452\n",
      "Epoch 238/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2267 - accuracy: 0.9140 - val_loss: 0.3082 - val_accuracy: 0.8643\n",
      "Epoch 239/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2231 - accuracy: 0.9107 - val_loss: 0.3179 - val_accuracy: 0.8702\n",
      "Epoch 240/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2284 - accuracy: 0.9125 - val_loss: 0.2810 - val_accuracy: 0.8857\n",
      "Epoch 241/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2256 - accuracy: 0.9158 - val_loss: 0.2924 - val_accuracy: 0.8786\n",
      "Epoch 242/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2207 - accuracy: 0.9143 - val_loss: 0.2921 - val_accuracy: 0.8869\n",
      "Epoch 243/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2237 - accuracy: 0.9119 - val_loss: 0.3288 - val_accuracy: 0.8440\n",
      "Epoch 244/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2220 - accuracy: 0.9176 - val_loss: 0.3518 - val_accuracy: 0.8202\n",
      "Epoch 245/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2187 - accuracy: 0.9086 - val_loss: 0.2752 - val_accuracy: 0.8869\n",
      "Epoch 246/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2204 - accuracy: 0.9131 - val_loss: 0.3121 - val_accuracy: 0.8595\n",
      "Epoch 247/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2229 - accuracy: 0.9134 - val_loss: 0.2817 - val_accuracy: 0.8976\n",
      "Epoch 248/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2231 - accuracy: 0.9143 - val_loss: 0.3269 - val_accuracy: 0.8500\n",
      "Epoch 249/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2198 - accuracy: 0.9167 - val_loss: 0.3018 - val_accuracy: 0.8774\n",
      "Epoch 250/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2142 - accuracy: 0.9164 - val_loss: 0.2821 - val_accuracy: 0.8917\n",
      "Epoch 251/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2215 - accuracy: 0.9143 - val_loss: 0.3131 - val_accuracy: 0.8607\n",
      "Epoch 252/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2184 - accuracy: 0.9185 - val_loss: 0.2865 - val_accuracy: 0.8845\n",
      "Epoch 253/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2203 - accuracy: 0.9146 - val_loss: 0.3043 - val_accuracy: 0.8750\n",
      "Epoch 254/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2157 - accuracy: 0.9092 - val_loss: 0.3166 - val_accuracy: 0.8679\n",
      "Epoch 255/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2070 - accuracy: 0.9214 - val_loss: 0.3477 - val_accuracy: 0.8274\n",
      "Epoch 256/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2166 - accuracy: 0.9143 - val_loss: 0.2831 - val_accuracy: 0.8821\n",
      "Epoch 257/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2194 - accuracy: 0.9137 - val_loss: 0.2899 - val_accuracy: 0.8845\n",
      "Epoch 258/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2207 - accuracy: 0.9214 - val_loss: 0.3066 - val_accuracy: 0.8750\n",
      "Epoch 259/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2128 - accuracy: 0.9185 - val_loss: 0.3873 - val_accuracy: 0.7869\n",
      "Epoch 260/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2171 - accuracy: 0.9164 - val_loss: 0.2894 - val_accuracy: 0.8833\n",
      "Epoch 261/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2136 - accuracy: 0.9220 - val_loss: 0.3132 - val_accuracy: 0.8631\n",
      "Epoch 262/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2086 - accuracy: 0.9193 - val_loss: 0.2900 - val_accuracy: 0.8833\n",
      "Epoch 263/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2175 - accuracy: 0.9170 - val_loss: 0.2882 - val_accuracy: 0.8905\n",
      "Epoch 264/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2082 - accuracy: 0.9193 - val_loss: 0.2796 - val_accuracy: 0.8798\n",
      "Epoch 265/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2077 - accuracy: 0.9238 - val_loss: 0.3233 - val_accuracy: 0.8464\n",
      "Epoch 266/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2096 - accuracy: 0.9223 - val_loss: 0.2652 - val_accuracy: 0.8917\n",
      "Epoch 267/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2154 - accuracy: 0.9143 - val_loss: 0.2752 - val_accuracy: 0.8845\n",
      "Epoch 268/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2188 - accuracy: 0.9152 - val_loss: 0.2743 - val_accuracy: 0.8940\n",
      "Epoch 269/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2071 - accuracy: 0.9199 - val_loss: 0.3205 - val_accuracy: 0.8702\n",
      "Epoch 270/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2035 - accuracy: 0.9220 - val_loss: 0.3227 - val_accuracy: 0.8417\n",
      "Epoch 271/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2127 - accuracy: 0.9182 - val_loss: 0.3058 - val_accuracy: 0.8643\n",
      "Epoch 272/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2104 - accuracy: 0.9176 - val_loss: 0.3207 - val_accuracy: 0.8536\n",
      "Epoch 273/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.2092 - accuracy: 0.9235 - val_loss: 0.2852 - val_accuracy: 0.8821\n",
      "Epoch 274/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2153 - accuracy: 0.9202 - val_loss: 0.3263 - val_accuracy: 0.8476\n",
      "Epoch 275/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2102 - accuracy: 0.9244 - val_loss: 0.3052 - val_accuracy: 0.8750\n",
      "Epoch 276/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2125 - accuracy: 0.9193 - val_loss: 0.2757 - val_accuracy: 0.8893\n",
      "Epoch 277/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2105 - accuracy: 0.9187 - val_loss: 0.2934 - val_accuracy: 0.8714\n",
      "Epoch 278/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2031 - accuracy: 0.9253 - val_loss: 0.2866 - val_accuracy: 0.8810\n",
      "Epoch 279/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2116 - accuracy: 0.9149 - val_loss: 0.2724 - val_accuracy: 0.8976\n",
      "Epoch 280/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2063 - accuracy: 0.9205 - val_loss: 0.3129 - val_accuracy: 0.8619\n",
      "Epoch 281/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.2078 - accuracy: 0.9190 - val_loss: 0.2903 - val_accuracy: 0.8786\n",
      "Epoch 282/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.2090 - accuracy: 0.9170 - val_loss: 0.3271 - val_accuracy: 0.8476\n",
      "Epoch 283/400\n",
      "3360/3360 [==============================] - 0s 103us/sample - loss: 0.2119 - accuracy: 0.9214 - val_loss: 0.2940 - val_accuracy: 0.8833\n",
      "Epoch 284/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1997 - accuracy: 0.9158 - val_loss: 0.2637 - val_accuracy: 0.8917\n",
      "Epoch 285/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2036 - accuracy: 0.9214 - val_loss: 0.2957 - val_accuracy: 0.8810\n",
      "Epoch 286/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2049 - accuracy: 0.9247 - val_loss: 0.3031 - val_accuracy: 0.8774\n",
      "Epoch 287/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1937 - accuracy: 0.9265 - val_loss: 0.2742 - val_accuracy: 0.8881\n",
      "Epoch 288/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2014 - accuracy: 0.9211 - val_loss: 0.3139 - val_accuracy: 0.8619\n",
      "Epoch 289/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2089 - accuracy: 0.9170 - val_loss: 0.2810 - val_accuracy: 0.8881\n",
      "Epoch 290/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2090 - accuracy: 0.9238 - val_loss: 0.2928 - val_accuracy: 0.8857\n",
      "Epoch 291/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2006 - accuracy: 0.9176 - val_loss: 0.3049 - val_accuracy: 0.8702\n",
      "Epoch 292/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2055 - accuracy: 0.9223 - val_loss: 0.3067 - val_accuracy: 0.8690\n",
      "Epoch 293/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2005 - accuracy: 0.9232 - val_loss: 0.2920 - val_accuracy: 0.8833\n",
      "Epoch 294/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.2058 - accuracy: 0.9202 - val_loss: 0.2686 - val_accuracy: 0.8869\n",
      "Epoch 295/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1993 - accuracy: 0.9182 - val_loss: 0.2924 - val_accuracy: 0.8786\n",
      "Epoch 296/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1948 - accuracy: 0.9244 - val_loss: 0.3015 - val_accuracy: 0.8738\n",
      "Epoch 297/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1967 - accuracy: 0.9229 - val_loss: 0.3029 - val_accuracy: 0.8690\n",
      "Epoch 298/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1985 - accuracy: 0.9244 - val_loss: 0.2765 - val_accuracy: 0.8881\n",
      "Epoch 299/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1883 - accuracy: 0.9235 - val_loss: 0.2764 - val_accuracy: 0.8810\n",
      "Epoch 300/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.2008 - accuracy: 0.9199 - val_loss: 0.2984 - val_accuracy: 0.8714\n",
      "Epoch 301/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1982 - accuracy: 0.9262 - val_loss: 0.3450 - val_accuracy: 0.8298\n",
      "Epoch 302/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1999 - accuracy: 0.9193 - val_loss: 0.3459 - val_accuracy: 0.8250\n",
      "Epoch 303/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1955 - accuracy: 0.9301 - val_loss: 0.2688 - val_accuracy: 0.8893\n",
      "Epoch 304/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1963 - accuracy: 0.9286 - val_loss: 0.2807 - val_accuracy: 0.8810\n",
      "Epoch 305/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1962 - accuracy: 0.9250 - val_loss: 0.3340 - val_accuracy: 0.8417\n",
      "Epoch 306/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1930 - accuracy: 0.9196 - val_loss: 0.3235 - val_accuracy: 0.8417\n",
      "Epoch 307/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1961 - accuracy: 0.9262 - val_loss: 0.3440 - val_accuracy: 0.8179\n",
      "Epoch 308/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1937 - accuracy: 0.9253 - val_loss: 0.3055 - val_accuracy: 0.8667\n",
      "Epoch 309/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1919 - accuracy: 0.9315 - val_loss: 0.3053 - val_accuracy: 0.8702\n",
      "Epoch 310/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1840 - accuracy: 0.9259 - val_loss: 0.2682 - val_accuracy: 0.8976\n",
      "Epoch 311/400\n",
      "3360/3360 [==============================] - 0s 104us/sample - loss: 0.1991 - accuracy: 0.9277 - val_loss: 0.3162 - val_accuracy: 0.8536\n",
      "Epoch 312/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1978 - accuracy: 0.9229 - val_loss: 0.2641 - val_accuracy: 0.9024\n",
      "Epoch 313/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1863 - accuracy: 0.9312 - val_loss: 0.2922 - val_accuracy: 0.8786\n",
      "Epoch 314/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1934 - accuracy: 0.9277 - val_loss: 0.3054 - val_accuracy: 0.8643\n",
      "Epoch 315/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1922 - accuracy: 0.9262 - val_loss: 0.3141 - val_accuracy: 0.8464\n",
      "Epoch 316/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1922 - accuracy: 0.9250 - val_loss: 0.2661 - val_accuracy: 0.8929\n",
      "Epoch 317/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1937 - accuracy: 0.9277 - val_loss: 0.2871 - val_accuracy: 0.8798\n",
      "Epoch 318/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1910 - accuracy: 0.9307 - val_loss: 0.2962 - val_accuracy: 0.8714\n",
      "Epoch 319/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1931 - accuracy: 0.9318 - val_loss: 0.2796 - val_accuracy: 0.8798\n",
      "Epoch 320/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1886 - accuracy: 0.9312 - val_loss: 0.2912 - val_accuracy: 0.8810\n",
      "Epoch 321/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1896 - accuracy: 0.9283 - val_loss: 0.3168 - val_accuracy: 0.8417\n",
      "Epoch 322/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1937 - accuracy: 0.9277 - val_loss: 0.3055 - val_accuracy: 0.8548\n",
      "Epoch 323/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1914 - accuracy: 0.9265 - val_loss: 0.2999 - val_accuracy: 0.8667\n",
      "Epoch 324/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1825 - accuracy: 0.9298 - val_loss: 0.2683 - val_accuracy: 0.8964\n",
      "Epoch 325/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1851 - accuracy: 0.9354 - val_loss: 0.2882 - val_accuracy: 0.8774\n",
      "Epoch 326/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1812 - accuracy: 0.9315 - val_loss: 0.3223 - val_accuracy: 0.8440\n",
      "Epoch 327/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1850 - accuracy: 0.9259 - val_loss: 0.3070 - val_accuracy: 0.8583\n",
      "Epoch 328/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1835 - accuracy: 0.9298 - val_loss: 0.2858 - val_accuracy: 0.8738\n",
      "Epoch 329/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1880 - accuracy: 0.9327 - val_loss: 0.2726 - val_accuracy: 0.8929\n",
      "Epoch 330/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1841 - accuracy: 0.9312 - val_loss: 0.2613 - val_accuracy: 0.8976\n",
      "Epoch 331/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.1836 - accuracy: 0.9315 - val_loss: 0.3157 - val_accuracy: 0.8548\n",
      "Epoch 332/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1791 - accuracy: 0.9327 - val_loss: 0.3071 - val_accuracy: 0.8607\n",
      "Epoch 333/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1899 - accuracy: 0.9238 - val_loss: 0.2747 - val_accuracy: 0.8810\n",
      "Epoch 334/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1862 - accuracy: 0.9310 - val_loss: 0.3148 - val_accuracy: 0.8631\n",
      "Epoch 335/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.1871 - accuracy: 0.9286 - val_loss: 0.2702 - val_accuracy: 0.8940\n",
      "Epoch 336/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1868 - accuracy: 0.9244 - val_loss: 0.3139 - val_accuracy: 0.8488\n",
      "Epoch 337/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1892 - accuracy: 0.9295 - val_loss: 0.3347 - val_accuracy: 0.8250\n",
      "Epoch 338/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1801 - accuracy: 0.9295 - val_loss: 0.2688 - val_accuracy: 0.8857\n",
      "Epoch 339/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1949 - accuracy: 0.9256 - val_loss: 0.2939 - val_accuracy: 0.8786\n",
      "Epoch 340/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.1879 - accuracy: 0.9268 - val_loss: 0.3084 - val_accuracy: 0.8524\n",
      "Epoch 341/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1904 - accuracy: 0.9271 - val_loss: 0.3188 - val_accuracy: 0.8381\n",
      "Epoch 342/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1790 - accuracy: 0.9304 - val_loss: 0.2826 - val_accuracy: 0.8762\n",
      "Epoch 343/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1770 - accuracy: 0.9351 - val_loss: 0.2766 - val_accuracy: 0.8857\n",
      "Epoch 344/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1712 - accuracy: 0.9357 - val_loss: 0.2920 - val_accuracy: 0.8655\n",
      "Epoch 345/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1803 - accuracy: 0.9304 - val_loss: 0.2745 - val_accuracy: 0.8857\n",
      "Epoch 346/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1865 - accuracy: 0.9289 - val_loss: 0.3166 - val_accuracy: 0.8429\n",
      "Epoch 347/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1798 - accuracy: 0.9289 - val_loss: 0.2571 - val_accuracy: 0.8905\n",
      "Epoch 348/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1743 - accuracy: 0.9342 - val_loss: 0.3491 - val_accuracy: 0.8060\n",
      "Epoch 349/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1828 - accuracy: 0.9289 - val_loss: 0.2936 - val_accuracy: 0.8750\n",
      "Epoch 350/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1940 - accuracy: 0.9295 - val_loss: 0.2860 - val_accuracy: 0.8714\n",
      "Epoch 351/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1772 - accuracy: 0.9363 - val_loss: 0.2890 - val_accuracy: 0.8679\n",
      "Epoch 352/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1790 - accuracy: 0.9268 - val_loss: 0.3088 - val_accuracy: 0.8560\n",
      "Epoch 353/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1701 - accuracy: 0.9387 - val_loss: 0.2860 - val_accuracy: 0.8798\n",
      "Epoch 354/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1793 - accuracy: 0.9307 - val_loss: 0.2749 - val_accuracy: 0.8881\n",
      "Epoch 355/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1842 - accuracy: 0.9289 - val_loss: 0.3038 - val_accuracy: 0.8500\n",
      "Epoch 356/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1821 - accuracy: 0.9310 - val_loss: 0.2874 - val_accuracy: 0.8750\n",
      "Epoch 357/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1776 - accuracy: 0.9369 - val_loss: 0.3462 - val_accuracy: 0.8083\n",
      "Epoch 358/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1745 - accuracy: 0.9345 - val_loss: 0.3204 - val_accuracy: 0.8357\n",
      "Epoch 359/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1712 - accuracy: 0.9354 - val_loss: 0.2929 - val_accuracy: 0.8655\n",
      "Epoch 360/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1728 - accuracy: 0.9336 - val_loss: 0.2827 - val_accuracy: 0.8893\n",
      "Epoch 361/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1740 - accuracy: 0.9357 - val_loss: 0.2592 - val_accuracy: 0.8988\n",
      "Epoch 362/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1813 - accuracy: 0.9271 - val_loss: 0.3150 - val_accuracy: 0.8524\n",
      "Epoch 363/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1810 - accuracy: 0.9327 - val_loss: 0.2901 - val_accuracy: 0.8798\n",
      "Epoch 364/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1753 - accuracy: 0.9342 - val_loss: 0.3374 - val_accuracy: 0.8238\n",
      "Epoch 365/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1792 - accuracy: 0.9321 - val_loss: 0.3580 - val_accuracy: 0.8071\n",
      "Epoch 366/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1816 - accuracy: 0.9280 - val_loss: 0.2800 - val_accuracy: 0.8821\n",
      "Epoch 367/400\n",
      "3360/3360 [==============================] - 0s 102us/sample - loss: 0.1768 - accuracy: 0.9295 - val_loss: 0.2784 - val_accuracy: 0.8881\n",
      "Epoch 368/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1738 - accuracy: 0.9307 - val_loss: 0.2807 - val_accuracy: 0.8810\n",
      "Epoch 369/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1730 - accuracy: 0.9342 - val_loss: 0.3180 - val_accuracy: 0.8440\n",
      "Epoch 370/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1785 - accuracy: 0.9312 - val_loss: 0.2799 - val_accuracy: 0.8798\n",
      "Epoch 371/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1758 - accuracy: 0.9324 - val_loss: 0.3015 - val_accuracy: 0.8679\n",
      "Epoch 372/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1771 - accuracy: 0.9318 - val_loss: 0.3332 - val_accuracy: 0.8357\n",
      "Epoch 373/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1615 - accuracy: 0.9438 - val_loss: 0.2670 - val_accuracy: 0.8833\n",
      "Epoch 374/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1743 - accuracy: 0.9307 - val_loss: 0.3196 - val_accuracy: 0.8464\n",
      "Epoch 375/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1699 - accuracy: 0.9381 - val_loss: 0.3118 - val_accuracy: 0.8476\n",
      "Epoch 376/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1761 - accuracy: 0.9336 - val_loss: 0.3269 - val_accuracy: 0.8357\n",
      "Epoch 377/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1767 - accuracy: 0.9304 - val_loss: 0.2954 - val_accuracy: 0.8726\n",
      "Epoch 378/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1727 - accuracy: 0.9387 - val_loss: 0.2753 - val_accuracy: 0.8952\n",
      "Epoch 379/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1682 - accuracy: 0.9357 - val_loss: 0.3185 - val_accuracy: 0.8393\n",
      "Epoch 380/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1725 - accuracy: 0.9330 - val_loss: 0.2927 - val_accuracy: 0.8762\n",
      "Epoch 381/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1759 - accuracy: 0.9298 - val_loss: 0.3063 - val_accuracy: 0.8583\n",
      "Epoch 382/400\n",
      "3360/3360 [==============================] - 0s 101us/sample - loss: 0.1739 - accuracy: 0.9360 - val_loss: 0.2867 - val_accuracy: 0.8810\n",
      "Epoch 383/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1738 - accuracy: 0.9327 - val_loss: 0.2949 - val_accuracy: 0.8655\n",
      "Epoch 384/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1687 - accuracy: 0.9405 - val_loss: 0.2722 - val_accuracy: 0.8857\n",
      "Epoch 385/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1764 - accuracy: 0.9318 - val_loss: 0.2814 - val_accuracy: 0.8786\n",
      "Epoch 386/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1694 - accuracy: 0.9327 - val_loss: 0.2858 - val_accuracy: 0.8726\n",
      "Epoch 387/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1729 - accuracy: 0.9378 - val_loss: 0.2832 - val_accuracy: 0.8833\n",
      "Epoch 388/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1635 - accuracy: 0.9408 - val_loss: 0.2803 - val_accuracy: 0.8738\n",
      "Epoch 389/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1711 - accuracy: 0.9354 - val_loss: 0.2956 - val_accuracy: 0.8607\n",
      "Epoch 390/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1729 - accuracy: 0.9301 - val_loss: 0.2857 - val_accuracy: 0.8714\n",
      "Epoch 391/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1678 - accuracy: 0.9351 - val_loss: 0.2735 - val_accuracy: 0.8833\n",
      "Epoch 392/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.1610 - accuracy: 0.9378 - val_loss: 0.3728 - val_accuracy: 0.7988\n",
      "Epoch 393/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.1784 - accuracy: 0.9330 - val_loss: 0.3023 - val_accuracy: 0.8619\n",
      "Epoch 394/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1703 - accuracy: 0.9327 - val_loss: 0.3044 - val_accuracy: 0.8536\n",
      "Epoch 395/400\n",
      "3360/3360 [==============================] - 0s 100us/sample - loss: 0.1810 - accuracy: 0.9339 - val_loss: 0.3253 - val_accuracy: 0.8440\n",
      "Epoch 396/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1731 - accuracy: 0.9321 - val_loss: 0.3159 - val_accuracy: 0.8452\n",
      "Epoch 397/400\n",
      "3360/3360 [==============================] - 0s 97us/sample - loss: 0.1569 - accuracy: 0.9417 - val_loss: 0.2988 - val_accuracy: 0.8583\n",
      "Epoch 398/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1647 - accuracy: 0.9372 - val_loss: 0.2840 - val_accuracy: 0.8726\n",
      "Epoch 399/400\n",
      "3360/3360 [==============================] - 0s 98us/sample - loss: 0.1661 - accuracy: 0.9396 - val_loss: 0.3453 - val_accuracy: 0.8167\n",
      "Epoch 400/400\n",
      "3360/3360 [==============================] - 0s 99us/sample - loss: 0.1645 - accuracy: 0.9363 - val_loss: 0.2782 - val_accuracy: 0.8798\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 400\n",
    "img_size = 32\n",
    "input_shape = (img_size, img_size, 3)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_2 = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_2 = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "model = createModel(input_shape, num_classes)\n",
    "\n",
    "history = model.fit(x_train_2, y_train_2,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test_2, y_test_2),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c505967508>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.set_title(\"eyes dataset, global normalization, 64px img\")\n",
    "ax.set_ylim((0.4,1))\n",
    "ax.set_yticks(np.arange(0.4,1,0.05))\n",
    "ax.grid()\n",
    "ax.plot(history.history['accuracy'])\n",
    "ax.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Convolutional LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading arithmetic calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "frame_length = 1\n",
    "sequence_length = 6\n",
    "overlap = 0.5\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file information: UJing 1 1 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 2 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 1 3 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 4 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 1 5 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 6 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 59/60\n",
      "file information: UJing 1 7 EasyAdd\n",
      "Interpolating 60/60Interpolating 30/6060 frames generated with label  0.0\n",
      "file information: UJing 1 8 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 1 9 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 10 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 59/60\n",
      "file information: UJing 1 11 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 12 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 1 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 2 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 3 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 4 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 5 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 6 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 7 EasyAdd\n",
      "Interpolating 60/60Interpolating 32/6060 frames generated with label  0.0\n",
      "file information: UJing 2 8 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 9 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 10 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 11 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 60/60\n",
      "file information: UJing 2 12 HardMult\n",
      "Interpolating 60/60Interpolating 33/6060 frames generated with label  1.0\n",
      "file information: UJing 3 1 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 61/70\n",
      "file information: UJing 3 2 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 62/70\n",
      "file information: UJing 3 3 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 63/70\n",
      "file information: UJing 3 4 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 64/70\n",
      "file information: UJing 3 5 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 59/70\n",
      "file information: UJing 3 6 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 62/70\n",
      "file information: UJing 3 7 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 64/70\n",
      "file information: UJing 3 8 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 64/70\n",
      "file information: UJing 3 9 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 68/70\n",
      "file information: UJing 3 10 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 68/70\n",
      "file information: UJing 3 11 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 66/70\n",
      "file information: UJing 3 12 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 68/70\n",
      "file information: UJuan 1 1 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 2 HardMult\n",
      "60 frames generated with label  1.0\n",
      "file information: UJuan 1 3 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 4 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 1 5 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 6 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 1 7 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 8 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 1 9 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 60/60\n",
      "file information: UJuan 1 10 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 1 11 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 12 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 2 1 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 2 HardMult\n",
      "60 frames generated with label  1.0\n",
      "file information: UJuan 2 3 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 4 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 2 5 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 6 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 2 7 EasyAdd\n",
      "60 frames generated with label  0.0\n",
      "file information: UJuan 2 8 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 2 9 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 10 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJuan 2 11 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 12 HardMult\n",
      "60 frames generated with label  1.0/60\n"
     ]
    }
   ],
   "source": [
    "dataPath = Path(r\"C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiments3-Data\\ArithmeticCalibrationProcedure\\edf\")\n",
    "X_arith_seq, y_arith_seq = createImageDataset(dataPath,imageSize=image_size,frameDuration=frame_length,overlap=overlap,\n",
    "                           augment_data=False, labels = [\"EasyAdd\",\"HardMult\"],\n",
    "                           lstm_format=True, lstm_sequence_length=sequence_length,\n",
    "                           fileNameFormat=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file information: UI02 1 1 pegNormal\n",
      "375 frames generated with label  0.0/375Interpolating 60/375Interpolating 92/375Interpolating 123/375Interpolating 153/375Interpolating 184/375Interpolating 216/375Interpolating 244/375Interpolating 275/375Interpolating 306/375Interpolating 337/375Interpolating 369/375\n",
      "file information: UI02 1 2 pegInversion\n",
      "375 frames generated with label  1.0/375Interpolating 67/375Interpolating 97/375Interpolating 129/375Interpolating 161/375Interpolating 193/375Interpolating 224/375Interpolating 255/375Interpolating 287/375Interpolating 316/375Interpolating 347/375\n",
      "file information: UI02 1 3 pegNormal\n",
      "375 frames generated with label  0.0/375Interpolating 64/375Interpolating 96/375Interpolating 129/375Interpolating 161/375Interpolating 193/375Interpolating 224/375Interpolating 254/375Interpolating 285/375Interpolating 313/375Interpolating 343/375Interpolating 374/375\n",
      "file information: UI02 1 4 pegInversion\n",
      "375 frames generated with label  1.0/375Interpolating 64/375Interpolating 95/375Interpolating 127/375Interpolating 159/375Interpolating 191/375Interpolating 224/375Interpolating 255/375Interpolating 286/375Interpolating 317/375Interpolating 349/375\n",
      "file information: UI02 1 5 pegNormal\n",
      "Interpolating 171/375nterpolating 34/375Interpolating 66/375Interpolating 99/375Interpolating 129/375Interpolating 156/375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-708609c219e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0maugment_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"pegNormal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"pegInversion\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mlstm_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_sequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                          fileNameFormat=1)   \n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\PycharmProjects\\eeg_project_gnaut_power_band_analysis\\SpectralImagesClassification\\TrainModel.py\u001b[0m in \u001b[0;36mcreateImageDataset\u001b[1;34m(path, imageSize, frameDuration, overlap, image_format, lstm_format, lstm_sequence_length, augment_data, labels, fileNameFormat)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimage_format\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_2d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbandpower\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugment_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'frames generated with label '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\PycharmProjects\\eeg_project_gnaut_power_band_analysis\\SpectralImagesClassification\\SpectralImagesUtils.py\u001b[0m in \u001b[0;36mgen_images\u001b[1;34m(locs, features, n_gridpoints, normalize, augment, pca, std_mult, n_components, edgeless)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_colors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n\u001b[1;32m---> 66\u001b[1;33m                                     method='cubic', fill_value=np.nan)\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Interpolating {0}/{1}\\r'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnSamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Normalizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\scipy\\interpolate\\ndgriddata.py\u001b[0m in \u001b[0;36mgriddata\u001b[1;34m(points, values, xi, method, fill_value, rescale)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cubic'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         ip = CloughTocher2DInterpolator(points, values, fill_value=fill_value,\n\u001b[1;32m--> 225\u001b[1;33m                                         rescale=rescale)\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32minterpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate.interpnd.CloughTocher2DInterpolator.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull.Delaunay.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull._QhullUser.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull.Delaunay._update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull._QhullUser._update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[0m\u001b[0;32m     33\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dataPath = Path(r\"C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiment1-Pilot\\UI02\\pyprep_edf\")\n",
    "# X_inver_seq, y_inver_seq = createImageDataset(dataPath,imageSize=32,frameDuration=1,overlap=0.2,\n",
    "#                           augment_data=False, labels = [\"pegNormal\",\"pegInversion\"],\n",
    "#                           lstm_format=False, lstm_sequence_length=None,\n",
    "#                          fileNameFormat=1)   \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_arith_seq, y_arith_seq, test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451,)\n",
      "(451, 6, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "##Normalize the dataset\n",
    "\n",
    "##No normalization -- Seems to yield the best results \n",
    "# x_train_2 = x_train\n",
    "# x_test_2 = x_test\n",
    "\n",
    "##Global frame/time normalization\n",
    "global_mean = x_train.mean(); global_std = x_train.std();\n",
    "x_train_2 = (x_train - global_mean)/global_std;\n",
    "x_test_2 = (x_test - global_mean)/global_std;\n",
    "\n",
    "## convert class vectors to binary class matrices\n",
    "y_train_2 = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_2 = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train_2 = x_train_2.astype('float32')\n",
    "x_test_2 = x_test_2.astype('float32')\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 451 samples, validate on 113 samples\n",
      "Epoch 1/500\n",
      "451/451 [==============================] - 7s 15ms/sample - loss: 0.7200 - accuracy: 0.4989 - val_loss: 0.6726 - val_accuracy: 0.5487\n",
      "Epoch 2/500\n",
      "451/451 [==============================] - 0s 196us/sample - loss: 0.6766 - accuracy: 0.5521 - val_loss: 0.6629 - val_accuracy: 0.6283\n",
      "Epoch 3/500\n",
      "451/451 [==============================] - 0s 198us/sample - loss: 0.6656 - accuracy: 0.5831 - val_loss: 0.6551 - val_accuracy: 0.6106\n",
      "Epoch 4/500\n",
      "451/451 [==============================] - 0s 190us/sample - loss: 0.6544 - accuracy: 0.6120 - val_loss: 0.6814 - val_accuracy: 0.5664\n",
      "Epoch 5/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.6576 - accuracy: 0.6341 - val_loss: 0.6573 - val_accuracy: 0.6106\n",
      "Epoch 6/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.6449 - accuracy: 0.6253 - val_loss: 0.6491 - val_accuracy: 0.6283\n",
      "Epoch 7/500\n",
      "451/451 [==============================] - 0s 193us/sample - loss: 0.6408 - accuracy: 0.6231 - val_loss: 0.6501 - val_accuracy: 0.6460\n",
      "Epoch 8/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.6391 - accuracy: 0.6430 - val_loss: 0.6475 - val_accuracy: 0.6283\n",
      "Epoch 9/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.6304 - accuracy: 0.6452 - val_loss: 0.6491 - val_accuracy: 0.6106\n",
      "Epoch 10/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.6321 - accuracy: 0.6541 - val_loss: 0.6423 - val_accuracy: 0.6460\n",
      "Epoch 11/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.6235 - accuracy: 0.6674 - val_loss: 0.6444 - val_accuracy: 0.6372\n",
      "Epoch 12/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.6283 - accuracy: 0.6585 - val_loss: 0.6402 - val_accuracy: 0.6549\n",
      "Epoch 13/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.6240 - accuracy: 0.6563 - val_loss: 0.6474 - val_accuracy: 0.5841\n",
      "Epoch 14/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.6295 - accuracy: 0.6408 - val_loss: 0.6414 - val_accuracy: 0.6372\n",
      "Epoch 15/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.6199 - accuracy: 0.6497 - val_loss: 0.6355 - val_accuracy: 0.6903\n",
      "Epoch 16/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.6160 - accuracy: 0.6674 - val_loss: 0.6704 - val_accuracy: 0.5664\n",
      "Epoch 17/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.6234 - accuracy: 0.6718 - val_loss: 0.6463 - val_accuracy: 0.6283\n",
      "Epoch 18/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.6039 - accuracy: 0.6763 - val_loss: 0.6436 - val_accuracy: 0.6283\n",
      "Epoch 19/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.6065 - accuracy: 0.6674 - val_loss: 0.6395 - val_accuracy: 0.6283\n",
      "Epoch 20/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.6076 - accuracy: 0.6785 - val_loss: 0.6493 - val_accuracy: 0.6018\n",
      "Epoch 21/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.6027 - accuracy: 0.6741 - val_loss: 0.6398 - val_accuracy: 0.6549\n",
      "Epoch 22/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5881 - accuracy: 0.6940 - val_loss: 0.6445 - val_accuracy: 0.6195\n",
      "Epoch 23/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.6144 - accuracy: 0.6696 - val_loss: 0.6292 - val_accuracy: 0.6637\n",
      "Epoch 24/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5974 - accuracy: 0.6896 - val_loss: 0.6289 - val_accuracy: 0.6637\n",
      "Epoch 25/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5980 - accuracy: 0.6741 - val_loss: 0.6266 - val_accuracy: 0.6549\n",
      "Epoch 26/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5917 - accuracy: 0.6984 - val_loss: 0.6295 - val_accuracy: 0.6549\n",
      "Epoch 27/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.5952 - accuracy: 0.6918 - val_loss: 0.6352 - val_accuracy: 0.6283\n",
      "Epoch 28/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5842 - accuracy: 0.6962 - val_loss: 0.6405 - val_accuracy: 0.6372\n",
      "Epoch 29/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5939 - accuracy: 0.6851 - val_loss: 0.6324 - val_accuracy: 0.6549\n",
      "Epoch 30/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5758 - accuracy: 0.7118 - val_loss: 0.6248 - val_accuracy: 0.6814\n",
      "Epoch 31/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.5885 - accuracy: 0.6940 - val_loss: 0.6552 - val_accuracy: 0.5841\n",
      "Epoch 32/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.5796 - accuracy: 0.7206 - val_loss: 0.6545 - val_accuracy: 0.5929\n",
      "Epoch 33/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5803 - accuracy: 0.7051 - val_loss: 0.6398 - val_accuracy: 0.6460\n",
      "Epoch 34/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.5758 - accuracy: 0.6962 - val_loss: 0.6372 - val_accuracy: 0.6195\n",
      "Epoch 35/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5867 - accuracy: 0.6585 - val_loss: 0.6372 - val_accuracy: 0.6195\n",
      "Epoch 36/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5783 - accuracy: 0.6896 - val_loss: 0.6384 - val_accuracy: 0.6106\n",
      "Epoch 37/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.5904 - accuracy: 0.6896 - val_loss: 0.6380 - val_accuracy: 0.6106\n",
      "Epoch 38/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5730 - accuracy: 0.6984 - val_loss: 0.6202 - val_accuracy: 0.6814\n",
      "Epoch 39/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5602 - accuracy: 0.7339 - val_loss: 0.6199 - val_accuracy: 0.6726\n",
      "Epoch 40/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5656 - accuracy: 0.7317 - val_loss: 0.6402 - val_accuracy: 0.6195\n",
      "Epoch 41/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5717 - accuracy: 0.7029 - val_loss: 0.6283 - val_accuracy: 0.6460\n",
      "Epoch 42/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5730 - accuracy: 0.7184 - val_loss: 0.6170 - val_accuracy: 0.6726\n",
      "Epoch 43/500\n",
      "451/451 [==============================] - 0s 185us/sample - loss: 0.5577 - accuracy: 0.7361 - val_loss: 0.6193 - val_accuracy: 0.6726\n",
      "Epoch 44/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5558 - accuracy: 0.7472 - val_loss: 0.6561 - val_accuracy: 0.6018\n",
      "Epoch 45/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.5777 - accuracy: 0.7007 - val_loss: 0.6550 - val_accuracy: 0.6018\n",
      "Epoch 46/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5603 - accuracy: 0.7118 - val_loss: 0.6240 - val_accuracy: 0.6814\n",
      "Epoch 47/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5541 - accuracy: 0.7317 - val_loss: 0.6173 - val_accuracy: 0.6549\n",
      "Epoch 48/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5524 - accuracy: 0.7295 - val_loss: 0.6214 - val_accuracy: 0.6814\n",
      "Epoch 49/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5484 - accuracy: 0.7029 - val_loss: 0.6219 - val_accuracy: 0.6637\n",
      "Epoch 50/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5593 - accuracy: 0.7051 - val_loss: 0.6220 - val_accuracy: 0.6903\n",
      "Epoch 51/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.5409 - accuracy: 0.7472 - val_loss: 0.6530 - val_accuracy: 0.5929\n",
      "Epoch 52/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5543 - accuracy: 0.7295 - val_loss: 0.6218 - val_accuracy: 0.6726\n",
      "Epoch 53/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5461 - accuracy: 0.7472 - val_loss: 0.6181 - val_accuracy: 0.6637\n",
      "Epoch 54/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5502 - accuracy: 0.7384 - val_loss: 0.6177 - val_accuracy: 0.6814\n",
      "Epoch 55/500\n",
      "451/451 [==============================] - 0s 198us/sample - loss: 0.5342 - accuracy: 0.7472 - val_loss: 0.6674 - val_accuracy: 0.6283\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 186us/sample - loss: 0.5524 - accuracy: 0.7140 - val_loss: 0.6260 - val_accuracy: 0.6991\n",
      "Epoch 57/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.5309 - accuracy: 0.7716 - val_loss: 0.6776 - val_accuracy: 0.6283\n",
      "Epoch 58/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5522 - accuracy: 0.7118 - val_loss: 0.6246 - val_accuracy: 0.6903\n",
      "Epoch 59/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5197 - accuracy: 0.7428 - val_loss: 0.6160 - val_accuracy: 0.6814\n",
      "Epoch 60/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5359 - accuracy: 0.7428 - val_loss: 0.6293 - val_accuracy: 0.6726\n",
      "Epoch 61/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5691 - accuracy: 0.7140 - val_loss: 0.6173 - val_accuracy: 0.6637\n",
      "Epoch 62/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5167 - accuracy: 0.7627 - val_loss: 0.6148 - val_accuracy: 0.6637\n",
      "Epoch 63/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5159 - accuracy: 0.7627 - val_loss: 0.6443 - val_accuracy: 0.6372\n",
      "Epoch 64/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5311 - accuracy: 0.7450 - val_loss: 0.6166 - val_accuracy: 0.6726\n",
      "Epoch 65/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5246 - accuracy: 0.7694 - val_loss: 0.7058 - val_accuracy: 0.5929\n",
      "Epoch 66/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.5575 - accuracy: 0.6984 - val_loss: 0.6342 - val_accuracy: 0.6372\n",
      "Epoch 67/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5120 - accuracy: 0.7539 - val_loss: 0.6167 - val_accuracy: 0.6726\n",
      "Epoch 68/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.5346 - accuracy: 0.7428 - val_loss: 0.6671 - val_accuracy: 0.6283\n",
      "Epoch 69/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5251 - accuracy: 0.7627 - val_loss: 0.6238 - val_accuracy: 0.6460\n",
      "Epoch 70/500\n",
      "451/451 [==============================] - 0s 185us/sample - loss: 0.5141 - accuracy: 0.7650 - val_loss: 0.6445 - val_accuracy: 0.6283\n",
      "Epoch 71/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.5275 - accuracy: 0.7384 - val_loss: 0.6463 - val_accuracy: 0.6460\n",
      "Epoch 72/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5175 - accuracy: 0.7738 - val_loss: 0.6442 - val_accuracy: 0.6283\n",
      "Epoch 73/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.5231 - accuracy: 0.7517 - val_loss: 0.6162 - val_accuracy: 0.6991\n",
      "Epoch 74/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.5138 - accuracy: 0.7517 - val_loss: 0.6453 - val_accuracy: 0.6283\n",
      "Epoch 75/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5120 - accuracy: 0.7384 - val_loss: 0.6129 - val_accuracy: 0.6814\n",
      "Epoch 76/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4945 - accuracy: 0.7450 - val_loss: 0.6420 - val_accuracy: 0.6460\n",
      "Epoch 77/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5087 - accuracy: 0.7583 - val_loss: 0.6128 - val_accuracy: 0.6637\n",
      "Epoch 78/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4931 - accuracy: 0.7605 - val_loss: 0.6145 - val_accuracy: 0.6637\n",
      "Epoch 79/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5061 - accuracy: 0.7627 - val_loss: 0.6202 - val_accuracy: 0.6549\n",
      "Epoch 80/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5321 - accuracy: 0.7472 - val_loss: 0.6638 - val_accuracy: 0.6460\n",
      "Epoch 81/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5119 - accuracy: 0.7517 - val_loss: 0.6158 - val_accuracy: 0.6726\n",
      "Epoch 82/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.5080 - accuracy: 0.7650 - val_loss: 0.6248 - val_accuracy: 0.6637\n",
      "Epoch 83/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.5089 - accuracy: 0.7561 - val_loss: 0.6797 - val_accuracy: 0.6106\n",
      "Epoch 84/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.5142 - accuracy: 0.7517 - val_loss: 0.6210 - val_accuracy: 0.6903\n",
      "Epoch 85/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4783 - accuracy: 0.7716 - val_loss: 0.6137 - val_accuracy: 0.6991\n",
      "Epoch 86/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4993 - accuracy: 0.7539 - val_loss: 0.6730 - val_accuracy: 0.6372\n",
      "Epoch 87/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4900 - accuracy: 0.7761 - val_loss: 0.6798 - val_accuracy: 0.5841\n",
      "Epoch 88/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.5061 - accuracy: 0.7583 - val_loss: 0.6166 - val_accuracy: 0.6637\n",
      "Epoch 89/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4862 - accuracy: 0.7827 - val_loss: 0.6130 - val_accuracy: 0.6991\n",
      "Epoch 90/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.4817 - accuracy: 0.7960 - val_loss: 0.6269 - val_accuracy: 0.6637\n",
      "Epoch 91/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.5050 - accuracy: 0.7494 - val_loss: 0.6529 - val_accuracy: 0.6283\n",
      "Epoch 92/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4941 - accuracy: 0.7805 - val_loss: 0.6210 - val_accuracy: 0.6991\n",
      "Epoch 93/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4902 - accuracy: 0.7871 - val_loss: 0.6170 - val_accuracy: 0.6726\n",
      "Epoch 94/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.5074 - accuracy: 0.7406 - val_loss: 0.6623 - val_accuracy: 0.6372\n",
      "Epoch 95/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4806 - accuracy: 0.7783 - val_loss: 0.6204 - val_accuracy: 0.6903\n",
      "Epoch 96/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4602 - accuracy: 0.7871 - val_loss: 0.6431 - val_accuracy: 0.6460\n",
      "Epoch 97/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.5072 - accuracy: 0.7361 - val_loss: 0.6310 - val_accuracy: 0.6814\n",
      "Epoch 98/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4867 - accuracy: 0.7627 - val_loss: 0.6222 - val_accuracy: 0.6903\n",
      "Epoch 99/500\n",
      "451/451 [==============================] - 0s 185us/sample - loss: 0.4799 - accuracy: 0.7694 - val_loss: 0.6144 - val_accuracy: 0.6903\n",
      "Epoch 100/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4674 - accuracy: 0.7894 - val_loss: 0.6399 - val_accuracy: 0.6637\n",
      "Epoch 101/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.4892 - accuracy: 0.7583 - val_loss: 0.6614 - val_accuracy: 0.6372\n",
      "Epoch 102/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.4855 - accuracy: 0.7761 - val_loss: 0.6355 - val_accuracy: 0.6549\n",
      "Epoch 103/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4659 - accuracy: 0.7849 - val_loss: 0.6255 - val_accuracy: 0.6726\n",
      "Epoch 104/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.4717 - accuracy: 0.8027 - val_loss: 0.6307 - val_accuracy: 0.6549\n",
      "Epoch 105/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4586 - accuracy: 0.8093 - val_loss: 0.6357 - val_accuracy: 0.6549\n",
      "Epoch 106/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4672 - accuracy: 0.7805 - val_loss: 0.6738 - val_accuracy: 0.6195\n",
      "Epoch 107/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4677 - accuracy: 0.7783 - val_loss: 0.6285 - val_accuracy: 0.6814\n",
      "Epoch 108/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4869 - accuracy: 0.7561 - val_loss: 0.6207 - val_accuracy: 0.6726\n",
      "Epoch 109/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4759 - accuracy: 0.7894 - val_loss: 0.6536 - val_accuracy: 0.6726\n",
      "Epoch 110/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4658 - accuracy: 0.7805 - val_loss: 0.6321 - val_accuracy: 0.6637\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 183us/sample - loss: 0.4751 - accuracy: 0.7738 - val_loss: 0.7286 - val_accuracy: 0.6195\n",
      "Epoch 112/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.4879 - accuracy: 0.7583 - val_loss: 0.6583 - val_accuracy: 0.6372\n",
      "Epoch 113/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4758 - accuracy: 0.7605 - val_loss: 0.6399 - val_accuracy: 0.6549\n",
      "Epoch 114/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4602 - accuracy: 0.7805 - val_loss: 0.6241 - val_accuracy: 0.6814\n",
      "Epoch 115/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4535 - accuracy: 0.8160 - val_loss: 0.7967 - val_accuracy: 0.6106\n",
      "Epoch 116/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4796 - accuracy: 0.7916 - val_loss: 0.6260 - val_accuracy: 0.6637\n",
      "Epoch 117/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4632 - accuracy: 0.7783 - val_loss: 0.6222 - val_accuracy: 0.6991\n",
      "Epoch 118/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4538 - accuracy: 0.7982 - val_loss: 0.6423 - val_accuracy: 0.6460\n",
      "Epoch 119/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4496 - accuracy: 0.7938 - val_loss: 0.6682 - val_accuracy: 0.6637\n",
      "Epoch 120/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4671 - accuracy: 0.7738 - val_loss: 0.6172 - val_accuracy: 0.6991\n",
      "Epoch 121/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4506 - accuracy: 0.7938 - val_loss: 0.6160 - val_accuracy: 0.6903\n",
      "Epoch 122/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4419 - accuracy: 0.7960 - val_loss: 0.6508 - val_accuracy: 0.6549\n",
      "Epoch 123/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4943 - accuracy: 0.7450 - val_loss: 0.6493 - val_accuracy: 0.6460\n",
      "Epoch 124/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4446 - accuracy: 0.8027 - val_loss: 0.6237 - val_accuracy: 0.6814\n",
      "Epoch 125/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4663 - accuracy: 0.7716 - val_loss: 0.6317 - val_accuracy: 0.6726\n",
      "Epoch 126/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4547 - accuracy: 0.7938 - val_loss: 0.6904 - val_accuracy: 0.5841\n",
      "Epoch 127/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4669 - accuracy: 0.7894 - val_loss: 0.6289 - val_accuracy: 0.6726\n",
      "Epoch 128/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4434 - accuracy: 0.8337 - val_loss: 0.6418 - val_accuracy: 0.6372\n",
      "Epoch 129/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4416 - accuracy: 0.8093 - val_loss: 0.6576 - val_accuracy: 0.6283\n",
      "Epoch 130/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4441 - accuracy: 0.7916 - val_loss: 0.6239 - val_accuracy: 0.6903\n",
      "Epoch 131/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4341 - accuracy: 0.8027 - val_loss: 0.6182 - val_accuracy: 0.6991\n",
      "Epoch 132/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4365 - accuracy: 0.8204 - val_loss: 0.6647 - val_accuracy: 0.6549\n",
      "Epoch 133/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.4684 - accuracy: 0.7539 - val_loss: 0.6799 - val_accuracy: 0.6372\n",
      "Epoch 134/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4664 - accuracy: 0.7650 - val_loss: 0.6166 - val_accuracy: 0.7080\n",
      "Epoch 135/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4236 - accuracy: 0.8027 - val_loss: 0.6481 - val_accuracy: 0.6195\n",
      "Epoch 136/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.4712 - accuracy: 0.7627 - val_loss: 0.6484 - val_accuracy: 0.6106\n",
      "Epoch 137/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4512 - accuracy: 0.8004 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Epoch 138/500\n",
      "451/451 [==============================] - 0s 176us/sample - loss: 0.4070 - accuracy: 0.8470 - val_loss: 0.6238 - val_accuracy: 0.6903\n",
      "Epoch 139/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4328 - accuracy: 0.8027 - val_loss: 0.6437 - val_accuracy: 0.6372\n",
      "Epoch 140/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.4239 - accuracy: 0.8248 - val_loss: 0.6238 - val_accuracy: 0.6814\n",
      "Epoch 141/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.4313 - accuracy: 0.8093 - val_loss: 0.7154 - val_accuracy: 0.5752\n",
      "Epoch 142/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.4380 - accuracy: 0.8293 - val_loss: 0.6514 - val_accuracy: 0.6726\n",
      "Epoch 143/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.4101 - accuracy: 0.8271 - val_loss: 0.6539 - val_accuracy: 0.6637\n",
      "Epoch 144/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4198 - accuracy: 0.8027 - val_loss: 0.6398 - val_accuracy: 0.6637\n",
      "Epoch 145/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4484 - accuracy: 0.7738 - val_loss: 0.6228 - val_accuracy: 0.6991\n",
      "Epoch 146/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4207 - accuracy: 0.8137 - val_loss: 0.6268 - val_accuracy: 0.6637\n",
      "Epoch 147/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4179 - accuracy: 0.8248 - val_loss: 0.6315 - val_accuracy: 0.6903\n",
      "Epoch 148/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3924 - accuracy: 0.8315 - val_loss: 0.6537 - val_accuracy: 0.6637\n",
      "Epoch 149/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4493 - accuracy: 0.8027 - val_loss: 0.7148 - val_accuracy: 0.6018\n",
      "Epoch 150/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4310 - accuracy: 0.8182 - val_loss: 0.6391 - val_accuracy: 0.6726\n",
      "Epoch 151/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4151 - accuracy: 0.8071 - val_loss: 0.6397 - val_accuracy: 0.6637\n",
      "Epoch 152/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4250 - accuracy: 0.7982 - val_loss: 0.7355 - val_accuracy: 0.6283\n",
      "Epoch 153/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4220 - accuracy: 0.7982 - val_loss: 0.6821 - val_accuracy: 0.6283\n",
      "Epoch 154/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4254 - accuracy: 0.8248 - val_loss: 0.6301 - val_accuracy: 0.6814\n",
      "Epoch 155/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4127 - accuracy: 0.8359 - val_loss: 0.6389 - val_accuracy: 0.6814\n",
      "Epoch 156/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4229 - accuracy: 0.8071 - val_loss: 0.6750 - val_accuracy: 0.6637\n",
      "Epoch 157/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.4017 - accuracy: 0.8248 - val_loss: 0.7324 - val_accuracy: 0.6018\n",
      "Epoch 158/500\n",
      "451/451 [==============================] - 0s 197us/sample - loss: 0.4099 - accuracy: 0.8315 - val_loss: 0.6803 - val_accuracy: 0.6637\n",
      "Epoch 159/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.3935 - accuracy: 0.8293 - val_loss: 0.6820 - val_accuracy: 0.6637\n",
      "Epoch 160/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4161 - accuracy: 0.8004 - val_loss: 0.6343 - val_accuracy: 0.6903\n",
      "Epoch 161/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4089 - accuracy: 0.8204 - val_loss: 0.6330 - val_accuracy: 0.6903\n",
      "Epoch 162/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3886 - accuracy: 0.8271 - val_loss: 0.6316 - val_accuracy: 0.6903\n",
      "Epoch 163/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4059 - accuracy: 0.8404 - val_loss: 0.6447 - val_accuracy: 0.6637\n",
      "Epoch 164/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4009 - accuracy: 0.8204 - val_loss: 0.6568 - val_accuracy: 0.6549\n",
      "Epoch 165/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4114 - accuracy: 0.8204 - val_loss: 0.6674 - val_accuracy: 0.6372\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4304 - accuracy: 0.7916 - val_loss: 0.6448 - val_accuracy: 0.6637\n",
      "Epoch 167/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4006 - accuracy: 0.8337 - val_loss: 0.6526 - val_accuracy: 0.6460\n",
      "Epoch 168/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.4028 - accuracy: 0.8293 - val_loss: 0.6560 - val_accuracy: 0.6549\n",
      "Epoch 169/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.4017 - accuracy: 0.8226 - val_loss: 0.6518 - val_accuracy: 0.6549\n",
      "Epoch 170/500\n",
      "451/451 [==============================] - 0s 176us/sample - loss: 0.3881 - accuracy: 0.8448 - val_loss: 0.6403 - val_accuracy: 0.6726\n",
      "Epoch 171/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4075 - accuracy: 0.8004 - val_loss: 0.6601 - val_accuracy: 0.6637\n",
      "Epoch 172/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3968 - accuracy: 0.8271 - val_loss: 0.6329 - val_accuracy: 0.6726\n",
      "Epoch 173/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.4141 - accuracy: 0.7960 - val_loss: 0.6280 - val_accuracy: 0.6903\n",
      "Epoch 174/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3660 - accuracy: 0.8514 - val_loss: 0.6536 - val_accuracy: 0.6460\n",
      "Epoch 175/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4084 - accuracy: 0.8115 - val_loss: 0.6359 - val_accuracy: 0.7080\n",
      "Epoch 176/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.3964 - accuracy: 0.8271 - val_loss: 0.6821 - val_accuracy: 0.6549\n",
      "Epoch 177/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3717 - accuracy: 0.8248 - val_loss: 0.6753 - val_accuracy: 0.6460\n",
      "Epoch 178/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3837 - accuracy: 0.8293 - val_loss: 0.6355 - val_accuracy: 0.6903\n",
      "Epoch 179/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3813 - accuracy: 0.8137 - val_loss: 0.6423 - val_accuracy: 0.7168\n",
      "Epoch 180/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3802 - accuracy: 0.8581 - val_loss: 0.6521 - val_accuracy: 0.6814\n",
      "Epoch 181/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.3703 - accuracy: 0.8514 - val_loss: 0.6617 - val_accuracy: 0.6637\n",
      "Epoch 182/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4294 - accuracy: 0.8115 - val_loss: 0.6400 - val_accuracy: 0.6814\n",
      "Epoch 183/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3712 - accuracy: 0.8404 - val_loss: 0.6365 - val_accuracy: 0.7080\n",
      "Epoch 184/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.3982 - accuracy: 0.8293 - val_loss: 0.6388 - val_accuracy: 0.6991\n",
      "Epoch 185/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.3910 - accuracy: 0.8160 - val_loss: 0.6403 - val_accuracy: 0.6814\n",
      "Epoch 186/500\n",
      "451/451 [==============================] - 0s 176us/sample - loss: 0.3685 - accuracy: 0.8426 - val_loss: 0.6977 - val_accuracy: 0.6726\n",
      "Epoch 187/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.4001 - accuracy: 0.8115 - val_loss: 0.7288 - val_accuracy: 0.6637\n",
      "Epoch 188/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.6368 - val_accuracy: 0.6460\n",
      "Epoch 189/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3541 - accuracy: 0.8514 - val_loss: 0.7140 - val_accuracy: 0.5929\n",
      "Epoch 190/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.4502 - accuracy: 0.7849 - val_loss: 0.6428 - val_accuracy: 0.6814\n",
      "Epoch 191/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.3552 - accuracy: 0.8514 - val_loss: 0.6499 - val_accuracy: 0.6903\n",
      "Epoch 192/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3561 - accuracy: 0.8448 - val_loss: 0.6784 - val_accuracy: 0.6637\n",
      "Epoch 193/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4011 - accuracy: 0.8049 - val_loss: 0.6444 - val_accuracy: 0.7168\n",
      "Epoch 194/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3758 - accuracy: 0.8226 - val_loss: 0.7389 - val_accuracy: 0.6106\n",
      "Epoch 195/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.3684 - accuracy: 0.8337 - val_loss: 0.6856 - val_accuracy: 0.6460\n",
      "Epoch 196/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3631 - accuracy: 0.8537 - val_loss: 0.6449 - val_accuracy: 0.7080\n",
      "Epoch 197/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3650 - accuracy: 0.8603 - val_loss: 0.7374 - val_accuracy: 0.6637\n",
      "Epoch 198/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3803 - accuracy: 0.8293 - val_loss: 0.6671 - val_accuracy: 0.6549\n",
      "Epoch 199/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3612 - accuracy: 0.8559 - val_loss: 0.6504 - val_accuracy: 0.6991\n",
      "Epoch 200/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3992 - accuracy: 0.8137 - val_loss: 0.6457 - val_accuracy: 0.6903\n",
      "Epoch 201/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3371 - accuracy: 0.8670 - val_loss: 0.6488 - val_accuracy: 0.6991\n",
      "Epoch 202/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3542 - accuracy: 0.8426 - val_loss: 0.6461 - val_accuracy: 0.6903\n",
      "Epoch 203/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.3399 - accuracy: 0.8625 - val_loss: 0.7048 - val_accuracy: 0.6549\n",
      "Epoch 204/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4124 - accuracy: 0.8071 - val_loss: 0.6608 - val_accuracy: 0.6726\n",
      "Epoch 205/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3429 - accuracy: 0.8603 - val_loss: 0.7664 - val_accuracy: 0.5841\n",
      "Epoch 206/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3742 - accuracy: 0.8271 - val_loss: 0.6476 - val_accuracy: 0.6991\n",
      "Epoch 207/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3591 - accuracy: 0.8537 - val_loss: 0.7634 - val_accuracy: 0.5841\n",
      "Epoch 208/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3731 - accuracy: 0.8470 - val_loss: 0.6702 - val_accuracy: 0.6460\n",
      "Epoch 209/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3294 - accuracy: 0.8514 - val_loss: 0.6833 - val_accuracy: 0.6549\n",
      "Epoch 210/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3602 - accuracy: 0.8514 - val_loss: 0.7998 - val_accuracy: 0.6460\n",
      "Epoch 211/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.4182 - accuracy: 0.8071 - val_loss: 0.6483 - val_accuracy: 0.6991\n",
      "Epoch 212/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3568 - accuracy: 0.8625 - val_loss: 0.6444 - val_accuracy: 0.6903\n",
      "Epoch 213/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.4185 - accuracy: 0.7960 - val_loss: 0.6407 - val_accuracy: 0.6991\n",
      "Epoch 214/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3391 - accuracy: 0.8736 - val_loss: 0.6530 - val_accuracy: 0.6814\n",
      "Epoch 215/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3315 - accuracy: 0.8625 - val_loss: 0.6902 - val_accuracy: 0.6549\n",
      "Epoch 216/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3592 - accuracy: 0.8603 - val_loss: 0.6733 - val_accuracy: 0.6814\n",
      "Epoch 217/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3374 - accuracy: 0.8670 - val_loss: 0.6937 - val_accuracy: 0.6549\n",
      "Epoch 218/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.3382 - accuracy: 0.8714 - val_loss: 0.7760 - val_accuracy: 0.6903\n",
      "Epoch 219/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3681 - accuracy: 0.8293 - val_loss: 0.6930 - val_accuracy: 0.6637\n",
      "Epoch 220/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3724 - accuracy: 0.8337 - val_loss: 0.6777 - val_accuracy: 0.6726\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3287 - accuracy: 0.8625 - val_loss: 0.6674 - val_accuracy: 0.6991\n",
      "Epoch 222/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3175 - accuracy: 0.8625 - val_loss: 0.6657 - val_accuracy: 0.6814\n",
      "Epoch 223/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.3252 - accuracy: 0.8891 - val_loss: 0.7663 - val_accuracy: 0.6106\n",
      "Epoch 224/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3902 - accuracy: 0.8293 - val_loss: 0.6656 - val_accuracy: 0.6549\n",
      "Epoch 225/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.3094 - accuracy: 0.8780 - val_loss: 0.6960 - val_accuracy: 0.6637\n",
      "Epoch 226/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3532 - accuracy: 0.8426 - val_loss: 0.6635 - val_accuracy: 0.6903\n",
      "Epoch 227/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3215 - accuracy: 0.8803 - val_loss: 0.6624 - val_accuracy: 0.6814\n",
      "Epoch 228/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3489 - accuracy: 0.8603 - val_loss: 0.6556 - val_accuracy: 0.7168\n",
      "Epoch 229/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3247 - accuracy: 0.8803 - val_loss: 0.6906 - val_accuracy: 0.6726\n",
      "Epoch 230/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.2967 - accuracy: 0.8736 - val_loss: 0.7653 - val_accuracy: 0.6814\n",
      "Epoch 231/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3767 - accuracy: 0.8160 - val_loss: 0.6684 - val_accuracy: 0.6814\n",
      "Epoch 232/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3158 - accuracy: 0.8625 - val_loss: 0.7623 - val_accuracy: 0.6637\n",
      "Epoch 233/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3362 - accuracy: 0.8670 - val_loss: 0.6740 - val_accuracy: 0.6903\n",
      "Epoch 234/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.3072 - accuracy: 0.8825 - val_loss: 0.6680 - val_accuracy: 0.7080\n",
      "Epoch 235/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2980 - accuracy: 0.8914 - val_loss: 0.6711 - val_accuracy: 0.7080\n",
      "Epoch 236/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.3631 - accuracy: 0.8271 - val_loss: 0.8520 - val_accuracy: 0.5664\n",
      "Epoch 237/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.3463 - accuracy: 0.8514 - val_loss: 0.6597 - val_accuracy: 0.6991\n",
      "Epoch 238/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3074 - accuracy: 0.8758 - val_loss: 0.7173 - val_accuracy: 0.6726\n",
      "Epoch 239/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3281 - accuracy: 0.8670 - val_loss: 0.6714 - val_accuracy: 0.6903\n",
      "Epoch 240/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2866 - accuracy: 0.8869 - val_loss: 0.7864 - val_accuracy: 0.6283\n",
      "Epoch 241/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3691 - accuracy: 0.8337 - val_loss: 0.6852 - val_accuracy: 0.6460\n",
      "Epoch 242/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3110 - accuracy: 0.8736 - val_loss: 0.7075 - val_accuracy: 0.6549\n",
      "Epoch 243/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3161 - accuracy: 0.8803 - val_loss: 0.6744 - val_accuracy: 0.6726\n",
      "Epoch 244/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.3080 - accuracy: 0.8758 - val_loss: 0.6974 - val_accuracy: 0.6549\n",
      "Epoch 245/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.4068 - accuracy: 0.7894 - val_loss: 0.6957 - val_accuracy: 0.6637\n",
      "Epoch 246/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3172 - accuracy: 0.8692 - val_loss: 0.6566 - val_accuracy: 0.6814\n",
      "Epoch 247/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2999 - accuracy: 0.8891 - val_loss: 0.7627 - val_accuracy: 0.6283\n",
      "Epoch 248/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.3515 - accuracy: 0.8248 - val_loss: 0.6807 - val_accuracy: 0.6814\n",
      "Epoch 249/500\n",
      "451/451 [==============================] - 0s 189us/sample - loss: 0.3005 - accuracy: 0.8891 - val_loss: 0.6747 - val_accuracy: 0.6991\n",
      "Epoch 250/500\n",
      "451/451 [==============================] - 0s 193us/sample - loss: 0.3309 - accuracy: 0.8448 - val_loss: 0.7799 - val_accuracy: 0.6991\n",
      "Epoch 251/500\n",
      "451/451 [==============================] - 0s 189us/sample - loss: 0.3064 - accuracy: 0.8847 - val_loss: 0.6774 - val_accuracy: 0.6726\n",
      "Epoch 252/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2760 - accuracy: 0.9091 - val_loss: 0.6785 - val_accuracy: 0.6903\n",
      "Epoch 253/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2827 - accuracy: 0.9047 - val_loss: 0.7184 - val_accuracy: 0.6460\n",
      "Epoch 254/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3680 - accuracy: 0.8182 - val_loss: 0.7034 - val_accuracy: 0.6460\n",
      "Epoch 255/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3057 - accuracy: 0.8847 - val_loss: 0.7655 - val_accuracy: 0.6726\n",
      "Epoch 256/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3304 - accuracy: 0.8625 - val_loss: 0.6856 - val_accuracy: 0.6814\n",
      "Epoch 257/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3368 - accuracy: 0.8514 - val_loss: 0.7142 - val_accuracy: 0.6549\n",
      "Epoch 258/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2864 - accuracy: 0.8914 - val_loss: 0.6770 - val_accuracy: 0.6903\n",
      "Epoch 259/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3154 - accuracy: 0.8692 - val_loss: 0.6742 - val_accuracy: 0.6991\n",
      "Epoch 260/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2996 - accuracy: 0.8647 - val_loss: 0.7400 - val_accuracy: 0.6637\n",
      "Epoch 261/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3388 - accuracy: 0.8514 - val_loss: 0.6866 - val_accuracy: 0.6903\n",
      "Epoch 262/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2719 - accuracy: 0.9047 - val_loss: 0.7259 - val_accuracy: 0.6726\n",
      "Epoch 263/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3576 - accuracy: 0.8248 - val_loss: 0.7288 - val_accuracy: 0.6637\n",
      "Epoch 264/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.2937 - accuracy: 0.8758 - val_loss: 0.6907 - val_accuracy: 0.6814\n",
      "Epoch 265/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3036 - accuracy: 0.8714 - val_loss: 0.7121 - val_accuracy: 0.6991\n",
      "Epoch 266/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2813 - accuracy: 0.9002 - val_loss: 0.6878 - val_accuracy: 0.6991\n",
      "Epoch 267/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.2739 - accuracy: 0.8914 - val_loss: 0.7978 - val_accuracy: 0.6903\n",
      "Epoch 268/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3543 - accuracy: 0.8248 - val_loss: 0.6765 - val_accuracy: 0.6903\n",
      "Epoch 269/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2755 - accuracy: 0.9113 - val_loss: 0.7087 - val_accuracy: 0.6903\n",
      "Epoch 270/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2747 - accuracy: 0.9047 - val_loss: 0.7232 - val_accuracy: 0.6903\n",
      "Epoch 271/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.3289 - accuracy: 0.8537 - val_loss: 0.8270 - val_accuracy: 0.5841\n",
      "Epoch 272/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3010 - accuracy: 0.8714 - val_loss: 0.6807 - val_accuracy: 0.6814\n",
      "Epoch 273/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2602 - accuracy: 0.9069 - val_loss: 0.7032 - val_accuracy: 0.6726\n",
      "Epoch 274/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3297 - accuracy: 0.8359 - val_loss: 0.7394 - val_accuracy: 0.6549\n",
      "Epoch 275/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2739 - accuracy: 0.9024 - val_loss: 0.7212 - val_accuracy: 0.6726\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 188us/sample - loss: 0.2673 - accuracy: 0.9069 - val_loss: 0.7395 - val_accuracy: 0.6637\n",
      "Epoch 277/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2878 - accuracy: 0.8869 - val_loss: 0.7866 - val_accuracy: 0.6549\n",
      "Epoch 278/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3055 - accuracy: 0.8625 - val_loss: 0.7576 - val_accuracy: 0.6637\n",
      "Epoch 279/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.2913 - accuracy: 0.8803 - val_loss: 0.7467 - val_accuracy: 0.6637\n",
      "Epoch 280/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2944 - accuracy: 0.8692 - val_loss: 0.7114 - val_accuracy: 0.6814\n",
      "Epoch 281/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3350 - accuracy: 0.8248 - val_loss: 0.7537 - val_accuracy: 0.6549\n",
      "Epoch 282/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.2975 - accuracy: 0.8803 - val_loss: 0.6855 - val_accuracy: 0.6726\n",
      "Epoch 283/500\n",
      "451/451 [==============================] - 0s 191us/sample - loss: 0.2658 - accuracy: 0.9047 - val_loss: 0.7989 - val_accuracy: 0.6903\n",
      "Epoch 284/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3391 - accuracy: 0.8492 - val_loss: 0.6848 - val_accuracy: 0.6991\n",
      "Epoch 285/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2631 - accuracy: 0.9047 - val_loss: 0.7464 - val_accuracy: 0.6726\n",
      "Epoch 286/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2502 - accuracy: 0.9047 - val_loss: 0.6963 - val_accuracy: 0.6903\n",
      "Epoch 287/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2523 - accuracy: 0.9202 - val_loss: 0.7983 - val_accuracy: 0.6372\n",
      "Epoch 288/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.3187 - accuracy: 0.8603 - val_loss: 0.7419 - val_accuracy: 0.6903\n",
      "Epoch 289/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.2562 - accuracy: 0.9157 - val_loss: 0.7416 - val_accuracy: 0.6726\n",
      "Epoch 290/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3150 - accuracy: 0.8581 - val_loss: 0.7000 - val_accuracy: 0.6814\n",
      "Epoch 291/500\n",
      "451/451 [==============================] - 0s 176us/sample - loss: 0.2415 - accuracy: 0.9135 - val_loss: 0.7247 - val_accuracy: 0.6814\n",
      "Epoch 292/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3010 - accuracy: 0.8736 - val_loss: 0.7433 - val_accuracy: 0.6726\n",
      "Epoch 293/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2429 - accuracy: 0.9180 - val_loss: 0.7942 - val_accuracy: 0.6814\n",
      "Epoch 294/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.2701 - accuracy: 0.8869 - val_loss: 0.7338 - val_accuracy: 0.6903\n",
      "Epoch 295/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.2991 - accuracy: 0.8692 - val_loss: 0.6997 - val_accuracy: 0.6903\n",
      "Epoch 296/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.2487 - accuracy: 0.9246 - val_loss: 0.7417 - val_accuracy: 0.6637\n",
      "Epoch 297/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3475 - accuracy: 0.8404 - val_loss: 0.7240 - val_accuracy: 0.6814\n",
      "Epoch 298/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2428 - accuracy: 0.9290 - val_loss: 0.7226 - val_accuracy: 0.6991\n",
      "Epoch 299/500\n",
      "451/451 [==============================] - 0s 193us/sample - loss: 0.2418 - accuracy: 0.9202 - val_loss: 0.7305 - val_accuracy: 0.6726\n",
      "Epoch 300/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.2671 - accuracy: 0.8736 - val_loss: 0.7737 - val_accuracy: 0.6726\n",
      "Epoch 301/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2810 - accuracy: 0.9002 - val_loss: 0.7142 - val_accuracy: 0.6726\n",
      "Epoch 302/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2365 - accuracy: 0.9180 - val_loss: 0.7166 - val_accuracy: 0.6814\n",
      "Epoch 303/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2552 - accuracy: 0.9024 - val_loss: 0.7664 - val_accuracy: 0.6726\n",
      "Epoch 304/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2735 - accuracy: 0.8891 - val_loss: 0.7182 - val_accuracy: 0.6903\n",
      "Epoch 305/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2795 - accuracy: 0.8891 - val_loss: 0.7204 - val_accuracy: 0.6903\n",
      "Epoch 306/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2288 - accuracy: 0.9313 - val_loss: 0.8987 - val_accuracy: 0.6195\n",
      "Epoch 307/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3158 - accuracy: 0.8537 - val_loss: 0.7171 - val_accuracy: 0.6814\n",
      "Epoch 308/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2314 - accuracy: 0.9224 - val_loss: 0.7446 - val_accuracy: 0.6637\n",
      "Epoch 309/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2804 - accuracy: 0.8780 - val_loss: 0.7272 - val_accuracy: 0.6903\n",
      "Epoch 310/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2462 - accuracy: 0.8980 - val_loss: 0.7571 - val_accuracy: 0.6903\n",
      "Epoch 311/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2545 - accuracy: 0.9047 - val_loss: 0.7387 - val_accuracy: 0.6814\n",
      "Epoch 312/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2505 - accuracy: 0.9091 - val_loss: 0.7669 - val_accuracy: 0.6903\n",
      "Epoch 313/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2743 - accuracy: 0.8891 - val_loss: 0.7427 - val_accuracy: 0.6814\n",
      "Epoch 314/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2450 - accuracy: 0.9024 - val_loss: 0.7261 - val_accuracy: 0.6726\n",
      "Epoch 315/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2329 - accuracy: 0.9157 - val_loss: 0.8448 - val_accuracy: 0.6549\n",
      "Epoch 316/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3227 - accuracy: 0.8537 - val_loss: 0.7338 - val_accuracy: 0.6726\n",
      "Epoch 317/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2369 - accuracy: 0.9113 - val_loss: 0.7649 - val_accuracy: 0.6549\n",
      "Epoch 318/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2407 - accuracy: 0.9157 - val_loss: 0.7626 - val_accuracy: 0.6637\n",
      "Epoch 319/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2241 - accuracy: 0.9091 - val_loss: 0.7386 - val_accuracy: 0.6637\n",
      "Epoch 320/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2372 - accuracy: 0.9135 - val_loss: 0.8027 - val_accuracy: 0.6549\n",
      "Epoch 321/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.2224 - accuracy: 0.9113 - val_loss: 0.9488 - val_accuracy: 0.6106\n",
      "Epoch 322/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2823 - accuracy: 0.8714 - val_loss: 0.7271 - val_accuracy: 0.6903\n",
      "Epoch 323/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.2110 - accuracy: 0.9335 - val_loss: 0.7332 - val_accuracy: 0.6726\n",
      "Epoch 324/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2445 - accuracy: 0.9024 - val_loss: 0.8192 - val_accuracy: 0.6637\n",
      "Epoch 325/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2619 - accuracy: 0.9047 - val_loss: 0.7321 - val_accuracy: 0.6903\n",
      "Epoch 326/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2247 - accuracy: 0.9202 - val_loss: 0.7249 - val_accuracy: 0.6903\n",
      "Epoch 327/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2595 - accuracy: 0.9024 - val_loss: 0.8249 - val_accuracy: 0.6637\n",
      "Epoch 328/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2905 - accuracy: 0.8714 - val_loss: 0.8061 - val_accuracy: 0.6637\n",
      "Epoch 329/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2074 - accuracy: 0.9446 - val_loss: 0.7484 - val_accuracy: 0.6637\n",
      "Epoch 330/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2329 - accuracy: 0.9135 - val_loss: 0.8921 - val_accuracy: 0.6283\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2749 - accuracy: 0.8780 - val_loss: 0.7254 - val_accuracy: 0.6991\n",
      "Epoch 332/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2048 - accuracy: 0.9313 - val_loss: 0.7448 - val_accuracy: 0.6726\n",
      "Epoch 333/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2349 - accuracy: 0.9157 - val_loss: 0.7913 - val_accuracy: 0.7257\n",
      "Epoch 334/500\n",
      "451/451 [==============================] - 0s 189us/sample - loss: 0.2133 - accuracy: 0.9246 - val_loss: 0.7542 - val_accuracy: 0.6814\n",
      "Epoch 335/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2019 - accuracy: 0.9290 - val_loss: 0.7411 - val_accuracy: 0.6726\n",
      "Epoch 336/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2341 - accuracy: 0.9047 - val_loss: 0.8763 - val_accuracy: 0.6637\n",
      "Epoch 337/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3011 - accuracy: 0.8581 - val_loss: 0.7787 - val_accuracy: 0.6726\n",
      "Epoch 338/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.2139 - accuracy: 0.9268 - val_loss: 0.7483 - val_accuracy: 0.6814\n",
      "Epoch 339/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2272 - accuracy: 0.9069 - val_loss: 0.8532 - val_accuracy: 0.6726\n",
      "Epoch 340/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.2203 - accuracy: 0.9335 - val_loss: 0.7495 - val_accuracy: 0.6814\n",
      "Epoch 341/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2485 - accuracy: 0.9091 - val_loss: 0.7844 - val_accuracy: 0.6637\n",
      "Epoch 342/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2279 - accuracy: 0.9157 - val_loss: 0.7675 - val_accuracy: 0.6814\n",
      "Epoch 343/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1887 - accuracy: 0.9512 - val_loss: 0.7544 - val_accuracy: 0.6903\n",
      "Epoch 344/500\n",
      "451/451 [==============================] - 0s 187us/sample - loss: 0.2118 - accuracy: 0.9290 - val_loss: 0.7746 - val_accuracy: 0.6814\n",
      "Epoch 345/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.1984 - accuracy: 0.9246 - val_loss: 1.2088 - val_accuracy: 0.5487\n",
      "Epoch 346/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.3836 - accuracy: 0.8160 - val_loss: 0.7353 - val_accuracy: 0.6637\n",
      "Epoch 347/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1990 - accuracy: 0.9357 - val_loss: 0.8521 - val_accuracy: 0.6726\n",
      "Epoch 348/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2582 - accuracy: 0.8825 - val_loss: 0.7971 - val_accuracy: 0.6814\n",
      "Epoch 349/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.1951 - accuracy: 0.9424 - val_loss: 0.8643 - val_accuracy: 0.6903\n",
      "Epoch 350/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2955 - accuracy: 0.8692 - val_loss: 0.7689 - val_accuracy: 0.6903\n",
      "Epoch 351/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.1905 - accuracy: 0.9446 - val_loss: 0.7555 - val_accuracy: 0.6637\n",
      "Epoch 352/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1843 - accuracy: 0.9512 - val_loss: 0.7583 - val_accuracy: 0.6637\n",
      "Epoch 353/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1975 - accuracy: 0.9246 - val_loss: 0.7717 - val_accuracy: 0.6726\n",
      "Epoch 354/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3041 - accuracy: 0.8714 - val_loss: 0.8362 - val_accuracy: 0.6814\n",
      "Epoch 355/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2049 - accuracy: 0.9379 - val_loss: 0.7809 - val_accuracy: 0.6726\n",
      "Epoch 356/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2070 - accuracy: 0.9268 - val_loss: 0.7915 - val_accuracy: 0.6814\n",
      "Epoch 357/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1997 - accuracy: 0.9401 - val_loss: 0.7873 - val_accuracy: 0.6637\n",
      "Epoch 358/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2209 - accuracy: 0.9268 - val_loss: 0.9333 - val_accuracy: 0.6195\n",
      "Epoch 359/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2286 - accuracy: 0.9357 - val_loss: 0.8312 - val_accuracy: 0.6726\n",
      "Epoch 360/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2191 - accuracy: 0.9224 - val_loss: 0.7760 - val_accuracy: 0.6726\n",
      "Epoch 361/500\n",
      "451/451 [==============================] - 0s 193us/sample - loss: 0.1887 - accuracy: 0.9379 - val_loss: 0.7886 - val_accuracy: 0.6903\n",
      "Epoch 362/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2521 - accuracy: 0.8847 - val_loss: 0.7684 - val_accuracy: 0.6814\n",
      "Epoch 363/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.1785 - accuracy: 0.9512 - val_loss: 0.8129 - val_accuracy: 0.6726\n",
      "Epoch 364/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2008 - accuracy: 0.9224 - val_loss: 0.9045 - val_accuracy: 0.6372\n",
      "Epoch 365/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.2572 - accuracy: 0.8936 - val_loss: 0.7725 - val_accuracy: 0.6814\n",
      "Epoch 366/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1839 - accuracy: 0.9446 - val_loss: 0.7983 - val_accuracy: 0.6814\n",
      "Epoch 367/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1802 - accuracy: 0.9424 - val_loss: 0.8196 - val_accuracy: 0.6637\n",
      "Epoch 368/500\n",
      "451/451 [==============================] - 0s 189us/sample - loss: 0.1982 - accuracy: 0.9224 - val_loss: 0.8964 - val_accuracy: 0.6460\n",
      "Epoch 369/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3026 - accuracy: 0.8559 - val_loss: 0.7694 - val_accuracy: 0.6814\n",
      "Epoch 370/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1861 - accuracy: 0.9468 - val_loss: 0.8001 - val_accuracy: 0.6903\n",
      "Epoch 371/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.2071 - accuracy: 0.9290 - val_loss: 0.8838 - val_accuracy: 0.6814\n",
      "Epoch 372/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1941 - accuracy: 0.9313 - val_loss: 0.8147 - val_accuracy: 0.6814\n",
      "Epoch 373/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1920 - accuracy: 0.9313 - val_loss: 0.9196 - val_accuracy: 0.6814\n",
      "Epoch 374/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.2062 - accuracy: 0.9335 - val_loss: 0.7971 - val_accuracy: 0.6726\n",
      "Epoch 375/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2117 - accuracy: 0.9135 - val_loss: 0.8570 - val_accuracy: 0.6814\n",
      "Epoch 376/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.1958 - accuracy: 0.9424 - val_loss: 0.8000 - val_accuracy: 0.6814\n",
      "Epoch 377/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1659 - accuracy: 0.9623 - val_loss: 0.8269 - val_accuracy: 0.6637\n",
      "Epoch 378/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1938 - accuracy: 0.9335 - val_loss: 0.8426 - val_accuracy: 0.6814\n",
      "Epoch 379/500\n",
      "451/451 [==============================] - 0s 185us/sample - loss: 0.2871 - accuracy: 0.8625 - val_loss: 0.7806 - val_accuracy: 0.6726\n",
      "Epoch 380/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.1626 - accuracy: 0.9534 - val_loss: 0.7991 - val_accuracy: 0.6726\n",
      "Epoch 381/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1930 - accuracy: 0.9268 - val_loss: 0.9969 - val_accuracy: 0.6283\n",
      "Epoch 382/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2029 - accuracy: 0.9180 - val_loss: 0.8570 - val_accuracy: 0.6726\n",
      "Epoch 383/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1571 - accuracy: 0.9645 - val_loss: 0.8082 - val_accuracy: 0.6726\n",
      "Epoch 384/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2081 - accuracy: 0.9180 - val_loss: 0.9412 - val_accuracy: 0.6814\n",
      "Epoch 385/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2625 - accuracy: 0.8869 - val_loss: 0.8166 - val_accuracy: 0.6726\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 186us/sample - loss: 0.2081 - accuracy: 0.9246 - val_loss: 0.8169 - val_accuracy: 0.6549\n",
      "Epoch 387/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1890 - accuracy: 0.9379 - val_loss: 0.8616 - val_accuracy: 0.6814\n",
      "Epoch 388/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1712 - accuracy: 0.9401 - val_loss: 0.8079 - val_accuracy: 0.6726\n",
      "Epoch 389/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1667 - accuracy: 0.9446 - val_loss: 0.8247 - val_accuracy: 0.6903\n",
      "Epoch 390/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1778 - accuracy: 0.9357 - val_loss: 0.9090 - val_accuracy: 0.6991\n",
      "Epoch 391/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2191 - accuracy: 0.9135 - val_loss: 0.8268 - val_accuracy: 0.6726\n",
      "Epoch 392/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1798 - accuracy: 0.9335 - val_loss: 1.1174 - val_accuracy: 0.6195\n",
      "Epoch 393/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2059 - accuracy: 0.9202 - val_loss: 0.8054 - val_accuracy: 0.6726\n",
      "Epoch 394/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1537 - accuracy: 0.9623 - val_loss: 0.8592 - val_accuracy: 0.6726\n",
      "Epoch 395/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.1676 - accuracy: 0.9468 - val_loss: 1.0453 - val_accuracy: 0.6549\n",
      "Epoch 396/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2689 - accuracy: 0.8736 - val_loss: 0.8575 - val_accuracy: 0.6460\n",
      "Epoch 397/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.2278 - accuracy: 0.9024 - val_loss: 0.8120 - val_accuracy: 0.6814\n",
      "Epoch 398/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.1743 - accuracy: 0.9468 - val_loss: 0.8244 - val_accuracy: 0.6637\n",
      "Epoch 399/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1577 - accuracy: 0.9557 - val_loss: 0.8197 - val_accuracy: 0.6726\n",
      "Epoch 400/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1699 - accuracy: 0.9490 - val_loss: 0.9340 - val_accuracy: 0.6814\n",
      "Epoch 401/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.2088 - accuracy: 0.9113 - val_loss: 1.0079 - val_accuracy: 0.6549\n",
      "Epoch 402/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2549 - accuracy: 0.8891 - val_loss: 0.8215 - val_accuracy: 0.6726\n",
      "Epoch 403/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.1684 - accuracy: 0.9446 - val_loss: 0.8299 - val_accuracy: 0.6814\n",
      "Epoch 404/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.1585 - accuracy: 0.9601 - val_loss: 0.8444 - val_accuracy: 0.6726\n",
      "Epoch 405/500\n",
      "451/451 [==============================] - 0s 195us/sample - loss: 0.1893 - accuracy: 0.9290 - val_loss: 0.8353 - val_accuracy: 0.6637\n",
      "Epoch 406/500\n",
      "451/451 [==============================] - 0s 183us/sample - loss: 0.1582 - accuracy: 0.9579 - val_loss: 0.8356 - val_accuracy: 0.6726\n",
      "Epoch 407/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1559 - accuracy: 0.9623 - val_loss: 0.9313 - val_accuracy: 0.6460\n",
      "Epoch 408/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2571 - accuracy: 0.8825 - val_loss: 0.9565 - val_accuracy: 0.6549\n",
      "Epoch 409/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1737 - accuracy: 0.9490 - val_loss: 0.8234 - val_accuracy: 0.6726\n",
      "Epoch 410/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1491 - accuracy: 0.9623 - val_loss: 0.8438 - val_accuracy: 0.6726\n",
      "Epoch 411/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1392 - accuracy: 0.9579 - val_loss: 0.8241 - val_accuracy: 0.6637\n",
      "Epoch 412/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1534 - accuracy: 0.9490 - val_loss: 0.9219 - val_accuracy: 0.6637\n",
      "Epoch 413/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.2398 - accuracy: 0.8958 - val_loss: 0.8355 - val_accuracy: 0.6726\n",
      "Epoch 414/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.1440 - accuracy: 0.9623 - val_loss: 0.8318 - val_accuracy: 0.6726\n",
      "Epoch 415/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.1669 - accuracy: 0.9468 - val_loss: 0.9373 - val_accuracy: 0.6549\n",
      "Epoch 416/500\n",
      "451/451 [==============================] - 0s 190us/sample - loss: 0.1931 - accuracy: 0.9268 - val_loss: 0.9387 - val_accuracy: 0.6372\n",
      "Epoch 417/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1685 - accuracy: 0.9490 - val_loss: 0.8406 - val_accuracy: 0.6726\n",
      "Epoch 418/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1563 - accuracy: 0.9557 - val_loss: 0.8572 - val_accuracy: 0.6726\n",
      "Epoch 419/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.2151 - accuracy: 0.9091 - val_loss: 1.2322 - val_accuracy: 0.5841\n",
      "Epoch 420/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.2343 - accuracy: 0.9047 - val_loss: 0.8186 - val_accuracy: 0.6726\n",
      "Epoch 421/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1510 - accuracy: 0.9601 - val_loss: 0.8378 - val_accuracy: 0.6726\n",
      "Epoch 422/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1426 - accuracy: 0.9601 - val_loss: 0.8397 - val_accuracy: 0.6726\n",
      "Epoch 423/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1851 - accuracy: 0.9335 - val_loss: 0.9864 - val_accuracy: 0.6726\n",
      "Epoch 424/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.2020 - accuracy: 0.9268 - val_loss: 0.8290 - val_accuracy: 0.6726\n",
      "Epoch 425/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1441 - accuracy: 0.9601 - val_loss: 0.8365 - val_accuracy: 0.6726\n",
      "Epoch 426/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1342 - accuracy: 0.9690 - val_loss: 0.8541 - val_accuracy: 0.6726\n",
      "Epoch 427/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1465 - accuracy: 0.9468 - val_loss: 1.2692 - val_accuracy: 0.5664\n",
      "Epoch 428/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.3192 - accuracy: 0.8559 - val_loss: 0.8734 - val_accuracy: 0.6726\n",
      "Epoch 429/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1340 - accuracy: 0.9667 - val_loss: 0.9126 - val_accuracy: 0.6814\n",
      "Epoch 430/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1366 - accuracy: 0.9667 - val_loss: 0.8545 - val_accuracy: 0.6903\n",
      "Epoch 431/500\n",
      "451/451 [==============================] - 0s 187us/sample - loss: 0.1300 - accuracy: 0.9623 - val_loss: 0.8612 - val_accuracy: 0.6814\n",
      "Epoch 432/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.1273 - accuracy: 0.9712 - val_loss: 0.8470 - val_accuracy: 0.6726\n",
      "Epoch 433/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1457 - accuracy: 0.9512 - val_loss: 1.0412 - val_accuracy: 0.6460\n",
      "Epoch 434/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2569 - accuracy: 0.8869 - val_loss: 0.9550 - val_accuracy: 0.6637\n",
      "Epoch 435/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.1739 - accuracy: 0.9424 - val_loss: 0.8575 - val_accuracy: 0.6726\n",
      "Epoch 436/500\n",
      "451/451 [==============================] - 0s 188us/sample - loss: 0.1253 - accuracy: 0.9712 - val_loss: 0.8647 - val_accuracy: 0.6814\n",
      "Epoch 437/500\n",
      "451/451 [==============================] - 0s 189us/sample - loss: 0.1510 - accuracy: 0.9557 - val_loss: 0.9521 - val_accuracy: 0.6726\n",
      "Epoch 438/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1757 - accuracy: 0.9335 - val_loss: 0.9701 - val_accuracy: 0.6549\n",
      "Epoch 439/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1710 - accuracy: 0.9357 - val_loss: 0.9301 - val_accuracy: 0.6814\n",
      "Epoch 440/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1397 - accuracy: 0.9579 - val_loss: 0.8992 - val_accuracy: 0.6726\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1766 - accuracy: 0.9335 - val_loss: 1.2176 - val_accuracy: 0.5929\n",
      "Epoch 442/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1827 - accuracy: 0.9335 - val_loss: 0.8931 - val_accuracy: 0.6903\n",
      "Epoch 443/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1203 - accuracy: 0.9667 - val_loss: 0.8654 - val_accuracy: 0.6726\n",
      "Epoch 444/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.1540 - accuracy: 0.9490 - val_loss: 0.9787 - val_accuracy: 0.6726\n",
      "Epoch 445/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1479 - accuracy: 0.9357 - val_loss: 0.9261 - val_accuracy: 0.6549\n",
      "Epoch 446/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1742 - accuracy: 0.9313 - val_loss: 0.8761 - val_accuracy: 0.6637\n",
      "Epoch 447/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.1274 - accuracy: 0.9645 - val_loss: 1.0093 - val_accuracy: 0.6460\n",
      "Epoch 448/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1897 - accuracy: 0.9224 - val_loss: 0.9275 - val_accuracy: 0.6549\n",
      "Epoch 449/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1382 - accuracy: 0.9645 - val_loss: 0.8799 - val_accuracy: 0.6637\n",
      "Epoch 450/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1827 - accuracy: 0.9335 - val_loss: 0.8786 - val_accuracy: 0.6726\n",
      "Epoch 451/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1506 - accuracy: 0.9512 - val_loss: 0.9272 - val_accuracy: 0.6726\n",
      "Epoch 452/500\n",
      "451/451 [==============================] - 0s 179us/sample - loss: 0.1476 - accuracy: 0.9534 - val_loss: 0.9395 - val_accuracy: 0.6726\n",
      "Epoch 453/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2304 - accuracy: 0.8847 - val_loss: 1.0912 - val_accuracy: 0.6460\n",
      "Epoch 454/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1639 - accuracy: 0.9468 - val_loss: 0.8609 - val_accuracy: 0.6726\n",
      "Epoch 455/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.8621 - val_accuracy: 0.6637\n",
      "Epoch 456/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1232 - accuracy: 0.9778 - val_loss: 0.8658 - val_accuracy: 0.6726\n",
      "Epoch 457/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1287 - accuracy: 0.9645 - val_loss: 0.8927 - val_accuracy: 0.6814\n",
      "Epoch 458/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1346 - accuracy: 0.9557 - val_loss: 1.1873 - val_accuracy: 0.6283\n",
      "Epoch 459/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.2616 - accuracy: 0.8780 - val_loss: 1.0280 - val_accuracy: 0.6460\n",
      "Epoch 460/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1295 - accuracy: 0.9579 - val_loss: 0.8803 - val_accuracy: 0.6726\n",
      "Epoch 461/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.1258 - accuracy: 0.9645 - val_loss: 0.9582 - val_accuracy: 0.6726\n",
      "Epoch 462/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1415 - accuracy: 0.9534 - val_loss: 0.9374 - val_accuracy: 0.6726\n",
      "Epoch 463/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1388 - accuracy: 0.9512 - val_loss: 0.9854 - val_accuracy: 0.6460\n",
      "Epoch 464/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1221 - accuracy: 0.9690 - val_loss: 0.8981 - val_accuracy: 0.6726\n",
      "Epoch 465/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1122 - accuracy: 0.9734 - val_loss: 0.9290 - val_accuracy: 0.6814\n",
      "Epoch 466/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.2526 - accuracy: 0.8891 - val_loss: 1.0711 - val_accuracy: 0.6372\n",
      "Epoch 467/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1292 - accuracy: 0.9645 - val_loss: 0.8711 - val_accuracy: 0.6726\n",
      "Epoch 468/500\n",
      "451/451 [==============================] - 0s 181us/sample - loss: 0.1045 - accuracy: 0.9734 - val_loss: 0.8827 - val_accuracy: 0.6903\n",
      "Epoch 469/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.1055 - accuracy: 0.9800 - val_loss: 0.8858 - val_accuracy: 0.6637\n",
      "Epoch 470/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1141 - accuracy: 0.9778 - val_loss: 1.0088 - val_accuracy: 0.6814\n",
      "Epoch 471/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.3377 - accuracy: 0.8514 - val_loss: 0.8753 - val_accuracy: 0.6814\n",
      "Epoch 472/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.1270 - accuracy: 0.9579 - val_loss: 0.9651 - val_accuracy: 0.6726\n",
      "Epoch 473/500\n",
      "451/451 [==============================] - 0s 186us/sample - loss: 0.1103 - accuracy: 0.9756 - val_loss: 0.8820 - val_accuracy: 0.6549\n",
      "Epoch 474/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1148 - accuracy: 0.9712 - val_loss: 0.9359 - val_accuracy: 0.6549\n",
      "Epoch 475/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1671 - accuracy: 0.9379 - val_loss: 0.9256 - val_accuracy: 0.6637\n",
      "Epoch 476/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1206 - accuracy: 0.9734 - val_loss: 0.9255 - val_accuracy: 0.6549\n",
      "Epoch 477/500\n",
      "451/451 [==============================] - 0s 184us/sample - loss: 0.1681 - accuracy: 0.9290 - val_loss: 0.8882 - val_accuracy: 0.6814\n",
      "Epoch 478/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1269 - accuracy: 0.9623 - val_loss: 0.9022 - val_accuracy: 0.6726\n",
      "Epoch 479/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1312 - accuracy: 0.9579 - val_loss: 1.1706 - val_accuracy: 0.6549\n",
      "Epoch 480/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1999 - accuracy: 0.9180 - val_loss: 0.9219 - val_accuracy: 0.6814\n",
      "Epoch 481/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1190 - accuracy: 0.9690 - val_loss: 0.9250 - val_accuracy: 0.6726\n",
      "Epoch 482/500\n",
      "451/451 [==============================] - 0s 176us/sample - loss: 0.1014 - accuracy: 0.9800 - val_loss: 0.9143 - val_accuracy: 0.6814\n",
      "Epoch 483/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.1360 - accuracy: 0.9490 - val_loss: 1.0150 - val_accuracy: 0.6637\n",
      "Epoch 484/500\n",
      "451/451 [==============================] - 0s 176us/sample - loss: 0.1069 - accuracy: 0.9712 - val_loss: 0.9914 - val_accuracy: 0.6549\n",
      "Epoch 485/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1634 - accuracy: 0.9379 - val_loss: 1.0592 - val_accuracy: 0.6372\n",
      "Epoch 486/500\n",
      "451/451 [==============================] - 0s 178us/sample - loss: 0.1454 - accuracy: 0.9424 - val_loss: 0.8980 - val_accuracy: 0.6903\n",
      "Epoch 487/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1100 - accuracy: 0.9734 - val_loss: 1.0000 - val_accuracy: 0.6637\n",
      "Epoch 488/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1592 - accuracy: 0.9313 - val_loss: 0.9014 - val_accuracy: 0.6637\n",
      "Epoch 489/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.0995 - accuracy: 0.9823 - val_loss: 0.9024 - val_accuracy: 0.6726\n",
      "Epoch 490/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1178 - accuracy: 0.9557 - val_loss: 1.3215 - val_accuracy: 0.5752\n",
      "Epoch 491/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.2558 - accuracy: 0.8803 - val_loss: 0.9026 - val_accuracy: 0.6726\n",
      "Epoch 492/500\n",
      "451/451 [==============================] - 0s 182us/sample - loss: 0.1105 - accuracy: 0.9712 - val_loss: 0.9126 - val_accuracy: 0.6726\n",
      "Epoch 493/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1475 - accuracy: 0.9557 - val_loss: 0.9700 - val_accuracy: 0.6726\n",
      "Epoch 494/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.1195 - accuracy: 0.9623 - val_loss: 0.9082 - val_accuracy: 0.6637\n",
      "Epoch 495/500\n",
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1739 - accuracy: 0.9379 - val_loss: 0.9343 - val_accuracy: 0.6726\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 177us/sample - loss: 0.1145 - accuracy: 0.9734 - val_loss: 0.9064 - val_accuracy: 0.6726\n",
      "Epoch 497/500\n",
      "451/451 [==============================] - 0s 180us/sample - loss: 0.1047 - accuracy: 0.9712 - val_loss: 0.9110 - val_accuracy: 0.7168\n",
      "Epoch 498/500\n",
      "451/451 [==============================] - 0s 175us/sample - loss: 0.1027 - accuracy: 0.9778 - val_loss: 1.0033 - val_accuracy: 0.6726\n",
      "Epoch 499/500\n",
      "451/451 [==============================] - 0s 173us/sample - loss: 0.2492 - accuracy: 0.8825 - val_loss: 0.8969 - val_accuracy: 0.6726\n",
      "Epoch 500/500\n",
      "451/451 [==============================] - 0s 173us/sample - loss: 0.1312 - accuracy: 0.9557 - val_loss: 0.9349 - val_accuracy: 0.6549\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Training\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 500\n",
    "input_shape = (sequence_length, image_size,image_size,3)\n",
    "model = createConvLstmModel(input_shape, num_classes)\n",
    "\n",
    "history = model.fit(x_train_2, y_train_2,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test_2, y_test_2),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24bc3afcc08>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.set_title(\"LSTM classification, arithmetic\")\n",
    "ax.set_ylim((0.4,1))\n",
    "ax.set_yticks(np.arange(0.4,1,0.05))\n",
    "ax.grid()\n",
    "ax.plot(history.history['accuracy'])\n",
    "ax.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Simple LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "frame_length = 1\n",
    "sequence_length = 6\n",
    "overlap = 0.5\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file information: UJing 1 1 EasyAdd\n",
      "file information: UJing 1 2 HardMult\n",
      "file information: UJing 1 3 EasyAdd\n",
      "file information: UJing 1 4 HardMult\n",
      "file information: UJing 1 5 EasyAdd\n",
      "file information: UJing 1 6 HardMult\n",
      "file information: UJing 1 7 EasyAdd\n",
      "file information: UJing 1 8 HardMult\n",
      "file information: UJing 1 9 EasyAdd\n",
      "file information: UJing 1 10 HardMult\n",
      "file information: UJing 1 11 EasyAdd\n",
      "file information: UJing 1 12 HardMult\n",
      "file information: UJing 2 1 EasyAdd\n",
      "file information: UJing 2 2 HardMult\n",
      "file information: UJing 2 3 EasyAdd\n",
      "file information: UJing 2 4 HardMult\n",
      "file information: UJing 2 5 EasyAdd\n",
      "file information: UJing 2 6 HardMult\n",
      "file information: UJing 2 7 EasyAdd\n",
      "file information: UJing 2 8 HardMult\n",
      "file information: UJing 2 9 EasyAdd\n",
      "file information: UJing 2 10 HardMult\n",
      "file information: UJing 2 11 EasyAdd\n",
      "file information: UJing 2 12 HardMult\n",
      "file information: UJing 3 1 EasyAdd\n",
      "file information: UJing 3 2 HardMult\n",
      "file information: UJing 3 3 EasyAdd\n",
      "file information: UJing 3 4 HardMult\n",
      "file information: UJing 3 5 EasyAdd\n",
      "file information: UJing 3 6 HardMult\n",
      "file information: UJing 3 7 EasyAdd\n",
      "file information: UJing 3 8 HardMult\n",
      "file information: UJing 3 9 EasyAdd\n",
      "file information: UJing 3 10 HardMult\n",
      "file information: UJing 3 11 EasyAdd\n",
      "file information: UJing 3 12 HardMult\n",
      "file information: UJuan 1 1 EasyAdd\n",
      "file information: UJuan 1 2 HardMult\n",
      "file information: UJuan 1 3 EasyAdd\n",
      "file information: UJuan 1 4 HardMult\n",
      "file information: UJuan 1 5 EasyAdd\n",
      "file information: UJuan 1 6 HardMult\n",
      "file information: UJuan 1 7 EasyAdd\n",
      "file information: UJuan 1 8 HardMult\n",
      "file information: UJuan 1 9 EasyAdd\n",
      "file information: UJuan 1 10 HardMult\n",
      "file information: UJuan 1 11 EasyAdd\n",
      "file information: UJuan 1 12 HardMult\n",
      "file information: UJuan 2 1 EasyAdd\n",
      "file information: UJuan 2 2 HardMult\n",
      "file information: UJuan 2 3 EasyAdd\n",
      "file information: UJuan 2 4 HardMult\n",
      "file information: UJuan 2 5 EasyAdd\n",
      "file information: UJuan 2 6 HardMult\n",
      "file information: UJuan 2 7 EasyAdd\n",
      "file information: UJuan 2 8 HardMult\n",
      "file information: UJuan 2 9 EasyAdd\n",
      "file information: UJuan 2 10 HardMult\n",
      "file information: UJuan 2 11 EasyAdd\n",
      "file information: UJuan 2 12 HardMult\n"
     ]
    }
   ],
   "source": [
    "dataPath = Path(r\"C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiments3-Data\\ArithmeticCalibrationProcedure\\edf\")\n",
    "X_arith_seq, y_arith_seq = createImageDataset(dataPath,imageSize=image_size,frameDuration=frame_length,overlap=overlap,\n",
    "                           image_format=False, augment_data=False, labels = [\"EasyAdd\",\"HardMult\"],\n",
    "                           lstm_format=True, lstm_sequence_length=sequence_length,\n",
    "                           fileNameFormat=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_arith_seq, y_arith_seq, test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451,)\n",
      "(451, 6, 90)\n"
     ]
    }
   ],
   "source": [
    "##Normalize the dataset\n",
    "\n",
    "##No normalization -- Seems to yield the best results \n",
    "# x_train_2 = x_train\n",
    "# x_test_2 = x_test\n",
    "\n",
    "##Global frame/time normalization\n",
    "global_mean = x_train.mean(); global_std = x_train.std();\n",
    "x_train_2 = (x_train - global_mean)/global_std;\n",
    "x_test_2 = (x_test - global_mean)/global_std;\n",
    "\n",
    "## convert class vectors to binary class matrices\n",
    "y_train_2 = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_2 = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train_2 = x_train_2.astype('float32')\n",
    "x_test_2 = x_test_2.astype('float32')\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 451 samples, validate on 113 samples\n",
      "Epoch 1/500\n",
      "128/451 [=======>......................] - ETA: 16s"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(768, 90), b.shape=(90, 64), m=768, n=64, k=90\n\t [[node model/dense/Tensordot/MatMul (defined at <ipython-input-7-a57c89a920f8>:12) ]] [Op:__inference_distributed_function_11992]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a57c89a920f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m           shuffle=True)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mC:\\Users\\asus\\anaconda3\\envs\\keras-gpu-env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(768, 90), b.shape=(90, 64), m=768, n=64, k=90\n\t [[node model/dense/Tensordot/MatMul (defined at <ipython-input-7-a57c89a920f8>:12) ]] [Op:__inference_distributed_function_11992]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "##Training\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 500\n",
    "input_shape = (sequence_length,90)\n",
    "model = createLstmModel(input_shape, num_classes)\n",
    "\n",
    "history = model.fit(x_train_2, y_train_2,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test_2, y_test_2),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.set_title(\"Simple LSTM classification, arithmetic\")\n",
    "ax.set_ylim((0.4,1))\n",
    "ax.set_yticks(np.arange(0.4,1,0.05))\n",
    "ax.grid()\n",
    "ax.plot(history.history['accuracy'])\n",
    "ax.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file information: UJing 1 1 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 2 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 1 3 EasyAdd\n",
      "Interpolating 60/60Interpolating 31/6060 frames generated with label  0.0\n",
      "file information: UJing 1 4 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 1 5 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 6 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 51/60\n",
      "file information: UJing 1 7 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 8 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 1 9 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 10 HardMult\n",
      "Interpolating 60/60Interpolating 30/6060 frames generated with label  1.0\n",
      "file information: UJing 1 11 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 1 12 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 1 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 58/60\n",
      "file information: UJing 2 2 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 59/60\n",
      "file information: UJing 2 3 EasyAdd\n",
      "Interpolating 60/60Interpolating 32/6060 frames generated with label  0.0\n",
      "file information: UJing 2 4 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 60/60\n",
      "file information: UJing 2 5 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 6 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 33/60Interpolating 52/60\n",
      "file information: UJing 2 7 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 8 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 9 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 41/60\n",
      "file information: UJing 2 10 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 2 11 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJing 2 12 HardMult\n",
      "60 frames generated with label  1.0/60\n",
      "file information: UJing 3 1 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 59/70\n",
      "file information: UJing 3 2 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 63/70\n",
      "file information: UJing 3 3 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 64/70\n",
      "file information: UJing 3 4 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 58/70\n",
      "file information: UJing 3 5 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 59/70\n",
      "file information: UJing 3 6 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 60/70\n",
      "file information: UJing 3 7 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 54/70\n",
      "file information: UJing 3 8 HardMult\n",
      "70 frames generated with label  1.0/70\n",
      "file information: UJing 3 9 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 59/70\n",
      "file information: UJing 3 10 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 62/70\n",
      "file information: UJing 3 11 EasyAdd\n",
      "70 frames generated with label  0.0/70Interpolating 61/70\n",
      "file information: UJing 3 12 HardMult\n",
      "70 frames generated with label  1.0/70Interpolating 65/70\n",
      "file information: UJuan 1 1 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 2 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 56/60\n",
      "file information: UJuan 1 3 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 54/60\n",
      "file information: UJuan 1 4 HardMult\n",
      "Interpolating 60/60Interpolating 33/6060 frames generated with label  1.0\n",
      "file information: UJuan 1 5 EasyAdd\n",
      "60 frames generated with label  0.0\n",
      "file information: UJuan 1 6 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 50/60\n",
      "file information: UJuan 1 7 EasyAdd\n",
      "Interpolating 60/6060 frames generated with label  0.0\n",
      "file information: UJuan 1 8 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 60/60\n",
      "file information: UJuan 1 9 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 57/60\n",
      "file information: UJuan 1 10 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 57/60\n",
      "file information: UJuan 1 11 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 1 12 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 60/60\n",
      "file information: UJuan 2 1 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 51/60\n",
      "file information: UJuan 2 2 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 52/60\n",
      "file information: UJuan 2 3 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 4 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 57/60\n",
      "file information: UJuan 2 5 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 60/60\n",
      "file information: UJuan 2 6 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 58/60\n",
      "file information: UJuan 2 7 EasyAdd\n",
      "60 frames generated with label  0.0/60\n",
      "file information: UJuan 2 8 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 60/60\n",
      "file information: UJuan 2 9 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 54/60\n",
      "file information: UJuan 2 10 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 59/60\n",
      "file information: UJuan 2 11 EasyAdd\n",
      "60 frames generated with label  0.0/60Interpolating 41/60\n",
      "file information: UJuan 2 12 HardMult\n",
      "60 frames generated with label  1.0/60Interpolating 60/60\n"
     ]
    }
   ],
   "source": [
    "img_size = 32\n",
    "frame_duration = 1\n",
    "overlap = 0.5\n",
    "lstm_length = 5\n",
    "autoencoder = keras.models.load_model('autoEncoderWeights/autoencoder.h5')\n",
    "encoder = autoencoder.layers[1]\n",
    "\n",
    "dataPath = Path(r\"C:\\Users\\asus\\OneDrive - purdue.edu\\RealtimeProject\\Experiments3-Data\\ArithmeticCalibrationProcedure\\edf\")\n",
    "X_arithm_encoded, y_arithm_encoded = createImageDataset(dataPath, imageSize=img_size,frameDuration=frame_duration,overlap=overlap,\n",
    "                                      image_format=True, augment_data=False, labels = [\"EasyAdd\",\"HardMult\"],\n",
    "                                      encoded_format=True, autoencoder=encoder,lstm_format=True, lstm_sequence_length=lstm_length,\n",
    "                                      fileNameFormat=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(684, 5, 512)\n",
      "(547, 5, 512)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_arithm_encoded, y_arithm_encoded, test_size=0.20,shuffle=True)\n",
    "print(X_arithm_encoded.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547,)\n",
      "(547, 5, 512)\n"
     ]
    }
   ],
   "source": [
    "##Global frame/time normalization\n",
    "global_mean = x_train.mean(); global_std = x_train.std();\n",
    "x_train_2 = (x_train - global_mean)/global_std;\n",
    "x_test_2 = (x_test - global_mean)/global_std;\n",
    "\n",
    "## convert class vectors to binary class matrices\n",
    "y_train_2 = keras.utils.to_categorical(y_train, 2)\n",
    "y_test_2 = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "x_train_2 = x_train_2.astype('float32')\n",
    "x_test_2 = x_test_2.astype('float32')\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 5, 512)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5, 64)             32832     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 5, 64)             256       \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 5, 8)              2208      \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 35,730\n",
      "Trainable params: 35,602\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def createLstmModel(input_shape,num_classes, lstmLayers=2, lstmOutputSize=4.0,\n",
    "                  isBidirectional=1.0, inputLayerNeurons=64, inputLayerDropout=0.25):\n",
    "\n",
    "    dropoutRate = 0.45\n",
    "    \n",
    "    lstmLayers = int(lstmLayers)\n",
    "    lstmOutputSize =int(lstmOutputSize)\n",
    "    isBidirectional =int(isBidirectional)\n",
    "\n",
    "    # Input layer\n",
    "    networkInput = Input(shape=input_shape)\n",
    "    dropout1 = Dropout(rate=inputLayerDropout)(networkInput)\n",
    "\n",
    "    # First Hidden layer\n",
    "    hidden1 = Dense(inputLayerNeurons, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(rate=dropoutRate)(hidden1)\n",
    "    batchNorm1 = BatchNormalization()(dropout2)\n",
    "\n",
    "    out = batchNorm1\n",
    "    for i in range(1, lstmLayers+1):\n",
    "        retSeq = False if i == lstmLayers else True\n",
    "        lstmLayer = LSTM(lstmOutputSize, stateful=False, return_sequences=retSeq,\n",
    "                         dropout=dropoutRate, kernel_regularizer=regularizers.l2(0.05))\n",
    "        if isBidirectional:\n",
    "            out = Bidirectional(lstmLayer, merge_mode='concat')(out)\n",
    "        else:\n",
    "            out = lstmLayer(out)\n",
    "\n",
    "    hidden3 = Dense(num_classes, activation='linear')(out)\n",
    "    networkOutput = Softmax()(hidden3)\n",
    "\n",
    "    model1 = Model(inputs=networkInput, outputs=networkOutput)\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model1\n",
    "\n",
    "lstmModel = createLstmModel(x_train_2.shape[1:], 2)\n",
    "lstmModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 547 samples, validate on 137 samples\n",
      "Epoch 1/500\n",
      "547/547 [==============================] - 8s 15ms/sample - loss: 4.3502 - accuracy: 0.5338 - val_loss: 4.2311 - val_accuracy: 0.5328\n",
      "Epoch 2/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 4.1782 - accuracy: 0.5082 - val_loss: 4.0668 - val_accuracy: 0.5328\n",
      "Epoch 3/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 4.0165 - accuracy: 0.5210 - val_loss: 3.9059 - val_accuracy: 0.5255\n",
      "Epoch 4/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 3.8624 - accuracy: 0.5320 - val_loss: 3.7503 - val_accuracy: 0.5474\n",
      "Epoch 5/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 3.7129 - accuracy: 0.5338 - val_loss: 3.6022 - val_accuracy: 0.5693\n",
      "Epoch 6/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 3.5711 - accuracy: 0.5155 - val_loss: 3.4613 - val_accuracy: 0.5620\n",
      "Epoch 7/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 3.4241 - accuracy: 0.5740 - val_loss: 3.3262 - val_accuracy: 0.5766\n",
      "Epoch 8/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 3.2970 - accuracy: 0.5539 - val_loss: 3.1957 - val_accuracy: 0.5839\n",
      "Epoch 9/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 3.1680 - accuracy: 0.6015 - val_loss: 3.0713 - val_accuracy: 0.6131\n",
      "Epoch 10/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 3.0473 - accuracy: 0.6033 - val_loss: 2.9533 - val_accuracy: 0.6277\n",
      "Epoch 11/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 2.9361 - accuracy: 0.5960 - val_loss: 2.8427 - val_accuracy: 0.6131\n",
      "Epoch 12/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 2.8245 - accuracy: 0.5850 - val_loss: 2.7378 - val_accuracy: 0.6350\n",
      "Epoch 13/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 2.7251 - accuracy: 0.5430 - val_loss: 2.6377 - val_accuracy: 0.6277\n",
      "Epoch 14/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 2.6228 - accuracy: 0.5850 - val_loss: 2.5419 - val_accuracy: 0.6496\n",
      "Epoch 15/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 2.5263 - accuracy: 0.6088 - val_loss: 2.4518 - val_accuracy: 0.6423\n",
      "Epoch 16/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 2.4438 - accuracy: 0.5704 - val_loss: 2.3646 - val_accuracy: 0.6496\n",
      "Epoch 17/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 2.3605 - accuracy: 0.5759 - val_loss: 2.2806 - val_accuracy: 0.6715\n",
      "Epoch 18/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 2.2758 - accuracy: 0.5558 - val_loss: 2.2026 - val_accuracy: 0.6423\n",
      "Epoch 19/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 2.1972 - accuracy: 0.6051 - val_loss: 2.1296 - val_accuracy: 0.6423\n",
      "Epoch 20/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 2.1252 - accuracy: 0.5850 - val_loss: 2.0581 - val_accuracy: 0.6350\n",
      "Epoch 21/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 2.0482 - accuracy: 0.5996 - val_loss: 1.9905 - val_accuracy: 0.6350\n",
      "Epoch 22/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 1.9795 - accuracy: 0.6307 - val_loss: 1.9264 - val_accuracy: 0.6423\n",
      "Epoch 23/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 1.9160 - accuracy: 0.6252 - val_loss: 1.8648 - val_accuracy: 0.6423\n",
      "Epoch 24/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 1.8537 - accuracy: 0.6325 - val_loss: 1.8050 - val_accuracy: 0.6569\n",
      "Epoch 25/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.7902 - accuracy: 0.6252 - val_loss: 1.7464 - val_accuracy: 0.6569\n",
      "Epoch 26/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.7406 - accuracy: 0.6380 - val_loss: 1.6924 - val_accuracy: 0.6496\n",
      "Epoch 27/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.6913 - accuracy: 0.6143 - val_loss: 1.6425 - val_accuracy: 0.6569\n",
      "Epoch 28/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.6427 - accuracy: 0.6051 - val_loss: 1.5947 - val_accuracy: 0.6642\n",
      "Epoch 29/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 1.5875 - accuracy: 0.6490 - val_loss: 1.5461 - val_accuracy: 0.6642\n",
      "Epoch 30/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 1.5444 - accuracy: 0.6234 - val_loss: 1.4977 - val_accuracy: 0.6350\n",
      "Epoch 31/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 1.4965 - accuracy: 0.6819 - val_loss: 1.4513 - val_accuracy: 0.6569\n",
      "Epoch 32/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.4577 - accuracy: 0.6344 - val_loss: 1.4098 - val_accuracy: 0.6569\n",
      "Epoch 33/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 1.4230 - accuracy: 0.6106 - val_loss: 1.3716 - val_accuracy: 0.6642\n",
      "Epoch 34/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.3853 - accuracy: 0.6362 - val_loss: 1.3367 - val_accuracy: 0.6642\n",
      "Epoch 35/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 1.3390 - accuracy: 0.6490 - val_loss: 1.3025 - val_accuracy: 0.6423\n",
      "Epoch 36/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.3083 - accuracy: 0.6764 - val_loss: 1.2683 - val_accuracy: 0.6788\n",
      "Epoch 37/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.2658 - accuracy: 0.6691 - val_loss: 1.2355 - val_accuracy: 0.6642\n",
      "Epoch 38/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.2485 - accuracy: 0.6399 - val_loss: 1.2052 - val_accuracy: 0.6642\n",
      "Epoch 39/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 1.2146 - accuracy: 0.6472 - val_loss: 1.1794 - val_accuracy: 0.6423\n",
      "Epoch 40/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 1.1747 - accuracy: 0.6801 - val_loss: 1.1536 - val_accuracy: 0.6642\n",
      "Epoch 41/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.1470 - accuracy: 0.6563 - val_loss: 1.1286 - val_accuracy: 0.6642\n",
      "Epoch 42/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.1273 - accuracy: 0.6618 - val_loss: 1.1069 - val_accuracy: 0.6496\n",
      "Epoch 43/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 1.0938 - accuracy: 0.6874 - val_loss: 1.0791 - val_accuracy: 0.6788\n",
      "Epoch 44/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 1.0703 - accuracy: 0.6746 - val_loss: 1.0498 - val_accuracy: 0.6861\n",
      "Epoch 45/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 1.0510 - accuracy: 0.6746 - val_loss: 1.0296 - val_accuracy: 0.6861\n",
      "Epoch 46/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 1.0420 - accuracy: 0.6453 - val_loss: 1.0104 - val_accuracy: 0.6934\n",
      "Epoch 47/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 1.0112 - accuracy: 0.6819 - val_loss: 0.9935 - val_accuracy: 0.6569\n",
      "Epoch 48/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.9928 - accuracy: 0.6673 - val_loss: 0.9659 - val_accuracy: 0.7080\n",
      "Epoch 49/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.9493 - accuracy: 0.7075 - val_loss: 0.9395 - val_accuracy: 0.7007\n",
      "Epoch 50/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.9519 - accuracy: 0.6709 - val_loss: 0.9233 - val_accuracy: 0.6861\n",
      "Epoch 51/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.9349 - accuracy: 0.6709 - val_loss: 0.9055 - val_accuracy: 0.7080\n",
      "Epoch 52/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.9011 - accuracy: 0.6965 - val_loss: 0.8878 - val_accuracy: 0.7153\n",
      "Epoch 53/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.9114 - accuracy: 0.6545 - val_loss: 0.8718 - val_accuracy: 0.7080\n",
      "Epoch 54/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.8885 - accuracy: 0.6673 - val_loss: 0.8608 - val_accuracy: 0.7226\n",
      "Epoch 55/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.8727 - accuracy: 0.7002 - val_loss: 0.8551 - val_accuracy: 0.6788\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 167us/sample - loss: 0.8503 - accuracy: 0.7002 - val_loss: 0.8435 - val_accuracy: 0.6642\n",
      "Epoch 57/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.8385 - accuracy: 0.6910 - val_loss: 0.8284 - val_accuracy: 0.6861\n",
      "Epoch 58/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.8078 - accuracy: 0.7075 - val_loss: 0.8151 - val_accuracy: 0.7007\n",
      "Epoch 59/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.8093 - accuracy: 0.7057 - val_loss: 0.8004 - val_accuracy: 0.6715\n",
      "Epoch 60/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.8063 - accuracy: 0.7093 - val_loss: 0.7877 - val_accuracy: 0.7080\n",
      "Epoch 61/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.7814 - accuracy: 0.7093 - val_loss: 0.7920 - val_accuracy: 0.6496\n",
      "Epoch 62/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.7843 - accuracy: 0.6929 - val_loss: 0.7965 - val_accuracy: 0.6788\n",
      "Epoch 63/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.7883 - accuracy: 0.6856 - val_loss: 0.8017 - val_accuracy: 0.6423\n",
      "Epoch 64/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.7500 - accuracy: 0.7093 - val_loss: 0.7963 - val_accuracy: 0.6496\n",
      "Epoch 65/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.7755 - accuracy: 0.6892 - val_loss: 0.7753 - val_accuracy: 0.6715\n",
      "Epoch 66/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.7373 - accuracy: 0.7185 - val_loss: 0.7618 - val_accuracy: 0.6861\n",
      "Epoch 67/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.7334 - accuracy: 0.7112 - val_loss: 0.7534 - val_accuracy: 0.6934\n",
      "Epoch 68/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.7274 - accuracy: 0.7038 - val_loss: 0.7346 - val_accuracy: 0.7080\n",
      "Epoch 69/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.7453 - accuracy: 0.6929 - val_loss: 0.7283 - val_accuracy: 0.6861\n",
      "Epoch 70/500\n",
      "547/547 [==============================] - 0s 171us/sample - loss: 0.7214 - accuracy: 0.6801 - val_loss: 0.7337 - val_accuracy: 0.6934\n",
      "Epoch 71/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.7085 - accuracy: 0.7185 - val_loss: 0.7646 - val_accuracy: 0.6131\n",
      "Epoch 72/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.7028 - accuracy: 0.7093 - val_loss: 0.7618 - val_accuracy: 0.6058\n",
      "Epoch 73/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6853 - accuracy: 0.7221 - val_loss: 0.7232 - val_accuracy: 0.6715\n",
      "Epoch 74/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.6960 - accuracy: 0.7020 - val_loss: 0.6753 - val_accuracy: 0.6861\n",
      "Epoch 75/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.6801 - accuracy: 0.7349 - val_loss: 0.6710 - val_accuracy: 0.7007\n",
      "Epoch 76/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.6795 - accuracy: 0.7130 - val_loss: 0.6802 - val_accuracy: 0.7007\n",
      "Epoch 77/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.6661 - accuracy: 0.7130 - val_loss: 0.6623 - val_accuracy: 0.6861\n",
      "Epoch 78/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6844 - accuracy: 0.7203 - val_loss: 0.6560 - val_accuracy: 0.7080\n",
      "Epoch 79/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6520 - accuracy: 0.7294 - val_loss: 0.6566 - val_accuracy: 0.7153\n",
      "Epoch 80/500\n",
      "547/547 [==============================] - 0s 185us/sample - loss: 0.6659 - accuracy: 0.7185 - val_loss: 0.6605 - val_accuracy: 0.7372\n",
      "Epoch 81/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.6619 - accuracy: 0.7166 - val_loss: 0.6475 - val_accuracy: 0.7372\n",
      "Epoch 82/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6326 - accuracy: 0.7514 - val_loss: 0.6442 - val_accuracy: 0.7080\n",
      "Epoch 83/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6465 - accuracy: 0.7239 - val_loss: 0.6669 - val_accuracy: 0.7007\n",
      "Epoch 84/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.6345 - accuracy: 0.7294 - val_loss: 0.6667 - val_accuracy: 0.7007\n",
      "Epoch 85/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6592 - accuracy: 0.6965 - val_loss: 0.6653 - val_accuracy: 0.6861\n",
      "Epoch 86/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.6239 - accuracy: 0.7166 - val_loss: 0.6394 - val_accuracy: 0.7080\n",
      "Epoch 87/500\n",
      "547/547 [==============================] - 0s 188us/sample - loss: 0.6088 - accuracy: 0.7276 - val_loss: 0.6230 - val_accuracy: 0.7299\n",
      "Epoch 88/500\n",
      "547/547 [==============================] - 0s 171us/sample - loss: 0.6201 - accuracy: 0.7130 - val_loss: 0.6137 - val_accuracy: 0.7299\n",
      "Epoch 89/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.6330 - accuracy: 0.7203 - val_loss: 0.6051 - val_accuracy: 0.7299\n",
      "Epoch 90/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.6171 - accuracy: 0.7020 - val_loss: 0.6111 - val_accuracy: 0.7445\n",
      "Epoch 91/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5921 - accuracy: 0.7623 - val_loss: 0.6100 - val_accuracy: 0.7445\n",
      "Epoch 92/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.6161 - accuracy: 0.7294 - val_loss: 0.6036 - val_accuracy: 0.7372\n",
      "Epoch 93/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.6063 - accuracy: 0.7313 - val_loss: 0.6018 - val_accuracy: 0.7445\n",
      "Epoch 94/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5985 - accuracy: 0.7203 - val_loss: 0.6040 - val_accuracy: 0.7153\n",
      "Epoch 95/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.6038 - accuracy: 0.7386 - val_loss: 0.6107 - val_accuracy: 0.7080\n",
      "Epoch 96/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.6011 - accuracy: 0.7294 - val_loss: 0.6000 - val_accuracy: 0.7226\n",
      "Epoch 97/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5939 - accuracy: 0.7587 - val_loss: 0.5915 - val_accuracy: 0.7299\n",
      "Epoch 98/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.6004 - accuracy: 0.7386 - val_loss: 0.5949 - val_accuracy: 0.7153\n",
      "Epoch 99/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.6061 - accuracy: 0.7331 - val_loss: 0.6037 - val_accuracy: 0.7372\n",
      "Epoch 100/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5891 - accuracy: 0.7239 - val_loss: 0.6026 - val_accuracy: 0.7299\n",
      "Epoch 101/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5945 - accuracy: 0.7313 - val_loss: 0.6003 - val_accuracy: 0.7372\n",
      "Epoch 102/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5779 - accuracy: 0.7569 - val_loss: 0.6028 - val_accuracy: 0.7080\n",
      "Epoch 103/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.5776 - accuracy: 0.7075 - val_loss: 0.6023 - val_accuracy: 0.6861\n",
      "Epoch 104/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5682 - accuracy: 0.7404 - val_loss: 0.5999 - val_accuracy: 0.7153\n",
      "Epoch 105/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5826 - accuracy: 0.7185 - val_loss: 0.6018 - val_accuracy: 0.7080\n",
      "Epoch 106/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5969 - accuracy: 0.7294 - val_loss: 0.6023 - val_accuracy: 0.7299\n",
      "Epoch 107/500\n",
      "547/547 [==============================] - 0s 176us/sample - loss: 0.5555 - accuracy: 0.7386 - val_loss: 0.5799 - val_accuracy: 0.7153\n",
      "Epoch 108/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.5804 - accuracy: 0.7239 - val_loss: 0.5676 - val_accuracy: 0.7372\n",
      "Epoch 109/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5919 - accuracy: 0.7294 - val_loss: 0.5787 - val_accuracy: 0.6861\n",
      "Epoch 110/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5696 - accuracy: 0.7532 - val_loss: 0.5729 - val_accuracy: 0.7080\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5479 - accuracy: 0.7514 - val_loss: 0.5705 - val_accuracy: 0.7299\n",
      "Epoch 112/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5613 - accuracy: 0.7404 - val_loss: 0.5736 - val_accuracy: 0.7299\n",
      "Epoch 113/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.5768 - accuracy: 0.7514 - val_loss: 0.5735 - val_accuracy: 0.7153\n",
      "Epoch 114/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5764 - accuracy: 0.7386 - val_loss: 0.5721 - val_accuracy: 0.7226\n",
      "Epoch 115/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.5629 - accuracy: 0.7386 - val_loss: 0.5694 - val_accuracy: 0.7299\n",
      "Epoch 116/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.5609 - accuracy: 0.7404 - val_loss: 0.5938 - val_accuracy: 0.7153\n",
      "Epoch 117/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5573 - accuracy: 0.7349 - val_loss: 0.6018 - val_accuracy: 0.7153\n",
      "Epoch 118/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5572 - accuracy: 0.7422 - val_loss: 0.5868 - val_accuracy: 0.7080\n",
      "Epoch 119/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5493 - accuracy: 0.7495 - val_loss: 0.5833 - val_accuracy: 0.7372\n",
      "Epoch 120/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5668 - accuracy: 0.7258 - val_loss: 0.5816 - val_accuracy: 0.7445\n",
      "Epoch 121/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.5703 - accuracy: 0.7239 - val_loss: 0.5856 - val_accuracy: 0.7372\n",
      "Epoch 122/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5609 - accuracy: 0.7404 - val_loss: 0.5762 - val_accuracy: 0.7226\n",
      "Epoch 123/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.5479 - accuracy: 0.7642 - val_loss: 0.5727 - val_accuracy: 0.6934\n",
      "Epoch 124/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5424 - accuracy: 0.7495 - val_loss: 0.5628 - val_accuracy: 0.7372\n",
      "Epoch 125/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5300 - accuracy: 0.7422 - val_loss: 0.5664 - val_accuracy: 0.7372\n",
      "Epoch 126/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5615 - accuracy: 0.7422 - val_loss: 0.5542 - val_accuracy: 0.7372\n",
      "Epoch 127/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5499 - accuracy: 0.7349 - val_loss: 0.5399 - val_accuracy: 0.7518\n",
      "Epoch 128/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5352 - accuracy: 0.7495 - val_loss: 0.5461 - val_accuracy: 0.7372\n",
      "Epoch 129/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5481 - accuracy: 0.7532 - val_loss: 0.5510 - val_accuracy: 0.7226\n",
      "Epoch 130/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.5488 - accuracy: 0.7313 - val_loss: 0.5677 - val_accuracy: 0.7226\n",
      "Epoch 131/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5206 - accuracy: 0.7422 - val_loss: 0.5750 - val_accuracy: 0.7226\n",
      "Epoch 132/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5483 - accuracy: 0.7239 - val_loss: 0.5749 - val_accuracy: 0.7153\n",
      "Epoch 133/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5318 - accuracy: 0.7404 - val_loss: 0.5663 - val_accuracy: 0.7518\n",
      "Epoch 134/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5079 - accuracy: 0.7715 - val_loss: 0.5934 - val_accuracy: 0.7153\n",
      "Epoch 135/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5778 - accuracy: 0.7221 - val_loss: 0.6457 - val_accuracy: 0.6569\n",
      "Epoch 136/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5506 - accuracy: 0.7514 - val_loss: 0.6242 - val_accuracy: 0.6861\n",
      "Epoch 137/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.5426 - accuracy: 0.7441 - val_loss: 0.5969 - val_accuracy: 0.7007\n",
      "Epoch 138/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5430 - accuracy: 0.7477 - val_loss: 0.5939 - val_accuracy: 0.6934\n",
      "Epoch 139/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5100 - accuracy: 0.7770 - val_loss: 0.6021 - val_accuracy: 0.7080\n",
      "Epoch 140/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5627 - accuracy: 0.7422 - val_loss: 0.5824 - val_accuracy: 0.7153\n",
      "Epoch 141/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5206 - accuracy: 0.7459 - val_loss: 0.5638 - val_accuracy: 0.7153\n",
      "Epoch 142/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5539 - accuracy: 0.7166 - val_loss: 0.5575 - val_accuracy: 0.7372\n",
      "Epoch 143/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5228 - accuracy: 0.7623 - val_loss: 0.5688 - val_accuracy: 0.7080\n",
      "Epoch 144/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5365 - accuracy: 0.7550 - val_loss: 0.5702 - val_accuracy: 0.7007\n",
      "Epoch 145/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5533 - accuracy: 0.7386 - val_loss: 0.5643 - val_accuracy: 0.6861\n",
      "Epoch 146/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5592 - accuracy: 0.7258 - val_loss: 0.5896 - val_accuracy: 0.7007\n",
      "Epoch 147/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5322 - accuracy: 0.7276 - val_loss: 0.5992 - val_accuracy: 0.7007\n",
      "Epoch 148/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5209 - accuracy: 0.7550 - val_loss: 0.6189 - val_accuracy: 0.6715\n",
      "Epoch 149/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5369 - accuracy: 0.7459 - val_loss: 0.5908 - val_accuracy: 0.7007\n",
      "Epoch 150/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5253 - accuracy: 0.7422 - val_loss: 0.5575 - val_accuracy: 0.7080\n",
      "Epoch 151/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5337 - accuracy: 0.7386 - val_loss: 0.5459 - val_accuracy: 0.7445\n",
      "Epoch 152/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5369 - accuracy: 0.7569 - val_loss: 0.5505 - val_accuracy: 0.7372\n",
      "Epoch 153/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5322 - accuracy: 0.7313 - val_loss: 0.5604 - val_accuracy: 0.7299\n",
      "Epoch 154/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5209 - accuracy: 0.7477 - val_loss: 0.5697 - val_accuracy: 0.7153\n",
      "Epoch 155/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5213 - accuracy: 0.7459 - val_loss: 0.5700 - val_accuracy: 0.7153\n",
      "Epoch 156/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5296 - accuracy: 0.7477 - val_loss: 0.5543 - val_accuracy: 0.7372\n",
      "Epoch 157/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5333 - accuracy: 0.7459 - val_loss: 0.5610 - val_accuracy: 0.7153\n",
      "Epoch 158/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.5290 - accuracy: 0.7477 - val_loss: 0.5837 - val_accuracy: 0.7080\n",
      "Epoch 159/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5066 - accuracy: 0.7587 - val_loss: 0.6068 - val_accuracy: 0.6934\n",
      "Epoch 160/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5246 - accuracy: 0.7386 - val_loss: 0.6298 - val_accuracy: 0.6788\n",
      "Epoch 161/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5328 - accuracy: 0.7404 - val_loss: 0.6092 - val_accuracy: 0.6934\n",
      "Epoch 162/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5279 - accuracy: 0.7495 - val_loss: 0.5713 - val_accuracy: 0.7007\n",
      "Epoch 163/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5269 - accuracy: 0.7459 - val_loss: 0.5482 - val_accuracy: 0.7372\n",
      "Epoch 164/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5398 - accuracy: 0.7477 - val_loss: 0.5458 - val_accuracy: 0.7445\n",
      "Epoch 165/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5330 - accuracy: 0.7441 - val_loss: 0.5582 - val_accuracy: 0.7226\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5395 - accuracy: 0.7404 - val_loss: 0.5683 - val_accuracy: 0.7299\n",
      "Epoch 167/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5396 - accuracy: 0.7477 - val_loss: 0.5861 - val_accuracy: 0.7153\n",
      "Epoch 168/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.5233 - accuracy: 0.7441 - val_loss: 0.5636 - val_accuracy: 0.7299\n",
      "Epoch 169/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4977 - accuracy: 0.7550 - val_loss: 0.5410 - val_accuracy: 0.7299\n",
      "Epoch 170/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5282 - accuracy: 0.7495 - val_loss: 0.5427 - val_accuracy: 0.7372\n",
      "Epoch 171/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5005 - accuracy: 0.7715 - val_loss: 0.5639 - val_accuracy: 0.7445\n",
      "Epoch 172/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5108 - accuracy: 0.7386 - val_loss: 0.5978 - val_accuracy: 0.6788\n",
      "Epoch 173/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5336 - accuracy: 0.7367 - val_loss: 0.6420 - val_accuracy: 0.6569\n",
      "Epoch 174/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5136 - accuracy: 0.7587 - val_loss: 0.6285 - val_accuracy: 0.6642\n",
      "Epoch 175/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5331 - accuracy: 0.7422 - val_loss: 0.6477 - val_accuracy: 0.6715\n",
      "Epoch 176/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5044 - accuracy: 0.7623 - val_loss: 0.6307 - val_accuracy: 0.6642\n",
      "Epoch 177/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5256 - accuracy: 0.7550 - val_loss: 0.5901 - val_accuracy: 0.7007\n",
      "Epoch 178/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5401 - accuracy: 0.7386 - val_loss: 0.5583 - val_accuracy: 0.7226\n",
      "Epoch 179/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5111 - accuracy: 0.7733 - val_loss: 0.5534 - val_accuracy: 0.7153\n",
      "Epoch 180/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5518 - accuracy: 0.7495 - val_loss: 0.5543 - val_accuracy: 0.7226\n",
      "Epoch 181/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5192 - accuracy: 0.7660 - val_loss: 0.5575 - val_accuracy: 0.7226\n",
      "Epoch 182/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5299 - accuracy: 0.7386 - val_loss: 0.5745 - val_accuracy: 0.6861\n",
      "Epoch 183/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5358 - accuracy: 0.7386 - val_loss: 0.5707 - val_accuracy: 0.7226\n",
      "Epoch 184/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5430 - accuracy: 0.7313 - val_loss: 0.5718 - val_accuracy: 0.7007\n",
      "Epoch 185/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5300 - accuracy: 0.7587 - val_loss: 0.5616 - val_accuracy: 0.7226\n",
      "Epoch 186/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5128 - accuracy: 0.7587 - val_loss: 0.5631 - val_accuracy: 0.7153\n",
      "Epoch 187/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5133 - accuracy: 0.7916 - val_loss: 0.5659 - val_accuracy: 0.7080\n",
      "Epoch 188/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5068 - accuracy: 0.7623 - val_loss: 0.5741 - val_accuracy: 0.6788\n",
      "Epoch 189/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5266 - accuracy: 0.7605 - val_loss: 0.5894 - val_accuracy: 0.6642\n",
      "Epoch 190/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5303 - accuracy: 0.7459 - val_loss: 0.5977 - val_accuracy: 0.6788\n",
      "Epoch 191/500\n",
      "547/547 [==============================] - 0s 171us/sample - loss: 0.5164 - accuracy: 0.7751 - val_loss: 0.5827 - val_accuracy: 0.6861\n",
      "Epoch 192/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5157 - accuracy: 0.7477 - val_loss: 0.5829 - val_accuracy: 0.7153\n",
      "Epoch 193/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5411 - accuracy: 0.7441 - val_loss: 0.5808 - val_accuracy: 0.6861\n",
      "Epoch 194/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.5367 - accuracy: 0.7386 - val_loss: 0.5391 - val_accuracy: 0.7299\n",
      "Epoch 195/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5055 - accuracy: 0.7770 - val_loss: 0.5505 - val_accuracy: 0.7445\n",
      "Epoch 196/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4882 - accuracy: 0.7697 - val_loss: 0.5870 - val_accuracy: 0.6934\n",
      "Epoch 197/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5199 - accuracy: 0.7569 - val_loss: 0.5916 - val_accuracy: 0.6788\n",
      "Epoch 198/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4959 - accuracy: 0.7715 - val_loss: 0.5732 - val_accuracy: 0.6934\n",
      "Epoch 199/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.5002 - accuracy: 0.7934 - val_loss: 0.5721 - val_accuracy: 0.6861\n",
      "Epoch 200/500\n",
      "547/547 [==============================] - 0s 159us/sample - loss: 0.5015 - accuracy: 0.7733 - val_loss: 0.5541 - val_accuracy: 0.6934\n",
      "Epoch 201/500\n",
      "547/547 [==============================] - 0s 159us/sample - loss: 0.5013 - accuracy: 0.7623 - val_loss: 0.5536 - val_accuracy: 0.7299\n",
      "Epoch 202/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5122 - accuracy: 0.7642 - val_loss: 0.5772 - val_accuracy: 0.7080\n",
      "Epoch 203/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5130 - accuracy: 0.7715 - val_loss: 0.5894 - val_accuracy: 0.7226\n",
      "Epoch 204/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5253 - accuracy: 0.7605 - val_loss: 0.5685 - val_accuracy: 0.7299\n",
      "Epoch 205/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5148 - accuracy: 0.7532 - val_loss: 0.5623 - val_accuracy: 0.7299\n",
      "Epoch 206/500\n",
      "547/547 [==============================] - 0s 159us/sample - loss: 0.5251 - accuracy: 0.7404 - val_loss: 0.5580 - val_accuracy: 0.7372\n",
      "Epoch 207/500\n",
      "547/547 [==============================] - 0s 157us/sample - loss: 0.4975 - accuracy: 0.7751 - val_loss: 0.5445 - val_accuracy: 0.7372\n",
      "Epoch 208/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5175 - accuracy: 0.7623 - val_loss: 0.5374 - val_accuracy: 0.7372\n",
      "Epoch 209/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4827 - accuracy: 0.7697 - val_loss: 0.5379 - val_accuracy: 0.7153\n",
      "Epoch 210/500\n",
      "547/547 [==============================] - 0s 160us/sample - loss: 0.5036 - accuracy: 0.7770 - val_loss: 0.5473 - val_accuracy: 0.7080\n",
      "Epoch 211/500\n",
      "547/547 [==============================] - 0s 159us/sample - loss: 0.4709 - accuracy: 0.7971 - val_loss: 0.5569 - val_accuracy: 0.7080\n",
      "Epoch 212/500\n",
      "547/547 [==============================] - 0s 154us/sample - loss: 0.5228 - accuracy: 0.7642 - val_loss: 0.5738 - val_accuracy: 0.7080\n",
      "Epoch 213/500\n",
      "547/547 [==============================] - 0s 155us/sample - loss: 0.4915 - accuracy: 0.7733 - val_loss: 0.5714 - val_accuracy: 0.7153\n",
      "Epoch 214/500\n",
      "547/547 [==============================] - 0s 157us/sample - loss: 0.5275 - accuracy: 0.7495 - val_loss: 0.5542 - val_accuracy: 0.7153\n",
      "Epoch 215/500\n",
      "547/547 [==============================] - 0s 157us/sample - loss: 0.5136 - accuracy: 0.7642 - val_loss: 0.5512 - val_accuracy: 0.7445\n",
      "Epoch 216/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5071 - accuracy: 0.7587 - val_loss: 0.5546 - val_accuracy: 0.7080\n",
      "Epoch 217/500\n",
      "547/547 [==============================] - 0s 154us/sample - loss: 0.5136 - accuracy: 0.7587 - val_loss: 0.5522 - val_accuracy: 0.7080\n",
      "Epoch 218/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4798 - accuracy: 0.7697 - val_loss: 0.5470 - val_accuracy: 0.7372\n",
      "Epoch 219/500\n",
      "547/547 [==============================] - 0s 157us/sample - loss: 0.5211 - accuracy: 0.7495 - val_loss: 0.5575 - val_accuracy: 0.7445\n",
      "Epoch 220/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5022 - accuracy: 0.7605 - val_loss: 0.5667 - val_accuracy: 0.7153\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 159us/sample - loss: 0.4993 - accuracy: 0.7532 - val_loss: 0.5512 - val_accuracy: 0.7372\n",
      "Epoch 222/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5216 - accuracy: 0.7514 - val_loss: 0.5473 - val_accuracy: 0.7153\n",
      "Epoch 223/500\n",
      "547/547 [==============================] - 0s 155us/sample - loss: 0.5047 - accuracy: 0.7733 - val_loss: 0.5527 - val_accuracy: 0.7226\n",
      "Epoch 224/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5321 - accuracy: 0.7441 - val_loss: 0.5676 - val_accuracy: 0.7080\n",
      "Epoch 225/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.5015 - accuracy: 0.7587 - val_loss: 0.5783 - val_accuracy: 0.6934\n",
      "Epoch 226/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5201 - accuracy: 0.7495 - val_loss: 0.5854 - val_accuracy: 0.6934\n",
      "Epoch 227/500\n",
      "547/547 [==============================] - 0s 154us/sample - loss: 0.4863 - accuracy: 0.7861 - val_loss: 0.6102 - val_accuracy: 0.6715\n",
      "Epoch 228/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4913 - accuracy: 0.7660 - val_loss: 0.6137 - val_accuracy: 0.6715\n",
      "Epoch 229/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.4690 - accuracy: 0.7788 - val_loss: 0.6179 - val_accuracy: 0.6642\n",
      "Epoch 230/500\n",
      "547/547 [==============================] - 0s 159us/sample - loss: 0.5069 - accuracy: 0.7605 - val_loss: 0.5979 - val_accuracy: 0.6861\n",
      "Epoch 231/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4796 - accuracy: 0.7715 - val_loss: 0.5687 - val_accuracy: 0.6861\n",
      "Epoch 232/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.5001 - accuracy: 0.7642 - val_loss: 0.5492 - val_accuracy: 0.7299\n",
      "Epoch 233/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5091 - accuracy: 0.7660 - val_loss: 0.5733 - val_accuracy: 0.6934\n",
      "Epoch 234/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4940 - accuracy: 0.7605 - val_loss: 0.5875 - val_accuracy: 0.6861\n",
      "Epoch 235/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5253 - accuracy: 0.7495 - val_loss: 0.5619 - val_accuracy: 0.6934\n",
      "Epoch 236/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5182 - accuracy: 0.7386 - val_loss: 0.5408 - val_accuracy: 0.7153\n",
      "Epoch 237/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4876 - accuracy: 0.7678 - val_loss: 0.5387 - val_accuracy: 0.7226\n",
      "Epoch 238/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4745 - accuracy: 0.7806 - val_loss: 0.5571 - val_accuracy: 0.7226\n",
      "Epoch 239/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4955 - accuracy: 0.7806 - val_loss: 0.5567 - val_accuracy: 0.7226\n",
      "Epoch 240/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4939 - accuracy: 0.7770 - val_loss: 0.5449 - val_accuracy: 0.7226\n",
      "Epoch 241/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4822 - accuracy: 0.7715 - val_loss: 0.5285 - val_accuracy: 0.7226\n",
      "Epoch 242/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5079 - accuracy: 0.7459 - val_loss: 0.5185 - val_accuracy: 0.7445\n",
      "Epoch 243/500\n",
      "547/547 [==============================] - 0s 182us/sample - loss: 0.4809 - accuracy: 0.7843 - val_loss: 0.5244 - val_accuracy: 0.7591\n",
      "Epoch 244/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5064 - accuracy: 0.7678 - val_loss: 0.5508 - val_accuracy: 0.7153\n",
      "Epoch 245/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.5229 - accuracy: 0.7294 - val_loss: 0.5822 - val_accuracy: 0.6934\n",
      "Epoch 246/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5236 - accuracy: 0.7404 - val_loss: 0.5783 - val_accuracy: 0.6788\n",
      "Epoch 247/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4833 - accuracy: 0.7824 - val_loss: 0.5803 - val_accuracy: 0.6861\n",
      "Epoch 248/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4777 - accuracy: 0.7898 - val_loss: 0.5601 - val_accuracy: 0.6934\n",
      "Epoch 249/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5128 - accuracy: 0.7715 - val_loss: 0.5466 - val_accuracy: 0.7299\n",
      "Epoch 250/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5078 - accuracy: 0.7697 - val_loss: 0.5342 - val_accuracy: 0.7226\n",
      "Epoch 251/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4581 - accuracy: 0.7916 - val_loss: 0.5342 - val_accuracy: 0.7372\n",
      "Epoch 252/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.5003 - accuracy: 0.7660 - val_loss: 0.5380 - val_accuracy: 0.7153\n",
      "Epoch 253/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4946 - accuracy: 0.7733 - val_loss: 0.5410 - val_accuracy: 0.7226\n",
      "Epoch 254/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5069 - accuracy: 0.7715 - val_loss: 0.5530 - val_accuracy: 0.7226\n",
      "Epoch 255/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4635 - accuracy: 0.7898 - val_loss: 0.6089 - val_accuracy: 0.6642\n",
      "Epoch 256/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4681 - accuracy: 0.8099 - val_loss: 0.6250 - val_accuracy: 0.6788\n",
      "Epoch 257/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4910 - accuracy: 0.7495 - val_loss: 0.5967 - val_accuracy: 0.6788\n",
      "Epoch 258/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4994 - accuracy: 0.7623 - val_loss: 0.5751 - val_accuracy: 0.6715\n",
      "Epoch 259/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5215 - accuracy: 0.7587 - val_loss: 0.5757 - val_accuracy: 0.6861\n",
      "Epoch 260/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.5167 - accuracy: 0.7678 - val_loss: 0.5624 - val_accuracy: 0.7007\n",
      "Epoch 261/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.5007 - accuracy: 0.7623 - val_loss: 0.5632 - val_accuracy: 0.6788\n",
      "Epoch 262/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4985 - accuracy: 0.7605 - val_loss: 0.5595 - val_accuracy: 0.7153\n",
      "Epoch 263/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4720 - accuracy: 0.7824 - val_loss: 0.5526 - val_accuracy: 0.7007\n",
      "Epoch 264/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4993 - accuracy: 0.7678 - val_loss: 0.5588 - val_accuracy: 0.7080\n",
      "Epoch 265/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4845 - accuracy: 0.7678 - val_loss: 0.5871 - val_accuracy: 0.7226\n",
      "Epoch 266/500\n",
      "547/547 [==============================] - 0s 171us/sample - loss: 0.4804 - accuracy: 0.7770 - val_loss: 0.5921 - val_accuracy: 0.7153\n",
      "Epoch 267/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4764 - accuracy: 0.7843 - val_loss: 0.5647 - val_accuracy: 0.7153\n",
      "Epoch 268/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4949 - accuracy: 0.7569 - val_loss: 0.5477 - val_accuracy: 0.7299\n",
      "Epoch 269/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4905 - accuracy: 0.7623 - val_loss: 0.5433 - val_accuracy: 0.7518\n",
      "Epoch 270/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4638 - accuracy: 0.7898 - val_loss: 0.5516 - val_accuracy: 0.7299\n",
      "Epoch 271/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4912 - accuracy: 0.7569 - val_loss: 0.5538 - val_accuracy: 0.7153\n",
      "Epoch 272/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4880 - accuracy: 0.7770 - val_loss: 0.5625 - val_accuracy: 0.7153\n",
      "Epoch 273/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4844 - accuracy: 0.7952 - val_loss: 0.5618 - val_accuracy: 0.7080\n",
      "Epoch 274/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4630 - accuracy: 0.7824 - val_loss: 0.5596 - val_accuracy: 0.7007\n",
      "Epoch 275/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4855 - accuracy: 0.7697 - val_loss: 0.5504 - val_accuracy: 0.7299\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4918 - accuracy: 0.7550 - val_loss: 0.5454 - val_accuracy: 0.7299\n",
      "Epoch 277/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4903 - accuracy: 0.7678 - val_loss: 0.5463 - val_accuracy: 0.7299\n",
      "Epoch 278/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4583 - accuracy: 0.8080 - val_loss: 0.5622 - val_accuracy: 0.7153\n",
      "Epoch 279/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4681 - accuracy: 0.7806 - val_loss: 0.5745 - val_accuracy: 0.7299\n",
      "Epoch 280/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4720 - accuracy: 0.7861 - val_loss: 0.5785 - val_accuracy: 0.7080\n",
      "Epoch 281/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4667 - accuracy: 0.7806 - val_loss: 0.5905 - val_accuracy: 0.7080\n",
      "Epoch 282/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4911 - accuracy: 0.7751 - val_loss: 0.5636 - val_accuracy: 0.7153\n",
      "Epoch 283/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4732 - accuracy: 0.7861 - val_loss: 0.5613 - val_accuracy: 0.7372\n",
      "Epoch 284/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4673 - accuracy: 0.7879 - val_loss: 0.5694 - val_accuracy: 0.7299\n",
      "Epoch 285/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5189 - accuracy: 0.7605 - val_loss: 0.5815 - val_accuracy: 0.7153\n",
      "Epoch 286/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4451 - accuracy: 0.7879 - val_loss: 0.5890 - val_accuracy: 0.7007\n",
      "Epoch 287/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4850 - accuracy: 0.7642 - val_loss: 0.5813 - val_accuracy: 0.7007\n",
      "Epoch 288/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4678 - accuracy: 0.7971 - val_loss: 0.5812 - val_accuracy: 0.7007\n",
      "Epoch 289/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4721 - accuracy: 0.7788 - val_loss: 0.5936 - val_accuracy: 0.6861\n",
      "Epoch 290/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4696 - accuracy: 0.7788 - val_loss: 0.5819 - val_accuracy: 0.6934\n",
      "Epoch 291/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4766 - accuracy: 0.7879 - val_loss: 0.5789 - val_accuracy: 0.7226\n",
      "Epoch 292/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4713 - accuracy: 0.7952 - val_loss: 0.5769 - val_accuracy: 0.7153\n",
      "Epoch 293/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4854 - accuracy: 0.7660 - val_loss: 0.5650 - val_accuracy: 0.7153\n",
      "Epoch 294/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4889 - accuracy: 0.7550 - val_loss: 0.5743 - val_accuracy: 0.6934\n",
      "Epoch 295/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4988 - accuracy: 0.7587 - val_loss: 0.5813 - val_accuracy: 0.6569\n",
      "Epoch 296/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4727 - accuracy: 0.7843 - val_loss: 0.5779 - val_accuracy: 0.7007\n",
      "Epoch 297/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4885 - accuracy: 0.7733 - val_loss: 0.5760 - val_accuracy: 0.7080\n",
      "Epoch 298/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4846 - accuracy: 0.7879 - val_loss: 0.5610 - val_accuracy: 0.7372\n",
      "Epoch 299/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.4784 - accuracy: 0.7879 - val_loss: 0.5606 - val_accuracy: 0.7226\n",
      "Epoch 300/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4729 - accuracy: 0.7898 - val_loss: 0.5855 - val_accuracy: 0.7153\n",
      "Epoch 301/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4668 - accuracy: 0.7751 - val_loss: 0.5908 - val_accuracy: 0.7007\n",
      "Epoch 302/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4807 - accuracy: 0.7770 - val_loss: 0.5780 - val_accuracy: 0.6934\n",
      "Epoch 303/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5001 - accuracy: 0.7788 - val_loss: 0.5638 - val_accuracy: 0.7153\n",
      "Epoch 304/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5106 - accuracy: 0.7678 - val_loss: 0.5548 - val_accuracy: 0.7226\n",
      "Epoch 305/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4939 - accuracy: 0.7678 - val_loss: 0.5502 - val_accuracy: 0.7372\n",
      "Epoch 306/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4977 - accuracy: 0.7422 - val_loss: 0.5574 - val_accuracy: 0.7153\n",
      "Epoch 307/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4876 - accuracy: 0.7879 - val_loss: 0.5635 - val_accuracy: 0.7080\n",
      "Epoch 308/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4963 - accuracy: 0.7623 - val_loss: 0.5662 - val_accuracy: 0.6934\n",
      "Epoch 309/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4821 - accuracy: 0.7697 - val_loss: 0.5825 - val_accuracy: 0.6861\n",
      "Epoch 310/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4592 - accuracy: 0.7916 - val_loss: 0.6164 - val_accuracy: 0.7080\n",
      "Epoch 311/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4611 - accuracy: 0.7916 - val_loss: 0.6232 - val_accuracy: 0.6934\n",
      "Epoch 312/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4844 - accuracy: 0.7678 - val_loss: 0.5853 - val_accuracy: 0.7226\n",
      "Epoch 313/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4861 - accuracy: 0.7569 - val_loss: 0.5873 - val_accuracy: 0.7153\n",
      "Epoch 314/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4605 - accuracy: 0.7678 - val_loss: 0.5712 - val_accuracy: 0.7007\n",
      "Epoch 315/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5029 - accuracy: 0.7532 - val_loss: 0.5594 - val_accuracy: 0.7080\n",
      "Epoch 316/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.4806 - accuracy: 0.7879 - val_loss: 0.5652 - val_accuracy: 0.7080\n",
      "Epoch 317/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4807 - accuracy: 0.7989 - val_loss: 0.5752 - val_accuracy: 0.7007\n",
      "Epoch 318/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4803 - accuracy: 0.7824 - val_loss: 0.5726 - val_accuracy: 0.6934\n",
      "Epoch 319/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.4793 - accuracy: 0.7788 - val_loss: 0.5722 - val_accuracy: 0.7299\n",
      "Epoch 320/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4770 - accuracy: 0.7715 - val_loss: 0.5740 - val_accuracy: 0.7372\n",
      "Epoch 321/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4795 - accuracy: 0.7861 - val_loss: 0.5784 - val_accuracy: 0.7299\n",
      "Epoch 322/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4927 - accuracy: 0.7697 - val_loss: 0.5742 - val_accuracy: 0.7226\n",
      "Epoch 323/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4735 - accuracy: 0.7715 - val_loss: 0.5655 - val_accuracy: 0.7372\n",
      "Epoch 324/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4666 - accuracy: 0.7788 - val_loss: 0.5649 - val_accuracy: 0.7080\n",
      "Epoch 325/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4998 - accuracy: 0.7898 - val_loss: 0.5805 - val_accuracy: 0.6715\n",
      "Epoch 326/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4959 - accuracy: 0.7532 - val_loss: 0.5748 - val_accuracy: 0.7007\n",
      "Epoch 327/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4747 - accuracy: 0.7715 - val_loss: 0.5592 - val_accuracy: 0.7007\n",
      "Epoch 328/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4876 - accuracy: 0.7861 - val_loss: 0.5570 - val_accuracy: 0.7299\n",
      "Epoch 329/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4859 - accuracy: 0.7550 - val_loss: 0.5592 - val_accuracy: 0.7226\n",
      "Epoch 330/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4747 - accuracy: 0.7788 - val_loss: 0.5599 - val_accuracy: 0.7372\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4747 - accuracy: 0.7678 - val_loss: 0.5598 - val_accuracy: 0.7226\n",
      "Epoch 332/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4925 - accuracy: 0.7642 - val_loss: 0.5634 - val_accuracy: 0.7153\n",
      "Epoch 333/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5028 - accuracy: 0.7751 - val_loss: 0.5696 - val_accuracy: 0.7080\n",
      "Epoch 334/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4895 - accuracy: 0.7642 - val_loss: 0.5698 - val_accuracy: 0.6861\n",
      "Epoch 335/500\n",
      "547/547 [==============================] - 0s 171us/sample - loss: 0.4855 - accuracy: 0.7697 - val_loss: 0.5720 - val_accuracy: 0.6934\n",
      "Epoch 336/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.5023 - accuracy: 0.7422 - val_loss: 0.5744 - val_accuracy: 0.7007\n",
      "Epoch 337/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4666 - accuracy: 0.7843 - val_loss: 0.6049 - val_accuracy: 0.6934\n",
      "Epoch 338/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4723 - accuracy: 0.7879 - val_loss: 0.6399 - val_accuracy: 0.6569\n",
      "Epoch 339/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5027 - accuracy: 0.7770 - val_loss: 0.6659 - val_accuracy: 0.6642\n",
      "Epoch 340/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4767 - accuracy: 0.7770 - val_loss: 0.7078 - val_accuracy: 0.6423\n",
      "Epoch 341/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4881 - accuracy: 0.7916 - val_loss: 0.7554 - val_accuracy: 0.6204\n",
      "Epoch 342/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4372 - accuracy: 0.8062 - val_loss: 0.7751 - val_accuracy: 0.6204\n",
      "Epoch 343/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4742 - accuracy: 0.7806 - val_loss: 0.7525 - val_accuracy: 0.6496\n",
      "Epoch 344/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4828 - accuracy: 0.7806 - val_loss: 0.6912 - val_accuracy: 0.6642\n",
      "Epoch 345/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4726 - accuracy: 0.7806 - val_loss: 0.6614 - val_accuracy: 0.6861\n",
      "Epoch 346/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4601 - accuracy: 0.7733 - val_loss: 0.6654 - val_accuracy: 0.6423\n",
      "Epoch 347/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4435 - accuracy: 0.8099 - val_loss: 0.6604 - val_accuracy: 0.6423\n",
      "Epoch 348/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.5091 - accuracy: 0.7550 - val_loss: 0.6308 - val_accuracy: 0.6861\n",
      "Epoch 349/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4717 - accuracy: 0.7788 - val_loss: 0.6270 - val_accuracy: 0.7153\n",
      "Epoch 350/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4938 - accuracy: 0.7788 - val_loss: 0.6223 - val_accuracy: 0.7080\n",
      "Epoch 351/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.6358 - val_accuracy: 0.6861\n",
      "Epoch 352/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4399 - accuracy: 0.8099 - val_loss: 0.6411 - val_accuracy: 0.6861\n",
      "Epoch 353/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4697 - accuracy: 0.7824 - val_loss: 0.6264 - val_accuracy: 0.7153\n",
      "Epoch 354/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.5021 - accuracy: 0.7550 - val_loss: 0.6045 - val_accuracy: 0.7080\n",
      "Epoch 355/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4442 - accuracy: 0.8007 - val_loss: 0.5604 - val_accuracy: 0.7299\n",
      "Epoch 356/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4377 - accuracy: 0.7971 - val_loss: 0.5589 - val_accuracy: 0.7226\n",
      "Epoch 357/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4568 - accuracy: 0.7898 - val_loss: 0.5494 - val_accuracy: 0.7299\n",
      "Epoch 358/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4586 - accuracy: 0.7971 - val_loss: 0.5492 - val_accuracy: 0.7153\n",
      "Epoch 359/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4615 - accuracy: 0.7898 - val_loss: 0.5602 - val_accuracy: 0.7080\n",
      "Epoch 360/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4261 - accuracy: 0.8117 - val_loss: 0.5584 - val_accuracy: 0.7007\n",
      "Epoch 361/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4582 - accuracy: 0.7697 - val_loss: 0.5482 - val_accuracy: 0.7007\n",
      "Epoch 362/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4494 - accuracy: 0.8062 - val_loss: 0.5416 - val_accuracy: 0.7226\n",
      "Epoch 363/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4640 - accuracy: 0.8099 - val_loss: 0.5467 - val_accuracy: 0.7226\n",
      "Epoch 364/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4461 - accuracy: 0.8007 - val_loss: 0.5359 - val_accuracy: 0.7153\n",
      "Epoch 365/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4602 - accuracy: 0.7788 - val_loss: 0.5513 - val_accuracy: 0.7153\n",
      "Epoch 366/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4877 - accuracy: 0.7678 - val_loss: 0.5861 - val_accuracy: 0.7299\n",
      "Epoch 367/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4597 - accuracy: 0.7770 - val_loss: 0.5863 - val_accuracy: 0.7299\n",
      "Epoch 368/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4884 - accuracy: 0.7770 - val_loss: 0.5757 - val_accuracy: 0.7153\n",
      "Epoch 369/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5745 - val_accuracy: 0.7226\n",
      "Epoch 370/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4586 - accuracy: 0.8026 - val_loss: 0.5648 - val_accuracy: 0.7080\n",
      "Epoch 371/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4869 - accuracy: 0.7587 - val_loss: 0.5584 - val_accuracy: 0.7080\n",
      "Epoch 372/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4617 - accuracy: 0.7879 - val_loss: 0.5552 - val_accuracy: 0.7226\n",
      "Epoch 373/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4571 - accuracy: 0.7916 - val_loss: 0.5658 - val_accuracy: 0.7007\n",
      "Epoch 374/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.4775 - accuracy: 0.7733 - val_loss: 0.5721 - val_accuracy: 0.7080\n",
      "Epoch 375/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4799 - accuracy: 0.7934 - val_loss: 0.5722 - val_accuracy: 0.7226\n",
      "Epoch 376/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4454 - accuracy: 0.7971 - val_loss: 0.5537 - val_accuracy: 0.7372\n",
      "Epoch 377/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4707 - accuracy: 0.7824 - val_loss: 0.5476 - val_accuracy: 0.7445\n",
      "Epoch 378/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4657 - accuracy: 0.7806 - val_loss: 0.5550 - val_accuracy: 0.7372\n",
      "Epoch 379/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4394 - accuracy: 0.7952 - val_loss: 0.5646 - val_accuracy: 0.7372\n",
      "Epoch 380/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4497 - accuracy: 0.7952 - val_loss: 0.5838 - val_accuracy: 0.7007\n",
      "Epoch 381/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4803 - accuracy: 0.7843 - val_loss: 0.5852 - val_accuracy: 0.6934\n",
      "Epoch 382/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4560 - accuracy: 0.7733 - val_loss: 0.5965 - val_accuracy: 0.6861\n",
      "Epoch 383/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4599 - accuracy: 0.8026 - val_loss: 0.6143 - val_accuracy: 0.6788\n",
      "Epoch 384/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4515 - accuracy: 0.7916 - val_loss: 0.6065 - val_accuracy: 0.6788\n",
      "Epoch 385/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4585 - accuracy: 0.8007 - val_loss: 0.5880 - val_accuracy: 0.6788\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4707 - accuracy: 0.7806 - val_loss: 0.5931 - val_accuracy: 0.6642\n",
      "Epoch 387/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4674 - accuracy: 0.7916 - val_loss: 0.5861 - val_accuracy: 0.7226\n",
      "Epoch 388/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4751 - accuracy: 0.7788 - val_loss: 0.5959 - val_accuracy: 0.7299\n",
      "Epoch 389/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4728 - accuracy: 0.7587 - val_loss: 0.5819 - val_accuracy: 0.7153\n",
      "Epoch 390/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4821 - accuracy: 0.7843 - val_loss: 0.5845 - val_accuracy: 0.6788\n",
      "Epoch 391/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.4855 - accuracy: 0.7806 - val_loss: 0.5751 - val_accuracy: 0.6934\n",
      "Epoch 392/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.5027 - accuracy: 0.7770 - val_loss: 0.5720 - val_accuracy: 0.7080\n",
      "Epoch 393/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4496 - accuracy: 0.8026 - val_loss: 0.5572 - val_accuracy: 0.7007\n",
      "Epoch 394/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4399 - accuracy: 0.8007 - val_loss: 0.5464 - val_accuracy: 0.7226\n",
      "Epoch 395/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4593 - accuracy: 0.7824 - val_loss: 0.5616 - val_accuracy: 0.7226\n",
      "Epoch 396/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4681 - accuracy: 0.7514 - val_loss: 0.5612 - val_accuracy: 0.7226\n",
      "Epoch 397/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4700 - accuracy: 0.7824 - val_loss: 0.5631 - val_accuracy: 0.7518\n",
      "Epoch 398/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4631 - accuracy: 0.7806 - val_loss: 0.5857 - val_accuracy: 0.7226\n",
      "Epoch 399/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4820 - accuracy: 0.7824 - val_loss: 0.5977 - val_accuracy: 0.7080\n",
      "Epoch 400/500\n",
      "547/547 [==============================] - 0s 171us/sample - loss: 0.4443 - accuracy: 0.8117 - val_loss: 0.5795 - val_accuracy: 0.7153\n",
      "Epoch 401/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4397 - accuracy: 0.8044 - val_loss: 0.5671 - val_accuracy: 0.7080\n",
      "Epoch 402/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4624 - accuracy: 0.7898 - val_loss: 0.5866 - val_accuracy: 0.6788\n",
      "Epoch 403/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4783 - accuracy: 0.7843 - val_loss: 0.5971 - val_accuracy: 0.6788\n",
      "Epoch 404/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4671 - accuracy: 0.7934 - val_loss: 0.5822 - val_accuracy: 0.6934\n",
      "Epoch 405/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4449 - accuracy: 0.8080 - val_loss: 0.5683 - val_accuracy: 0.7153\n",
      "Epoch 406/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4902 - accuracy: 0.7678 - val_loss: 0.5651 - val_accuracy: 0.7153\n",
      "Epoch 407/500\n",
      "547/547 [==============================] - 0s 185us/sample - loss: 0.4298 - accuracy: 0.8044 - val_loss: 0.5589 - val_accuracy: 0.7153\n",
      "Epoch 408/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4361 - accuracy: 0.8154 - val_loss: 0.5880 - val_accuracy: 0.6934\n",
      "Epoch 409/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4792 - accuracy: 0.7806 - val_loss: 0.5965 - val_accuracy: 0.7080\n",
      "Epoch 410/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4812 - accuracy: 0.7824 - val_loss: 0.6071 - val_accuracy: 0.6934\n",
      "Epoch 411/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4347 - accuracy: 0.8154 - val_loss: 0.6223 - val_accuracy: 0.7007\n",
      "Epoch 412/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.4613 - accuracy: 0.8099 - val_loss: 0.5984 - val_accuracy: 0.6934\n",
      "Epoch 413/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4616 - accuracy: 0.7788 - val_loss: 0.5846 - val_accuracy: 0.7153\n",
      "Epoch 414/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.6053 - val_accuracy: 0.6569\n",
      "Epoch 415/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4298 - accuracy: 0.7952 - val_loss: 0.5923 - val_accuracy: 0.7007\n",
      "Epoch 416/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4647 - accuracy: 0.7642 - val_loss: 0.5944 - val_accuracy: 0.6861\n",
      "Epoch 417/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4485 - accuracy: 0.7916 - val_loss: 0.5853 - val_accuracy: 0.6861\n",
      "Epoch 418/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4667 - accuracy: 0.7989 - val_loss: 0.5848 - val_accuracy: 0.7372\n",
      "Epoch 419/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4436 - accuracy: 0.7989 - val_loss: 0.5773 - val_accuracy: 0.7153\n",
      "Epoch 420/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4632 - accuracy: 0.7898 - val_loss: 0.5620 - val_accuracy: 0.7226\n",
      "Epoch 421/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4588 - accuracy: 0.7898 - val_loss: 0.5574 - val_accuracy: 0.7080\n",
      "Epoch 422/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4775 - accuracy: 0.7843 - val_loss: 0.5506 - val_accuracy: 0.7153\n",
      "Epoch 423/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4582 - accuracy: 0.7861 - val_loss: 0.5524 - val_accuracy: 0.7372\n",
      "Epoch 424/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4388 - accuracy: 0.8062 - val_loss: 0.5660 - val_accuracy: 0.7299\n",
      "Epoch 425/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4588 - accuracy: 0.7660 - val_loss: 0.6170 - val_accuracy: 0.7007\n",
      "Epoch 426/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4720 - accuracy: 0.8044 - val_loss: 0.6428 - val_accuracy: 0.6934\n",
      "Epoch 427/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4729 - accuracy: 0.7916 - val_loss: 0.6021 - val_accuracy: 0.6934\n",
      "Epoch 428/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4619 - accuracy: 0.7916 - val_loss: 0.5673 - val_accuracy: 0.7226\n",
      "Epoch 429/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4684 - accuracy: 0.7843 - val_loss: 0.5538 - val_accuracy: 0.7153\n",
      "Epoch 430/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4524 - accuracy: 0.7916 - val_loss: 0.5503 - val_accuracy: 0.7299\n",
      "Epoch 431/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4733 - accuracy: 0.7788 - val_loss: 0.5534 - val_accuracy: 0.7299\n",
      "Epoch 432/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4396 - accuracy: 0.7806 - val_loss: 0.5623 - val_accuracy: 0.7299\n",
      "Epoch 433/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4603 - accuracy: 0.7971 - val_loss: 0.5633 - val_accuracy: 0.7518\n",
      "Epoch 434/500\n",
      "547/547 [==============================] - 0s 162us/sample - loss: 0.4757 - accuracy: 0.7605 - val_loss: 0.5687 - val_accuracy: 0.7445\n",
      "Epoch 435/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4649 - accuracy: 0.7843 - val_loss: 0.5686 - val_accuracy: 0.7226\n",
      "Epoch 436/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4559 - accuracy: 0.7824 - val_loss: 0.5639 - val_accuracy: 0.7372\n",
      "Epoch 437/500\n",
      "547/547 [==============================] - 0s 164us/sample - loss: 0.4610 - accuracy: 0.7806 - val_loss: 0.5562 - val_accuracy: 0.7518\n",
      "Epoch 438/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4569 - accuracy: 0.7861 - val_loss: 0.5585 - val_accuracy: 0.7299\n",
      "Epoch 439/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4487 - accuracy: 0.8117 - val_loss: 0.5617 - val_accuracy: 0.7226\n",
      "Epoch 440/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4441 - accuracy: 0.8007 - val_loss: 0.5548 - val_accuracy: 0.7299\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4527 - accuracy: 0.7916 - val_loss: 0.5555 - val_accuracy: 0.6934\n",
      "Epoch 442/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4350 - accuracy: 0.7971 - val_loss: 0.5575 - val_accuracy: 0.6861\n",
      "Epoch 443/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4305 - accuracy: 0.8044 - val_loss: 0.5721 - val_accuracy: 0.7007\n",
      "Epoch 444/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4503 - accuracy: 0.8044 - val_loss: 0.5857 - val_accuracy: 0.7372\n",
      "Epoch 445/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4681 - accuracy: 0.7751 - val_loss: 0.6178 - val_accuracy: 0.7080\n",
      "Epoch 446/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4495 - accuracy: 0.8062 - val_loss: 0.6375 - val_accuracy: 0.6861\n",
      "Epoch 447/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4972 - accuracy: 0.7751 - val_loss: 0.6164 - val_accuracy: 0.7080\n",
      "Epoch 448/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.4316 - accuracy: 0.7898 - val_loss: 0.6028 - val_accuracy: 0.6788\n",
      "Epoch 449/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4814 - accuracy: 0.7916 - val_loss: 0.5933 - val_accuracy: 0.6788\n",
      "Epoch 450/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4550 - accuracy: 0.7733 - val_loss: 0.5819 - val_accuracy: 0.7153\n",
      "Epoch 451/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4551 - accuracy: 0.7898 - val_loss: 0.5681 - val_accuracy: 0.7153\n",
      "Epoch 452/500\n",
      "547/547 [==============================] - 0s 169us/sample - loss: 0.4379 - accuracy: 0.7898 - val_loss: 0.5555 - val_accuracy: 0.7007\n",
      "Epoch 453/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4555 - accuracy: 0.7898 - val_loss: 0.5623 - val_accuracy: 0.6788\n",
      "Epoch 454/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4445 - accuracy: 0.7824 - val_loss: 0.5748 - val_accuracy: 0.6861\n",
      "Epoch 455/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4675 - accuracy: 0.7824 - val_loss: 0.5495 - val_accuracy: 0.7153\n",
      "Epoch 456/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4950 - accuracy: 0.7715 - val_loss: 0.5427 - val_accuracy: 0.7080\n",
      "Epoch 457/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4444 - accuracy: 0.8007 - val_loss: 0.5373 - val_accuracy: 0.7226\n",
      "Epoch 458/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4486 - accuracy: 0.7916 - val_loss: 0.5443 - val_accuracy: 0.7445\n",
      "Epoch 459/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4257 - accuracy: 0.8135 - val_loss: 0.5642 - val_accuracy: 0.7299\n",
      "Epoch 460/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4204 - accuracy: 0.8117 - val_loss: 0.5711 - val_accuracy: 0.7372\n",
      "Epoch 461/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4419 - accuracy: 0.8227 - val_loss: 0.5775 - val_accuracy: 0.7153\n",
      "Epoch 462/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4340 - accuracy: 0.8154 - val_loss: 0.5974 - val_accuracy: 0.7080\n",
      "Epoch 463/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4987 - accuracy: 0.7678 - val_loss: 0.6259 - val_accuracy: 0.7007\n",
      "Epoch 464/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4444 - accuracy: 0.8080 - val_loss: 0.6190 - val_accuracy: 0.6861\n",
      "Epoch 465/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4812 - accuracy: 0.7751 - val_loss: 0.5862 - val_accuracy: 0.6934\n",
      "Epoch 466/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.4183 - accuracy: 0.8263 - val_loss: 0.5633 - val_accuracy: 0.7080\n",
      "Epoch 467/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4682 - accuracy: 0.7806 - val_loss: 0.5546 - val_accuracy: 0.7299\n",
      "Epoch 468/500\n",
      "547/547 [==============================] - 0s 161us/sample - loss: 0.4534 - accuracy: 0.7989 - val_loss: 0.5534 - val_accuracy: 0.7153\n",
      "Epoch 469/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4541 - accuracy: 0.8062 - val_loss: 0.5517 - val_accuracy: 0.7226\n",
      "Epoch 470/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4339 - accuracy: 0.8154 - val_loss: 0.5502 - val_accuracy: 0.7664\n",
      "Epoch 471/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4406 - accuracy: 0.7843 - val_loss: 0.5568 - val_accuracy: 0.7372\n",
      "Epoch 472/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4555 - accuracy: 0.7989 - val_loss: 0.5583 - val_accuracy: 0.7445\n",
      "Epoch 473/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4358 - accuracy: 0.8099 - val_loss: 0.5661 - val_accuracy: 0.7299\n",
      "Epoch 474/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4362 - accuracy: 0.8117 - val_loss: 0.5708 - val_accuracy: 0.7372\n",
      "Epoch 475/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4596 - accuracy: 0.7770 - val_loss: 0.5767 - val_accuracy: 0.7226\n",
      "Epoch 476/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4346 - accuracy: 0.8190 - val_loss: 0.5816 - val_accuracy: 0.7153\n",
      "Epoch 477/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4424 - accuracy: 0.7971 - val_loss: 0.6001 - val_accuracy: 0.6788\n",
      "Epoch 478/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4293 - accuracy: 0.8172 - val_loss: 0.6463 - val_accuracy: 0.6788\n",
      "Epoch 479/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4598 - accuracy: 0.7678 - val_loss: 0.6423 - val_accuracy: 0.6788\n",
      "Epoch 480/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4551 - accuracy: 0.7898 - val_loss: 0.6158 - val_accuracy: 0.6642\n",
      "Epoch 481/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4350 - accuracy: 0.7989 - val_loss: 0.5876 - val_accuracy: 0.7080\n",
      "Epoch 482/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4378 - accuracy: 0.8026 - val_loss: 0.6053 - val_accuracy: 0.6934\n",
      "Epoch 483/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4764 - accuracy: 0.7824 - val_loss: 0.6323 - val_accuracy: 0.6642\n",
      "Epoch 484/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4405 - accuracy: 0.7971 - val_loss: 0.6447 - val_accuracy: 0.6350\n",
      "Epoch 485/500\n",
      "547/547 [==============================] - 0s 165us/sample - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.6180 - val_accuracy: 0.6715\n",
      "Epoch 486/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4642 - accuracy: 0.7733 - val_loss: 0.6032 - val_accuracy: 0.6642\n",
      "Epoch 487/500\n",
      "547/547 [==============================] - 0s 174us/sample - loss: 0.4416 - accuracy: 0.7806 - val_loss: 0.5697 - val_accuracy: 0.7080\n",
      "Epoch 488/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4944 - accuracy: 0.7697 - val_loss: 0.5658 - val_accuracy: 0.7299\n",
      "Epoch 489/500\n",
      "547/547 [==============================] - 0s 163us/sample - loss: 0.4325 - accuracy: 0.8099 - val_loss: 0.5732 - val_accuracy: 0.7153\n",
      "Epoch 490/500\n",
      "547/547 [==============================] - 0s 167us/sample - loss: 0.4404 - accuracy: 0.7898 - val_loss: 0.5874 - val_accuracy: 0.7299\n",
      "Epoch 491/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4189 - accuracy: 0.8172 - val_loss: 0.6058 - val_accuracy: 0.7299\n",
      "Epoch 492/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4368 - accuracy: 0.7806 - val_loss: 0.6408 - val_accuracy: 0.7153\n",
      "Epoch 493/500\n",
      "547/547 [==============================] - 0s 172us/sample - loss: 0.4173 - accuracy: 0.8135 - val_loss: 0.6158 - val_accuracy: 0.7080\n",
      "Epoch 494/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4473 - accuracy: 0.8007 - val_loss: 0.5864 - val_accuracy: 0.7445\n",
      "Epoch 495/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4271 - accuracy: 0.8227 - val_loss: 0.5675 - val_accuracy: 0.7518\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4446 - accuracy: 0.7898 - val_loss: 0.5819 - val_accuracy: 0.7591\n",
      "Epoch 497/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4383 - accuracy: 0.8080 - val_loss: 0.5845 - val_accuracy: 0.7591\n",
      "Epoch 498/500\n",
      "547/547 [==============================] - 0s 166us/sample - loss: 0.4611 - accuracy: 0.7879 - val_loss: 0.5812 - val_accuracy: 0.7372\n",
      "Epoch 499/500\n",
      "547/547 [==============================] - 0s 170us/sample - loss: 0.4518 - accuracy: 0.8007 - val_loss: 0.6135 - val_accuracy: 0.6861\n",
      "Epoch 500/500\n",
      "547/547 [==============================] - 0s 168us/sample - loss: 0.4658 - accuracy: 0.7806 - val_loss: 0.6242 - val_accuracy: 0.6569\n"
     ]
    }
   ],
   "source": [
    "##Training\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "history = lstmModel.fit(x_train_2, y_train_2,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test_2, y_test_2),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1704b919c08>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.set_title(\"Simple LSTM with encoded feat, arithmetic\")\n",
    "ax.set_ylim((0.4,1))\n",
    "ax.set_yticks(np.arange(0.4,1,0.05))\n",
    "ax.grid()\n",
    "ax.plot(history.history['accuracy'])\n",
    "ax.plot(history.history['val_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
